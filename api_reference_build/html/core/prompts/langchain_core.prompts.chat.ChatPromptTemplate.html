
<!DOCTYPE html>

<html data-content_root="../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>ChatPromptTemplate — 🦜🔗 LangChain  documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../_static/pygments.css?v=a746c00c" rel="stylesheet" type="text/css"/>
<link href="../../_static/autodoc_pydantic.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom.css?v=b95e2228" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/documentation_options.js?v=3b5cce75"></script>
<script src="../../_static/doctools.js?v=9a2dae69"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=f281be69"></script>
<script src="../../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'core/prompts/langchain_core.prompts.chat.ChatPromptTemplate';</script>
<link href="../../_static/favicon.png" rel="icon"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="langchain_core.prompts.chat.HumanMessagePromptTemplate.html" rel="next" title="HumanMessagePromptTemplate"/>
<link href="langchain_core.prompts.chat.ChatMessagePromptTemplate.html" rel="prev" title="ChatMessagePromptTemplate"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Sep 25, 2024" name="docbuild:last-update"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../index.html">
<img alt="🦜🔗 LangChain  documentation - Home" class="logo__image only-light" src="../../_static/wordmark-api.svg"/>
<script>document.write(`<img src="../../_static/wordmark-api-dark.svg" class="logo__image only-dark" alt="🦜🔗 LangChain  documentation - Home"/>`);</script>
</a></div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../reference.html">
    Reference
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://api.python.langchain.com/">
    Legacy reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../reference.html">
    Reference
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://api.python.langchain.com/">
    Legacy reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Base packages</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Core</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../agents.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">agents</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../beta.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">beta</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../caches.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">caches</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../callbacks.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">callbacks</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chat_history.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_history</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chat_loaders.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_loaders</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../chat_sessions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_sessions</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../document_loaders.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">document_loaders</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../documents.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">documents</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../embeddings.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../example_selectors.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">example_selectors</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../exceptions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">exceptions</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../globals.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">globals</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../indexing.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">indexing</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../language_models.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">language_models</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../load.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">load</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../messages.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">messages</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../output_parsers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">output_parsers</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../outputs.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">outputs</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../prompt_values.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">prompt_values</span></code></a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../prompts.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">prompts</span></code></a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.base.BasePromptTemplate.html">BasePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.chat.AIMessagePromptTemplate.html">AIMessagePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html">BaseChatPromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html">BaseMessagePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.chat.BaseStringMessagePromptTemplate.html">BaseStringMessagePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.chat.ChatMessagePromptTemplate.html">ChatMessagePromptTemplate</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">ChatPromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.chat.HumanMessagePromptTemplate.html">HumanMessagePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.chat.MessagesPlaceholder.html">MessagesPlaceholder</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.chat.SystemMessagePromptTemplate.html">SystemMessagePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html">FewShotChatMessagePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.few_shot.FewShotPromptTemplate.html">FewShotPromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.few_shot_with_templates.FewShotPromptWithTemplates.html">FewShotPromptWithTemplates</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.image.ImagePromptTemplate.html">ImagePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.pipeline.PipelinePromptTemplate.html">PipelinePromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.prompt.PromptTemplate.html">PromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.string.StringPromptTemplate.html">StringPromptTemplate</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.structured.StructuredPrompt.html">StructuredPrompt</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.base.aformat_document.html">aformat_document</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.base.format_document.html">format_document</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.loading.load_prompt.html">load_prompt</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.loading.load_prompt_from_config.html">load_prompt_from_config</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.string.check_valid_template.html">check_valid_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.string.get_template_variables.html">get_template_variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.string.jinja2_formatter.html">jinja2_formatter</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.string.mustache_formatter.html">mustache_formatter</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.string.mustache_schema.html">mustache_schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.string.mustache_template_vars.html">mustache_template_vars</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain_core.prompts.string.validate_jinja2.html">validate_jinja2</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../rate_limiters.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">rate_limiters</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../retrievers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">retrievers</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../runnables.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">runnables</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../stores.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">stores</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../structured_query.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">structured_query</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../sys_info.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sys_info</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../tools.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tools</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../tracers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tracers</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">utils</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../vectorstores.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">vectorstores</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../langchain/index.html">Langchain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../text_splitters/index.html">Text Splitters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/index.html">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental/index.html">Experimental</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Integrations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ai21/index.html">AI21</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../airbyte/index.html">Airbyte</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../anthropic/index.html">Anthropic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../aws/index.html">AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../azure_dynamic_sessions/index.html">Azure Dynamic Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../box/index.html">Box</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chroma/index.html">Chroma</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cohere/index.html">Cohere</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../couchbase/index.html">Couchbase</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../elasticsearch/index.html">Elasticsearch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../exa/index.html">Exa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fireworks/index.html">Fireworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_community/index.html">Google Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_genai/index.html">Google GenAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_vertexai/index.html">Google VertexAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../groq/index.html">Groq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../huggingface/index.html">Huggingface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../milvus/index.html">Milvus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mistralai/index.html">MistralAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mongodb/index.html">MongoDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nomic/index.html">Nomic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ollama/index.html">Ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openai/index.html">OpenAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pinecone/index.html">Pinecone</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../postgres/index.html">Postgres</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../prompty/index.html">Prompty</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../qdrant/index.html">Qdrant</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../together/index.html">Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unstructured/index.html">Unstructured</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../voyageai/index.html">VoyageAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../weaviate/index.html">Weaviate</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../../reference.html">LangChain Python API Reference</a></li>
<li class="breadcrumb-item"><i class="fa-solid fa-ellipsis"></i></li>
<li class="breadcrumb-item"><a class="nav-link" href="../prompts.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">prompts</span></code></a></li>
<li aria-current="page" class="breadcrumb-item active">ChatPromptTemplate</li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<section id="chatprompttemplate">
<h1>ChatPromptTemplate<a class="headerlink" href="#chatprompttemplate" title="Link to this heading">#</a></h1>
<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain_core.prompts.chat.</span></span><span class="sig-name descname"><span class="pre">ChatPromptTemplate</span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseChatPromptTemplate</span></code></a></p>
<p>Prompt template for chat models.</p>
<p>Use to create flexible templated prompts for chat models.</p>
<p class="rubric">Examples</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.2.24: </span>You can pass any Message-like formats supported by
<code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.from_messages()</span></code> directly to <code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate()</span></code>
init.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">"system"</span><span class="p">,</span> <span class="s2">"You are a helpful AI bot. Your name is </span><span class="si">{name}</span><span class="s2">."</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"Hello, how are you doing?"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"ai"</span><span class="p">,</span> <span class="s2">"I'm doing well, thanks!"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{user_input}</span><span class="s2">"</span><span class="p">),</span>
<span class="p">])</span>

<span class="n">prompt_value</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"Bob"</span><span class="p">,</span>
        <span class="s2">"user_input"</span><span class="p">:</span> <span class="s2">"What is your name?"</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="c1"># Output:</span>
<span class="c1"># ChatPromptValue(</span>
<span class="c1">#    messages=[</span>
<span class="c1">#        SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),</span>
<span class="c1">#        HumanMessage(content='Hello, how are you doing?'),</span>
<span class="c1">#        AIMessage(content="I'm doing well, thanks!"),</span>
<span class="c1">#        HumanMessage(content='What is your name?')</span>
<span class="c1">#    ]</span>
<span class="c1">#)</span>
</pre></div>
</div>
<p>Messages Placeholder:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># In addition to Human/AI/Tool/Function messages,</span>
<span class="c1"># you can initialize the template with a MessagesPlaceholder</span>
<span class="c1"># either using the class directly or with the shorthand tuple syntax:</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">"system"</span><span class="p">,</span> <span class="s2">"You are a helpful AI bot."</span><span class="p">),</span>
    <span class="c1"># Means the template will receive an optional list of messages under</span>
    <span class="c1"># the "conversation" key</span>
    <span class="p">(</span><span class="s2">"placeholder"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{conversation}</span><span class="s2">"</span><span class="p">)</span>
    <span class="c1"># Equivalently:</span>
    <span class="c1"># MessagesPlaceholder(variable_name="conversation", optional=True)</span>
<span class="p">])</span>

<span class="n">prompt_value</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">"conversation"</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"Hi!"</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">"ai"</span><span class="p">,</span> <span class="s2">"How can I assist you today?"</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"Can you make me an ice cream sundae?"</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">"ai"</span><span class="p">,</span> <span class="s2">"No."</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Output:</span>
<span class="c1"># ChatPromptValue(</span>
<span class="c1">#    messages=[</span>
<span class="c1">#        SystemMessage(content='You are a helpful AI bot.'),</span>
<span class="c1">#        HumanMessage(content='Hi!'),</span>
<span class="c1">#        AIMessage(content='How can I assist you today?'),</span>
<span class="c1">#        HumanMessage(content='Can you make me an ice cream sundae?'),</span>
<span class="c1">#        AIMessage(content='No.'),</span>
<span class="c1">#    ]</span>
<span class="c1">#)</span>
</pre></div>
</div>
</div></blockquote>
<p>Single-variable template:</p>
<blockquote>
<div><p>If your prompt has only a single input variable (i.e., 1 instance of “{variable_nams}”),
and you invoke the template with a non-dict object, the prompt template will
inject the provided argument into that variable location.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">"system"</span><span class="p">,</span> <span class="s2">"You are a helpful AI bot. Your name is Carl."</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{user_input}</span><span class="s2">"</span><span class="p">),</span>
<span class="p">])</span>

<span class="n">prompt_value</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"Hello, there!"</span><span class="p">)</span>
<span class="c1"># Equivalent to</span>
<span class="c1"># prompt_value = template.invoke({"user_input": "Hello, there!"})</span>

<span class="c1"># Output:</span>
<span class="c1">#  ChatPromptValue(</span>
<span class="c1">#     messages=[</span>
<span class="c1">#         SystemMessage(content='You are a helpful AI bot. Your name is Carl.'),</span>
<span class="c1">#         HumanMessage(content='Hello, there!'),</span>
<span class="c1">#     ]</span>
<span class="c1"># )</span>
</pre></div>
</div>
</div></blockquote>
<p>Create a chat prompt template from a variety of message formats.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> – sequence of message representations.
A message can be represented using the following formats:
(1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of
(message type, template); e.g., (“human”, “{user_input}”),
(4) 2-tuple of (message class, template), (5) a string which is
shorthand for (“human”, template); e.g., “{user_input}”.</p></li>
<li><p><strong>template_format</strong> – format of the template. Defaults to “f-string”.</p></li>
<li><p><strong>input_variables</strong> – A list of the names of the variables whose values are
required as inputs to the prompt.</p></li>
<li><p><strong>optional_variables</strong> – A list of the names of the variables for placeholder</p></li>
<li><p><strong>inferred</strong> (<em>or MessagePlaceholder that are optional. These variables are auto</em>)</p></li>
<li><p><strong>them.</strong> (<em>from the prompt and user need not provide</em>)</p></li>
<li><p><strong>partial_variables</strong> – A dictionary of the partial variables the prompt
template carries. Partial variables populate the template so that you
don’t need to pass them in every time you call the prompt.</p></li>
<li><p><strong>validate_template</strong> – Whether to validate the template.</p></li>
<li><p><strong>input_types</strong> – A dictionary of the types of the variables the prompt template
expects. If not provided, all variables are assumed to be strings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A chat prompt template.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Instantiation from a list of message templates:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"Hello, how are you?"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"ai"</span><span class="p">,</span> <span class="s2">"I'm doing well, thanks!"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"That's good to hear."</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
<p>Instantiation from mixed message formats:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">"hello"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"Hello, how are you?"</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ChatPromptTemplate implements the standard <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Runnable</span> <span class="pre">Interface</span></code></a>. 🏃</p>
<p>The <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Runnable</span> <span class="pre">Interface</span></code></a> has additional methods that are available on runnables, such as <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_types" title="langchain_core.runnables.base.Runnable.with_types"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_types</span></code></a>, <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_retry" title="langchain_core.runnables.base.Runnable.with_retry"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_retry</span></code></a>, <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.assign" title="langchain_core.runnables.base.Runnable.assign"><code class="xref py py-meth docutils literal notranslate"><span class="pre">assign</span></code></a>, <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.bind" title="langchain_core.runnables.base.Runnable.bind"><code class="xref py py-meth docutils literal notranslate"><span class="pre">bind</span></code></a>, <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.get_graph" title="langchain_core.runnables.base.Runnable.get_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_graph</span></code></a>, and more.</p>
</div>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.input_types">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_types</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.input_types" title="Link to this definition">#</a></dt>
<dd><p>A dictionary of the types of the variables the prompt template expects.
If not provided, all variables are assumed to be strings.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.input_variables">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_variables</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.input_variables" title="Link to this definition">#</a></dt>
<dd><p>A list of the names of the variables whose values are required as inputs to the
prompt.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.messages">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">messages</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Annotated</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">MessageLike</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">SkipValidation</span><span class="p"><span class="pre">(</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.messages" title="Link to this definition">#</a></dt>
<dd><p>List of messages consisting of either message prompt templates or messages.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.metadata">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metadata</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.metadata" title="Link to this definition">#</a></dt>
<dd><p>Metadata to be used for tracing.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.optional_variables">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optional_variables</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.optional_variables" title="Link to this definition">#</a></dt>
<dd><p>optional_variables: A list of the names of the variables for placeholder
or MessagePlaceholder that are optional. These variables are auto inferred
from the prompt and user need not provide them.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.output_parser">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_parser</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../output_parsers/langchain_core.output_parsers.base.BaseOutputParser.html#langchain_core.output_parsers.base.BaseOutputParser" title="langchain_core.output_parsers.base.BaseOutputParser"><span class="pre">BaseOutputParser</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.output_parser" title="Link to this definition">#</a></dt>
<dd><p>How to parse the output of calling an LLM on this formatted prompt.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.partial_variables">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">partial_variables</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.partial_variables" title="Link to this definition">#</a></dt>
<dd><p>A dictionary of the partial variables the prompt template carries.</p>
<p>Partial variables populate the template so that you don’t need to
pass them in every time you call the prompt.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.tags">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tags</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.tags" title="Link to this definition">#</a></dt>
<dd><p>Tags to be used for tracing.</p>
</dd></dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.validate_template">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.validate_template" title="Link to this definition">#</a></dt>
<dd><p>Whether or not to try validating the template.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.abatch">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">abatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.abatch" title="Link to this definition">#</a></dt>
<dd><p>Default implementation runs ainvoke in parallel using asyncio.gather.</p>
<p>The default implementation of batch works well for IO bound runnables.</p>
<p>Subclasses should override this method if they can batch more efficiently;
e.g., if the underlying Runnable uses an API which supports a batch mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>list</em><em>[</em><em>Input</em><em>]</em>) – A list of inputs to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>list</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>] </em><em>| </em><em>None</em>) – A config to use when invoking the Runnable.
The config supports standard keys like ‘tags’, ‘metadata’ for tracing
purposes, ‘max_concurrency’ for controlling how much work to do
in parallel, and other keys. Please refer to the RunnableConfig
for more details. Defaults to None.</p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) – Whether to return exceptions instead of raising them.
Defaults to False.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) – Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of outputs from the Runnable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.abatch_as_completed">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">abatch_as_completed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Exception</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.abatch_as_completed" title="Link to this definition">#</a></dt>
<dd><p>Run ainvoke in parallel on a list of inputs,
yielding results as they complete.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Sequence</em><em>[</em><em>Input</em><em>]</em>) – A list of inputs to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>Sequence</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>] </em><em>| </em><em>None</em>) – A config to use when invoking the Runnable.
The config supports standard keys like ‘tags’, ‘metadata’ for tracing
purposes, ‘max_concurrency’ for controlling how much work to do
in parallel, and other keys. Please refer to the RunnableConfig
for more details. Defaults to None. Defaults to None.</p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) – Whether to return exceptions instead of raising them.
Defaults to False.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) – Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple of the index of the input and the output from the Runnable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>AsyncIterator</em>[tuple[int, <em>Output</em> | Exception]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.aformat">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aformat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat" title="Link to this definition">#</a></dt>
<dd><p>Async format the chat template into a string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) – keyword arguments to use for filling in template variables
in all the template messages in this chat template.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>formatted string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.aformat_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aformat_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.aformat_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat_messages" title="Link to this definition">#</a></dt>
<dd><p>Async format the chat template into a list of finalized messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) – keyword arguments to use for filling in template variables
in all the template messages in this chat template.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of formatted messages.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – If unexpected input.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.aformat_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aformat_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat_prompt" title="Link to this definition">#</a></dt>
<dd><p>Async format prompt. Should return a PromptValue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) – Keyword arguments to use for formatting.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>PromptValue.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.ainvoke">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ainvoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.ainvoke" title="Link to this definition">#</a></dt>
<dd><p>Async invoke the prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>dict</em>) – Dict, input to the prompt.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) – RunnableConfig, configuration for the prompt.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the prompt.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue">PromptValue</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.append">
<span class="sig-name descname"><span class="pre">append</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><span class="pre">BaseMessagePromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><span class="pre">BaseChatPromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.append"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.append" title="Link to this definition">#</a></dt>
<dd><p>Append a message to the end of the chat template.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>message</strong> (<a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><em>BaseMessagePromptTemplate</em></a><em> | </em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em> | </em><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><em>BaseChatPromptTemplate</em></a><em> | </em><em>tuple</em><em>[</em><em>str</em><em> | </em><em>type</em><em>, </em><em>str</em><em> | </em><em>list</em><em>[</em><em>dict</em><em>] </em><em>| </em><em>list</em><em>[</em><em>object</em><em>]</em><em>] </em><em>| </em><em>str</em>) – representation of a message to append.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.astream">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">astream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.astream" title="Link to this definition">#</a></dt>
<dd><p>Default implementation of astream, which calls ainvoke.
Subclasses should override this method if they support streaming output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Input</em>) – The input to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) – The config to use for the Runnable. Defaults to None.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) – Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the Runnable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>AsyncIterator</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.astream_events">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">astream_events</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'v1'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'v2'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.schema.StandardStreamEvent.html#langchain_core.runnables.schema.StandardStreamEvent" title="langchain_core.runnables.schema.StandardStreamEvent"><span class="pre">StandardStreamEvent</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.schema.CustomStreamEvent.html#langchain_core.runnables.schema.CustomStreamEvent" title="langchain_core.runnables.schema.CustomStreamEvent"><span class="pre">CustomStreamEvent</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.astream_events" title="Link to this definition">#</a></dt>
<dd><p>Generate a stream of events.</p>
<p>Use to create an iterator over StreamEvents that provide real-time information
about the progress of the Runnable, including StreamEvents from intermediate
results.</p>
<p>A StreamEvent is a dictionary with the following schema:</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">event</span></code>: <strong>str</strong> - Event names are of the</dt><dd><p>format: on_[runnable_type]_(start|stream|end).</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: <strong>str</strong> - The name of the Runnable that generated the event.</p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">run_id</span></code>: <strong>str</strong> - randomly generated ID associated with the given execution of</dt><dd><p>the Runnable that emitted the event.
A child Runnable that gets invoked as part of the execution of a
parent Runnable is assigned its own unique ID.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">parent_ids</span></code>: <strong>List[str]</strong> - The IDs of the parent runnables that</dt><dd><p>generated the event. The root Runnable will have an empty list.
The order of the parent IDs is from the root to the immediate parent.
Only available for v2 version of the API. The v1 version of the API
will return an empty list.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">tags</span></code>: <strong>Optional[List[str]]</strong> - The tags of the Runnable that generated</dt><dd><p>the event.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">metadata</span></code>: <strong>Optional[Dict[str, Any]]</strong> - The metadata of the Runnable</dt><dd><p>that generated the event.</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: <strong>Dict[str, Any]</strong></p></li>
</ul>
<p>Below is a table that illustrates some evens that might be emitted by various
chains. Metadata fields have been omitted from the table for brevity.
Chain definitions have been included after the table.</p>
<p><strong>ATTENTION</strong> This reference table is for the V2 version of the schema.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>event</p></th>
<th class="head"><p>name</p></th>
<th class="head"><p>chunk</p></th>
<th class="head"><p>input</p></th>
<th class="head"><p>output</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>on_chat_model_start</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{“messages”: [[SystemMessage, HumanMessage]]}</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_chat_model_stream</p></td>
<td><p>[model name]</p></td>
<td><p>AIMessageChunk(content=”hello”)</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chat_model_end</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{“messages”: [[SystemMessage, HumanMessage]]}</p></td>
<td><p>AIMessageChunk(content=”hello world”)</p></td>
</tr>
<tr class="row-odd"><td><p>on_llm_start</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{‘input’: ‘hello’}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_llm_stream</p></td>
<td><p>[model name]</p></td>
<td><p>‘Hello’</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_llm_end</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>‘Hello human!’</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chain_start</p></td>
<td><p>format_docs</p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_chain_stream</p></td>
<td><p>format_docs</p></td>
<td><p>“hello world!, goodbye world!”</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chain_end</p></td>
<td><p>format_docs</p></td>
<td></td>
<td><p>[Document(…)]</p></td>
<td><p>“hello world!, goodbye world!”</p></td>
</tr>
<tr class="row-odd"><td><p>on_tool_start</p></td>
<td><p>some_tool</p></td>
<td></td>
<td><p>{“x”: 1, “y”: “2”}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_tool_end</p></td>
<td><p>some_tool</p></td>
<td></td>
<td></td>
<td><p>{“x”: 1, “y”: “2”}</p></td>
</tr>
<tr class="row-odd"><td><p>on_retriever_start</p></td>
<td><p>[retriever name]</p></td>
<td></td>
<td><p>{“query”: “hello”}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_retriever_end</p></td>
<td><p>[retriever name]</p></td>
<td></td>
<td><p>{“query”: “hello”}</p></td>
<td><p>[Document(…), ..]</p></td>
</tr>
<tr class="row-odd"><td><p>on_prompt_start</p></td>
<td><p>[template_name]</p></td>
<td></td>
<td><p>{“question”: “hello”}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_prompt_end</p></td>
<td><p>[template_name]</p></td>
<td></td>
<td><p>{“question”: “hello”}</p></td>
<td><p>ChatPromptValue(messages: [SystemMessage, …])</p></td>
</tr>
</tbody>
</table>
</div>
<p>In addition to the standard events, users can also dispatch custom events (see example below).</p>
<p>Custom events will be only be surfaced with in the <cite>v2</cite> version of the API!</p>
<p>A custom event has following format:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>name</p></td>
<td><p>str</p></td>
<td><p>A user defined name for the event.</p></td>
</tr>
<tr class="row-odd"><td><p>data</p></td>
<td><p>Any</p></td>
<td><p>The data associated with the event. This can be anything, though we suggest making it JSON serializable.</p></td>
</tr>
</tbody>
</table>
</div>
<p>Here are declarations associated with the standard events shown above:</p>
<p><cite>format_docs</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">format_docs</span><span class="p">(</span><span class="n">docs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">'''Format the docs.'''</span>
    <span class="k">return</span> <span class="s2">", "</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">])</span>

<span class="n">format_docs</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">format_docs</span><span class="p">)</span>
</pre></div>
</div>
<p><cite>some_tool</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tool</span>
<span class="k">def</span> <span class="nf">some_tool</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">'''Some_tool.'''</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">"x"</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">"y"</span><span class="p">:</span> <span class="n">y</span><span class="p">}</span>
</pre></div>
</div>
<p><cite>prompt</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[(</span><span class="s2">"system"</span><span class="p">,</span> <span class="s2">"You are Cat Agent 007"</span><span class="p">),</span> <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{question}</span><span class="s2">"</span><span class="p">)]</span>
<span class="p">)</span><span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">"run_name"</span><span class="p">:</span> <span class="s2">"my_template"</span><span class="p">,</span> <span class="s2">"tags"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"my_template"</span><span class="p">]})</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">reverse</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">s</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">reverse</span><span class="p">)</span>

<span class="n">events</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">event</span> <span class="k">async</span> <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">chain</span><span class="o">.</span><span class="n">astream_events</span><span class="p">(</span><span class="s2">"hello"</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="s2">"v2"</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># will produce the following events (run_id, and parent_ids</span>
<span class="c1"># has been omitted for brevity):</span>
<span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">"data"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"input"</span><span class="p">:</span> <span class="s2">"hello"</span><span class="p">},</span>
        <span class="s2">"event"</span><span class="p">:</span> <span class="s2">"on_chain_start"</span><span class="p">,</span>
        <span class="s2">"metadata"</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"reverse"</span><span class="p">,</span>
        <span class="s2">"tags"</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">"data"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"chunk"</span><span class="p">:</span> <span class="s2">"olleh"</span><span class="p">},</span>
        <span class="s2">"event"</span><span class="p">:</span> <span class="s2">"on_chain_stream"</span><span class="p">,</span>
        <span class="s2">"metadata"</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"reverse"</span><span class="p">,</span>
        <span class="s2">"tags"</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">"data"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"output"</span><span class="p">:</span> <span class="s2">"olleh"</span><span class="p">},</span>
        <span class="s2">"event"</span><span class="p">:</span> <span class="s2">"on_chain_end"</span><span class="p">,</span>
        <span class="s2">"metadata"</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"reverse"</span><span class="p">,</span>
        <span class="s2">"tags"</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Example: Dispatch Custom Event</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.callbacks.manager</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">adispatch_custom_event</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span><span class="p">,</span> <span class="n">RunnableConfig</span>
<span class="kn">import</span> <span class="nn">asyncio</span>


<span class="k">async</span> <span class="k">def</span> <span class="nf">slow_thing</span><span class="p">(</span><span class="n">some_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">RunnableConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Do something that takes a long time."""</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Placeholder for some slow operation</span>
    <span class="k">await</span> <span class="n">adispatch_custom_event</span><span class="p">(</span>
        <span class="s2">"progress_event"</span><span class="p">,</span>
        <span class="p">{</span><span class="s2">"message"</span><span class="p">:</span> <span class="s2">"Finished step 1 of 3"</span><span class="p">},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span> <span class="c1"># Must be included for python &lt; 3.10</span>
    <span class="p">)</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Placeholder for some slow operation</span>
    <span class="k">await</span> <span class="n">adispatch_custom_event</span><span class="p">(</span>
        <span class="s2">"progress_event"</span><span class="p">,</span>
        <span class="p">{</span><span class="s2">"message"</span><span class="p">:</span> <span class="s2">"Finished step 2 of 3"</span><span class="p">},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span> <span class="c1"># Must be included for python &lt; 3.10</span>
    <span class="p">)</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Placeholder for some slow operation</span>
    <span class="k">return</span> <span class="s2">"Done"</span>

<span class="n">slow_thing</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">slow_thing</span><span class="p">)</span>

<span class="k">async</span> <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">slow_thing</span><span class="o">.</span><span class="n">astream_events</span><span class="p">(</span><span class="s2">"some_input"</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="s2">"v2"</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Any</em>) – The input to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) – The config to use for the Runnable.</p></li>
<li><p><strong>version</strong> (<em>Literal</em><em>[</em><em>'v1'</em><em>, </em><em>'v2'</em><em>]</em>) – The version of the schema to use either <cite>v2</cite> or <cite>v1</cite>.
Users should use <cite>v2</cite>.
<cite>v1</cite> is for backwards compatibility and will be deprecated
in 0.4.0.
No default will be assigned until the API is stabilized.
custom events will only be surfaced in <cite>v2</cite>.</p></li>
<li><p><strong>include_names</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – Only include events from runnables with matching names.</p></li>
<li><p><strong>include_types</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – Only include events from runnables with matching types.</p></li>
<li><p><strong>include_tags</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – Only include events from runnables with matching tags.</p></li>
<li><p><strong>exclude_names</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – Exclude events from runnables with matching names.</p></li>
<li><p><strong>exclude_types</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – Exclude events from runnables with matching types.</p></li>
<li><p><strong>exclude_tags</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – Exclude events from runnables with matching tags.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Additional keyword arguments to pass to the Runnable.
These will be passed to astream_log as this implementation
of astream_events is built on top of astream_log.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p>An async stream of StreamEvents.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>NotImplementedError</strong> – If the version is not <cite>v1</cite> or <cite>v2</cite>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>AsyncIterator</em>[<a class="reference internal" href="../runnables/langchain_core.runnables.schema.StandardStreamEvent.html#langchain_core.runnables.schema.StandardStreamEvent" title="langchain_core.runnables.schema.StandardStreamEvent"><em>StandardStreamEvent</em></a> | <a class="reference internal" href="../runnables/langchain_core.runnables.schema.CustomStreamEvent.html#langchain_core.runnables.schema.CustomStreamEvent" title="langchain_core.runnables.schema.CustomStreamEvent"><em>CustomStreamEvent</em></a>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.batch">
<span class="sig-name descname"><span class="pre">batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.batch" title="Link to this definition">#</a></dt>
<dd><p>Default implementation runs invoke in parallel using a thread pool executor.</p>
<p>The default implementation of batch works well for IO bound runnables.</p>
<p>Subclasses should override this method if they can batch more efficiently;
e.g., if the underlying Runnable uses an API which supports a batch mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>list</em><em>[</em><em>Input</em><em>]</em>)</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>list</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.batch_as_completed">
<span class="sig-name descname"><span class="pre">batch_as_completed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Exception</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.batch_as_completed" title="Link to this definition">#</a></dt>
<dd><p>Run invoke in parallel on a list of inputs,
yielding results as they complete.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Sequence</em><em>[</em><em>Input</em><em>]</em>)</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>Sequence</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Iterator</em>[tuple[int, <em>Output</em> | Exception]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.bind">
<span class="sig-name descname"><span class="pre">bind</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.bind" title="Link to this definition">#</a></dt>
<dd><p>Bind arguments to a Runnable, returning a new Runnable.</p>
<p>Useful when a Runnable in a chain requires an argument that is not
in the output of the previous Runnable or included in the user input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) – The arguments to bind to the Runnable.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the arguments bound.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_community.chat_models</span> <span class="kn">import</span> <span class="n">ChatOllama</span>
<span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOllama</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s1">'llama2'</span><span class="p">)</span>

<span class="c1"># Without bind.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">llm</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"Repeat quoted words exactly: 'One two three four five.'"</span><span class="p">)</span>
<span class="c1"># Output is 'One two three four five.'</span>

<span class="c1"># With bind.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">llm</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">stop</span><span class="o">=</span><span class="p">[</span><span class="s2">"three"</span><span class="p">])</span>
    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"Repeat quoted words exactly: 'One two three four five.'"</span><span class="p">)</span>
<span class="c1"># Output is 'One two'</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.configurable_alternatives">
<span class="sig-name descname"><span class="pre">configurable_alternatives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">which</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><span class="pre">ConfigurableField</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.configurable_alternatives" title="Link to this definition">#</a></dt>
<dd><p>Configure alternatives for Runnables that can be set at runtime.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>which</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><em>ConfigurableField</em></a>) – The ConfigurableField instance that will be used to select the
alternative.</p></li>
<li><p><strong>default_key</strong> (<em>str</em>) – The default key to use if no alternative is selected.
Defaults to “default”.</p></li>
<li><p><strong>prefix_keys</strong> (<em>bool</em>) – Whether to prefix the keys with the ConfigurableField id.
Defaults to False.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>] </em><em>| </em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>]</em><em>]</em>) – A dictionary of keys to Runnable instances or callables that
return Runnable instances.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the alternatives configured.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_anthropic</span> <span class="kn">import</span> <span class="n">ChatAnthropic</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables.utils</span> <span class="kn">import</span> <span class="n">ConfigurableField</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatAnthropic</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">"claude-3-sonnet-20240229"</span>
<span class="p">)</span><span class="o">.</span><span class="n">configurable_alternatives</span><span class="p">(</span>
    <span class="n">ConfigurableField</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">"llm"</span><span class="p">),</span>
    <span class="n">default_key</span><span class="o">=</span><span class="s2">"anthropic"</span><span class="p">,</span>
    <span class="n">openai</span><span class="o">=</span><span class="n">ChatOpenAI</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># uses the default model ChatAnthropic</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"which organization created you?"</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="c1"># uses ChatOpenAI</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
        <span class="n">configurable</span><span class="o">=</span><span class="p">{</span><span class="s2">"llm"</span><span class="p">:</span> <span class="s2">"openai"</span><span class="p">}</span>
    <span class="p">)</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"which organization created you?"</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.configurable_fields">
<span class="sig-name descname"><span class="pre">configurable_fields</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><span class="pre">ConfigurableField</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldSingleOption.html#langchain_core.runnables.utils.ConfigurableFieldSingleOption" title="langchain_core.runnables.utils.ConfigurableFieldSingleOption"><span class="pre">ConfigurableFieldSingleOption</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldMultiOption.html#langchain_core.runnables.utils.ConfigurableFieldMultiOption" title="langchain_core.runnables.utils.ConfigurableFieldMultiOption"><span class="pre">ConfigurableFieldMultiOption</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.configurable_fields" title="Link to this definition">#</a></dt>
<dd><p>Configure particular Runnable fields at runtime.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><em>ConfigurableField</em></a><em> | </em><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldSingleOption.html#langchain_core.runnables.utils.ConfigurableFieldSingleOption" title="langchain_core.runnables.utils.ConfigurableFieldSingleOption"><em>ConfigurableFieldSingleOption</em></a><em> | </em><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldMultiOption.html#langchain_core.runnables.utils.ConfigurableFieldMultiOption" title="langchain_core.runnables.utils.ConfigurableFieldMultiOption"><em>ConfigurableFieldMultiOption</em></a>) – A dictionary of ConfigurableField instances to configure.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the fields configured.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">ConfigurableField</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">configurable_fields</span><span class="p">(</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="n">ConfigurableField</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="s2">"output_token_number"</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">"Max tokens in the output"</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">"The maximum number of tokens in the output"</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># max_tokens = 20</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">"max_tokens_20: "</span><span class="p">,</span>
    <span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"tell me something about chess"</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>

<span class="c1"># max_tokens = 200</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"max_tokens_200: "</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
    <span class="n">configurable</span><span class="o">=</span><span class="p">{</span><span class="s2">"output_token_number"</span><span class="p">:</span> <span class="mi">200</span><span class="p">}</span>
    <span class="p">)</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"tell me something about chess"</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.extend">
<span class="sig-name descname"><span class="pre">extend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><span class="pre">BaseMessagePromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><span class="pre">BaseChatPromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.extend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.extend" title="Link to this definition">#</a></dt>
<dd><p>Extend the chat template with a sequence of messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><em>BaseMessagePromptTemplate</em></a><em> | </em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em> | </em><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><em>BaseChatPromptTemplate</em></a><em> | </em><em>tuple</em><em>[</em><em>str</em><em> | </em><em>type</em><em>, </em><em>str</em><em> | </em><em>list</em><em>[</em><em>dict</em><em>] </em><em>| </em><em>list</em><em>[</em><em>object</em><em>]</em><em>] </em><em>| </em><em>str</em><em>]</em>) – sequence of message representations to append.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.format">
<span class="sig-name descname"><span class="pre">format</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.format" title="Link to this definition">#</a></dt>
<dd><p>Format the chat template into a string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) – keyword arguments to use for filling in template variables
in all the template messages in this chat template.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>formatted string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.format_messages">
<span class="sig-name descname"><span class="pre">format_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.format_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.format_messages" title="Link to this definition">#</a></dt>
<dd><p>Format the chat template into a list of finalized messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) – keyword arguments to use for filling in template variables
in all the template messages in this chat template.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of formatted messages.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.format_prompt">
<span class="sig-name descname"><span class="pre">format_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.format_prompt" title="Link to this definition">#</a></dt>
<dd><p>Format prompt. Should return a PromptValue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) – Keyword arguments to use for formatting.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>PromptValue.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.from_messages">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><span class="pre">BaseMessagePromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><span class="pre">BaseChatPromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">template_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'f-string'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'mustache'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'jinja2'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'f-string'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.from_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_messages" title="Link to this definition">#</a></dt>
<dd><p>Create a chat prompt template from a variety of message formats.</p>
<p class="rubric">Examples</p>
<p>Instantiation from a list of message templates:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"Hello, how are you?"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"ai"</span><span class="p">,</span> <span class="s2">"I'm doing well, thanks!"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"That's good to hear."</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
<p>Instantiation from mixed message formats:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span>
    <span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">"hello"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"Hello, how are you?"</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><em>BaseMessagePromptTemplate</em></a><em> | </em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em> | </em><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><em>BaseChatPromptTemplate</em></a><em> | </em><em>tuple</em><em>[</em><em>str</em><em> | </em><em>type</em><em>, </em><em>str</em><em> | </em><em>list</em><em>[</em><em>dict</em><em>] </em><em>| </em><em>list</em><em>[</em><em>object</em><em>]</em><em>] </em><em>| </em><em>str</em><em>]</em>) – sequence of message representations.
A message can be represented using the following formats:
(1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of
(message type, template); e.g., (“human”, “{user_input}”),
(4) 2-tuple of (message class, template), (5) a string which is
shorthand for (“human”, template); e.g., “{user_input}”.</p></li>
<li><p><strong>template_format</strong> (<em>Literal</em><em>[</em><em>'f-string'</em><em>, </em><em>'mustache'</em><em>, </em><em>'jinja2'</em><em>]</em>) – format of the template. Defaults to “f-string”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a chat prompt template.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.from_role_strings">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_role_strings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">string_messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.from_role_strings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_role_strings" title="Link to this definition">#</a></dt>
<dd><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.0.1: </span>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">from_messages</span> <span class="pre">classmethod()</span></code> instead.</p>
</div>
<p>Create a chat prompt template from a list of (role, template) tuples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>string_messages</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – list of (role, template) tuples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a chat prompt template.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.from_strings">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_strings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">string_messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><span class="pre">BaseMessagePromptTemplate</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.from_strings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_strings" title="Link to this definition">#</a></dt>
<dd><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.0.1: </span>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">from_messages</span> <span class="pre">classmethod()</span></code> instead.</p>
</div>
<p>Create a chat prompt template from a list of (role class, template) tuples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>string_messages</strong> (<em>list</em><em>[</em><em>tuple</em><em>[</em><em>type</em><em>[</em><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><em>BaseMessagePromptTemplate</em></a><em>]</em><em>, </em><em>str</em><em>]</em><em>]</em>) – list of (role class, template) tuples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a chat prompt template.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.from_template">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_template</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">template</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.from_template"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_template" title="Link to this definition">#</a></dt>
<dd><p>Create a chat prompt template from a template string.</p>
<p>Creates a chat template consisting of a single message assumed to be from
the human.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>template</strong> (<em>str</em>) – template string</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) – keyword arguments to pass to the constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new instance of this class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.invoke">
<span class="sig-name descname"><span class="pre">invoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.invoke" title="Link to this definition">#</a></dt>
<dd><p>Invoke the prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>dict</em>) – Dict, input to the prompt.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) – RunnableConfig, configuration for the prompt.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the prompt.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue">PromptValue</a></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.partial">
<span class="sig-name descname"><span class="pre">partial</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.partial"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.partial" title="Link to this definition">#</a></dt>
<dd><p>Get a new ChatPromptTemplate with some input variables already filled in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) – keyword arguments to use for filling in template variables. Ought
to be a subset of the input variables.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new ChatPromptTemplate.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="s2">"system"</span><span class="p">,</span> <span class="s2">"You are an AI assistant named </span><span class="si">{name}</span><span class="s2">."</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"Hi I'm </span><span class="si">{user}</span><span class="s2">"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"ai"</span><span class="p">,</span> <span class="s2">"Hi there, </span><span class="si">{user}</span><span class="s2">, I'm </span><span class="si">{name}</span><span class="s2">."</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{input}</span><span class="s2">"</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">template2</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">user</span><span class="o">=</span><span class="s2">"Lucy"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"R2D2"</span><span class="p">)</span>

<span class="n">template2</span><span class="o">.</span><span class="n">format_messages</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">"hello"</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.pretty_print">
<span class="sig-name descname"><span class="pre">pretty_print</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.pretty_print" title="Link to this definition">#</a></dt>
<dd><p>Print a human-readable representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.pretty_repr">
<span class="sig-name descname"><span class="pre">pretty_repr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">html</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.pretty_repr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.pretty_repr" title="Link to this definition">#</a></dt>
<dd><p>Human-readable representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>html</strong> (<em>bool</em>) – Whether to format as HTML. Defaults to False.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Human-readable representation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Path</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.save" title="Link to this definition">#</a></dt>
<dd><p>Save prompt to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Path</em><em> | </em><em>str</em>) – path to file.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.stream" title="Link to this definition">#</a></dt>
<dd><p>Default implementation of stream, which calls invoke.
Subclasses should override this method if they support streaming output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Input</em>) – The input to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) – The config to use for the Runnable. Defaults to None.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) – Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the Runnable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Iterator</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.with_alisteners">
<span class="sig-name descname"><span class="pre">with_alisteners</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_start</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">AsyncListener</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_end</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">AsyncListener</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_error</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">AsyncListener</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_alisteners" title="Link to this definition">#</a></dt>
<dd><p>Bind asynchronous lifecycle listeners to a Runnable, returning a new Runnable.</p>
<p>on_start: Asynchronously called before the Runnable starts running.
on_end: Asynchronously called after the Runnable finishes running.
on_error: Asynchronously called if the Runnable throws an error.</p>
<p>The Run object contains information about the run, including its id,
type, input, output, error, start_time, end_time, and any tags or metadata
added to the run.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>on_start</strong> (<em>Optional</em><em>[</em><em>AsyncListener</em><em>]</em>) – Asynchronously called before the Runnable starts running.
Defaults to None.</p></li>
<li><p><strong>on_end</strong> (<em>Optional</em><em>[</em><em>AsyncListener</em><em>]</em>) – Asynchronously called after the Runnable finishes running.
Defaults to None.</p></li>
<li><p><strong>on_error</strong> (<em>Optional</em><em>[</em><em>AsyncListener</em><em>]</em>) – Asynchronously called if the Runnable throws an error.
Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the listeners bound.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable">Runnable</a>[Input, Output]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">test_runnable</span><span class="p">(</span><span class="n">time_to_sleep</span> <span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Runnable[</span><span class="si">{</span><span class="n">time_to_sleep</span><span class="si">}</span><span class="s2">s]: starts at </span><span class="si">{</span><span class="n">format_t</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">time_to_sleep</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Runnable[</span><span class="si">{</span><span class="n">time_to_sleep</span><span class="si">}</span><span class="s2">s]: ends at </span><span class="si">{</span><span class="n">format_t</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">fn_start</span><span class="p">(</span><span class="n">run_obj</span> <span class="p">:</span> <span class="n">Runnable</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"on start callback starts at </span><span class="si">{</span><span class="n">format_t</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"on start callback ends at </span><span class="si">{</span><span class="n">format_t</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">fn_end</span><span class="p">(</span><span class="n">run_obj</span> <span class="p">:</span> <span class="n">Runnable</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"on end callback starts at </span><span class="si">{</span><span class="n">format_t</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"on end callback ends at </span><span class="si">{</span><span class="n">format_t</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">test_runnable</span><span class="p">)</span><span class="o">.</span><span class="n">with_alisteners</span><span class="p">(</span>
    <span class="n">on_start</span><span class="o">=</span><span class="n">fn_start</span><span class="p">,</span>
    <span class="n">on_end</span><span class="o">=</span><span class="n">fn_end</span>
<span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">concurrent_runs</span><span class="p">():</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">runnable</span><span class="o">.</span><span class="n">ainvoke</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">runnable</span><span class="o">.</span><span class="n">ainvoke</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>

<span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">concurrent_runs</span><span class="p">())</span>
<span class="n">Result</span><span class="p">:</span>
<span class="n">on</span> <span class="n">start</span> <span class="n">callback</span> <span class="n">starts</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">29.637053</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">on</span> <span class="n">start</span> <span class="n">callback</span> <span class="n">starts</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">29.637150</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">on</span> <span class="n">start</span> <span class="n">callback</span> <span class="n">ends</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">32.638305</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">on</span> <span class="n">start</span> <span class="n">callback</span> <span class="n">ends</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">32.638383</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">Runnable</span><span class="p">[</span><span class="mi">3</span><span class="n">s</span><span class="p">]:</span> <span class="n">starts</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">32.638849</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">Runnable</span><span class="p">[</span><span class="mi">5</span><span class="n">s</span><span class="p">]:</span> <span class="n">starts</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">32.638999</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">Runnable</span><span class="p">[</span><span class="mi">3</span><span class="n">s</span><span class="p">]:</span> <span class="n">ends</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">35.640016</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">on</span> <span class="n">end</span> <span class="n">callback</span> <span class="n">starts</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">35.640534</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">Runnable</span><span class="p">[</span><span class="mi">5</span><span class="n">s</span><span class="p">]:</span> <span class="n">ends</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">37.640169</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">on</span> <span class="n">end</span> <span class="n">callback</span> <span class="n">starts</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">37.640574</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">on</span> <span class="n">end</span> <span class="n">callback</span> <span class="n">ends</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">37.640654</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
<span class="n">on</span> <span class="n">end</span> <span class="n">callback</span> <span class="n">ends</span> <span class="n">at</span> <span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">16</span><span class="n">T14</span><span class="p">:</span><span class="mi">20</span><span class="p">:</span><span class="mf">39.641751</span><span class="o">+</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.with_config">
<span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_config" title="Link to this definition">#</a></dt>
<dd><p>Bind config to a Runnable, returning a new Runnable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) – The config to bind to the Runnable.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the config bound.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.with_fallbacks">
<span class="sig-name descname"><span class="pre">with_fallbacks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">fallbacks:</span> <span class="pre">Sequence[Runnable[Input,</span> <span class="pre">Output]],</span> <span class="pre">*,</span> <span class="pre">exceptions_to_handle:</span> <span class="pre">tuple[type[BaseException],</span> <span class="pre">...]</span> <span class="pre">=</span> <span class="pre">(&lt;class</span> <span class="pre">'Exception'&gt;,),</span> <span class="pre">exception_key:</span> <span class="pre">Optional[str]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">RunnableWithFallbacksT</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_fallbacks" title="Link to this definition">#</a></dt>
<dd><p>Add fallbacks to a Runnable, returning a new Runnable.</p>
<p>The new Runnable will try the original Runnable, and then each fallback
in order, upon failures.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fallbacks</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>]</em><em>]</em>) – A sequence of runnables to try if the original Runnable fails.</p></li>
<li><p><strong>exceptions_to_handle</strong> (<em>tuple</em><em>[</em><em>type</em><em>[</em><em>BaseException</em><em>]</em><em>, </em><em>...</em><em>]</em>) – A tuple of exception types to handle.
Defaults to (Exception,).</p></li>
<li><p><strong>exception_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – If string is specified then handled exceptions will be passed
to fallbacks as part of the input under the specified key. If None,
exceptions will not be passed to fallbacks. If used, the base Runnable
and its fallbacks must accept a dictionary as input. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable that will try the original Runnable, and then each
fallback in order, upon failures.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>RunnableWithFallbacksT[Input, Output]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterator</span>

<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableGenerator</span>


<span class="k">def</span> <span class="nf">_generate_immediate_error</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
    <span class="k">yield</span> <span class="s2">""</span>


<span class="k">def</span> <span class="nf">_generate</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">yield from</span> <span class="s2">"foo bar"</span>


<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableGenerator</span><span class="p">(</span><span class="n">_generate_immediate_error</span><span class="p">)</span><span class="o">.</span><span class="n">with_fallbacks</span><span class="p">(</span>
    <span class="p">[</span><span class="n">RunnableGenerator</span><span class="p">(</span><span class="n">_generate</span><span class="p">)]</span>
    <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">runnable</span><span class="o">.</span><span class="n">stream</span><span class="p">({})))</span> <span class="c1">#foo bar</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fallbacks</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>]</em><em>]</em>) – A sequence of runnables to try if the original Runnable fails.</p></li>
<li><p><strong>exceptions_to_handle</strong> (<em>tuple</em><em>[</em><em>type</em><em>[</em><em>BaseException</em><em>]</em><em>, </em><em>...</em><em>]</em>) – A tuple of exception types to handle.</p></li>
<li><p><strong>exception_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – If string is specified then handled exceptions will be passed
to fallbacks as part of the input under the specified key. If None,
exceptions will not be passed to fallbacks. If used, the base Runnable
and its fallbacks must accept a dictionary as input.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable that will try the original Runnable, and then each
fallback in order, upon failures.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>RunnableWithFallbacksT[Input, Output]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.with_listeners">
<span class="sig-name descname"><span class="pre">with_listeners</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_start</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Run</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Run</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_end</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Run</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Run</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_error</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Run</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Run</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_listeners" title="Link to this definition">#</a></dt>
<dd><p>Bind lifecycle listeners to a Runnable, returning a new Runnable.</p>
<p>on_start: Called before the Runnable starts running, with the Run object.
on_end: Called after the Runnable finishes running, with the Run object.
on_error: Called if the Runnable throws an error, with the Run object.</p>
<p>The Run object contains information about the run, including its id,
type, input, output, error, start_time, end_time, and any tags or metadata
added to the run.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>on_start</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Run</em><em>]</em><em>, </em><em>None</em><em>]</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Run</em><em>, </em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em><em>]</em>) – Called before the Runnable starts running. Defaults to None.</p></li>
<li><p><strong>on_end</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Run</em><em>]</em><em>, </em><em>None</em><em>]</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Run</em><em>, </em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em><em>]</em>) – Called after the Runnable finishes running. Defaults to None.</p></li>
<li><p><strong>on_error</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Run</em><em>]</em><em>, </em><em>None</em><em>]</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Run</em><em>, </em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em><em>]</em>) – Called if the Runnable throws an error. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the listeners bound.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable">Runnable</a>[Input, Output]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>
<span class="kn">from</span> <span class="nn">langchain_core.tracers.schemas</span> <span class="kn">import</span> <span class="n">Run</span>

<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">test_runnable</span><span class="p">(</span><span class="n">time_to_sleep</span> <span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">time_to_sleep</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fn_start</span><span class="p">(</span><span class="n">run_obj</span><span class="p">:</span> <span class="n">Run</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"start_time:"</span><span class="p">,</span> <span class="n">run_obj</span><span class="o">.</span><span class="n">start_time</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fn_end</span><span class="p">(</span><span class="n">run_obj</span><span class="p">:</span> <span class="n">Run</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"end_time:"</span><span class="p">,</span> <span class="n">run_obj</span><span class="o">.</span><span class="n">end_time</span><span class="p">)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">test_runnable</span><span class="p">)</span><span class="o">.</span><span class="n">with_listeners</span><span class="p">(</span>
    <span class="n">on_start</span><span class="o">=</span><span class="n">fn_start</span><span class="p">,</span>
    <span class="n">on_end</span><span class="o">=</span><span class="n">fn_end</span>
<span class="p">)</span>
<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.with_retry">
<span class="sig-name descname"><span class="pre">with_retry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*,</span> <span class="pre">retry_if_exception_type:</span> <span class="pre">tuple[type[BaseException],</span> <span class="pre">...]</span> <span class="pre">=</span> <span class="pre">(&lt;class</span> <span class="pre">'Exception'&gt;,),</span> <span class="pre">wait_exponential_jitter:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">stop_after_attempt:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">3</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_retry" title="Link to this definition">#</a></dt>
<dd><p>Create a new Runnable that retries the original Runnable on exceptions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>retry_if_exception_type</strong> (<em>tuple</em><em>[</em><em>type</em><em>[</em><em>BaseException</em><em>]</em><em>, </em><em>...</em><em>]</em>) – A tuple of exception types to retry on.
Defaults to (Exception,).</p></li>
<li><p><strong>wait_exponential_jitter</strong> (<em>bool</em>) – Whether to add jitter to the wait
time between retries. Defaults to True.</p></li>
<li><p><strong>stop_after_attempt</strong> (<em>int</em>) – The maximum number of attempts to make before
giving up. Defaults to 3.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable that retries the original Runnable on exceptions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>


<span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">global</span> <span class="n">count</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"x is 1"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
         <span class="k">pass</span>


<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">runnable</span><span class="o">.</span><span class="n">with_retry</span><span class="p">(</span>
        <span class="n">stop_after_attempt</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">retry_if_exception_type</span><span class="o">=</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">,),</span>
    <span class="p">)</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="k">assert</span> <span class="p">(</span><span class="n">count</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>retry_if_exception_type</strong> (<em>tuple</em><em>[</em><em>type</em><em>[</em><em>BaseException</em><em>]</em><em>, </em><em>...</em><em>]</em>) – A tuple of exception types to retry on</p></li>
<li><p><strong>wait_exponential_jitter</strong> (<em>bool</em>) – Whether to add jitter to the wait time
between retries</p></li>
<li><p><strong>stop_after_attempt</strong> (<em>int</em>) – The maximum number of attempts to make before giving up</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable that retries the original Runnable on exceptions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.with_types">
<span class="sig-name descname"><span class="pre">with_types</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">type</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">type</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_types" title="Link to this definition">#</a></dt>
<dd><p>Bind input and output types to a Runnable, returning a new Runnable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_type</strong> (<em>type</em><em>[</em><em>Input</em><em>] </em><em>| </em><em>None</em>) – The input type to bind to the Runnable. Defaults to None.</p></li>
<li><p><strong>output_type</strong> (<em>type</em><em>[</em><em>Output</em><em>] </em><em>| </em><em>None</em>) – The output type to bind to the Runnable. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the types bound.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<p class="rubric">Examples using ChatPromptTemplate</p>
<ul class="simple">
<li><p><a class="reference external" href="https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain/"># Basic example (short documents)</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain/"># Example</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/versions/migrating_chains/llm_router_chain/"># Legacy</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/aws_dynamodb/">AWS DynamoDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/activeloop/">Activeloop Deep Memory</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/cassandra/">Apache Cassandra</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/aperturedb/">ApertureDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/arxiv/">ArxivRetriever</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/asknews/">AskNews</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/azure_ai_search/">AzureAISearchRetriever</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/azure_chat_openai/">AzureChatOpenAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/chatbot/">Build a Chatbot</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/local_rag/">Build a Local RAG Application</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/pdf_qa/">Build a PDF ingestion and Question/Answering system</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/query_analysis/">Build a Query Analysis System</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/rag/">Build a Retrieval Augmented Generation (RAG) App</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/llm_chain/">Build a Simple LLM Application with LCEL</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/extraction/">Build an Extraction Chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/ai21/">ChatAI21</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/anthropic/">ChatAnthropic</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/bedrock/">ChatBedrock</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/databricks/">ChatDatabricks</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/fireworks/">ChatFireworks</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/google_generative_ai/">ChatGoogleGenerativeAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/groq/">ChatGroq</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/mistralai/">ChatMistralAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/">ChatNVIDIA</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/oci_generative_ai/">ChatOCIGenAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/ollama/">ChatOllama</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/openai/">ChatOpenAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/perplexity/">ChatPerplexity</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/together/">ChatTogether</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/upstage/">ChatUpstage</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/google_vertex_ai_palm/">ChatVertexAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/ibm_watsonx/">ChatWatsonx</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/yi/">ChatYI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/classification/">Classify Text into Labels</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/cohere/">Cohere</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/concepts/">Conceptual guide</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/context/">Context</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/qa_chat_history/">Conversational RAG</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/couchbase_chat_message_history/">Couchbase</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/databricks/">Databricks Unity Catalog (UC)</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/edenai/">Eden AI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/elasticsearch_retriever/">ElasticsearchRetriever</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat_loaders/facebook/">Facebook Messenger</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/fiddler/">Fiddler</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_loaders/figma/">Figma</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/financial_datasets/">FinancialDatasets Toolkit</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/fleet_context/">Fleet AI Context</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/google_alloydb/">Google AlloyDB for PostgreSQL</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/google_el_carro/">Google El Carro Oracle</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/google_sql_mysql/">Google SQL for MySQL</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/google_sql_pg/">Google SQL for PostgreSQL</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/google_sql_mssql/">Google SQL for SQL Server</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/google_vertex_ai_search/">Google Vertex AI Search</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/query_high_cardinality/">How deal with high cardinality categoricals when doing query analysis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/graph_semantic/">How to add a semantic layer over graph database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/tools_prompting/">How to add ad-hoc tool calling capability to LLMs and Chat Models</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/qa_chat_history_how_to/">How to add chat history</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/binding/">How to add default invocation args to a Runnable</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/query_few_shot/">How to add examples to the prompt for query analysis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/fallbacks/">How to add fallbacks to a runnable</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/chatbots_memory/">How to add memory to chatbots</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/message_history/">How to add message history</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/chatbots_retrieval/">How to add retrieval to chatbots</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/chatbots_tools/">How to add tools to chatbots</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/assign/">How to add values to a chain’s state</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/callbacks_attach/">How to attach callbacks to a runnable</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/sequence/">How to chain runnables</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/convert_runnable_to_tool/">How to convert Runnables as Tools</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/custom_llm/">How to create a custom LLM class</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/dynamic_chain/">How to create a dynamic (self-constructing) chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/custom_callbacks/">How to create custom callback handlers</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/custom_tools/">How to create tools</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/sql_large_db/">How to deal with large databases when doing SQL question-answering</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/debugging/">How to debug your LLM apps</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/qa_per_user/">How to do per-user retrieval</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/sql_query_checking/">How to do query validation as part of SQL question-answering</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/sql_csv/">How to do question answering over CSVs</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/function_calling/">How to do tool/function calling</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/qa_citations/">How to get a RAG application to add citations</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/qa_sources/">How to get your RAG application to return sources</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/query_no_queries/">How to handle cases where no queries are generated</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/extraction_long_text/">How to handle long text when doing extraction</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/query_multiple_queries/">How to handle multiple queries when doing query analysis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/query_multiple_retrievers/">How to handle multiple retrievers when doing query analysis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/tools_error/">How to handle tool errors</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/inspect/">How to inspect runnables</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/parallel/">How to invoke runnables in parallel</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/graph_mapping/">How to map values to a graph database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/migrate_agent/">How to migrate from legacy LangChain agents to LangGraph</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/callbacks_runtime/">How to pass callbacks in at runtime</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/passthrough/">How to pass through arguments from one step to the next</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/callbacks_constructor/">How to propagate callbacks  constructor</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/multi_vector/">How to retrieve using multiple vectors per document</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/structured_output/">How to return structured data from a model</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/functions/">How to run custom functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/serialization/">How to save and load LangChain objects</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/tool_stream_events/">How to stream events from a tool</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/qa_streaming/">How to stream results from your RAG application</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/streaming/">How to stream runnables</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/summarize_stuff/">How to summarize text in a single LLM call</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/summarize_refine/">How to summarize text through iterative refinement</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/summarize_map_reduce/">How to summarize text through parallelization</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/chat_token_usage_tracking/">How to track token usage in ChatModels</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/few_shot_examples_chat/">How to use few shot examples in chat models</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/tools_few_shot/">How to use few-shot prompting with tool calling</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/multimodal_prompts/">How to use multimodal prompts</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/extraction_parse/">How to use prompting alone (no tool calling) to do extraction</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/extraction_examples/">How to use reference examples when doing extraction</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/hybrid/">Hybrid Search</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_loaders/image_captions/">Image captions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/jaguar/">Jaguar Vector Database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/jinachat/">JinaChat</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/kinetica/">Kinetica Language To SQL Chat Model</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/how_to/lcel_cheatsheet/">LangChain Expression Language Cheatsheet</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat_loaders/langsmith_llm_runs/">LangSmith LLM Runs</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/llamacpp/">Llama.cpp</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/llama2_chat/">Llama2Chat</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/versions/migrating_chains/conversation_retrieval_chain/">Load docs</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/mlflow_tracking/">MLflow</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/maritalk/">Maritalk</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/mongodb_chat_message_history/">MongoDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/text_embedding/nvidia_ai_endpoints/">NVIDIA NIMs </a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/ollama_functions/">OllamaFunctions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/llms/ollama/">OllamaLLM</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_transformers/openai_metadata_tagger/">OpenAI metadata tagger</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/ragatouille/">RAGatouille</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/redis_chat_message_history/">Redis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/riza/">Riza Code Interpreter</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/sql_chat_message_history/">SQL (SQLAlchemy)</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/sqlite/">SQLite</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/streamlit_chat_message_history/">Streamlit</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/summarization/">Summarize Text</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/tavily_search/">Tavily Search</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/tavily/">TavilySearchAPIRetriever</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/tidb_chat_message_history/">TiDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/uptrain/">UpTrain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/tutorials/retrievers/">Vector stores and retrievers</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/weaviate/">Weaviate</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/wikipedia/">WikipediaRetriever</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/vectorstores/yellowbrick/">Yellowbrick</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/you-retriever/">You.com</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/yuan2/">Yuan2.0</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/zep_cloud_chat_message_history/">ZepCloudChatMessageHistory</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat_loaders/imessage/">iMessage</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/vllm/">vLLM Chat</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/langserve/">🦜️🏓 LangServe</a></p></li>
</ul>
</section>
</article>
</div>
<div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate</span></code></a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.input_types"><code class="docutils literal notranslate"><span class="pre">input_types</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.input_variables"><code class="docutils literal notranslate"><span class="pre">input_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.messages"><code class="docutils literal notranslate"><span class="pre">messages</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.metadata"><code class="docutils literal notranslate"><span class="pre">metadata</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.optional_variables"><code class="docutils literal notranslate"><span class="pre">optional_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.output_parser"><code class="docutils literal notranslate"><span class="pre">output_parser</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.partial_variables"><code class="docutils literal notranslate"><span class="pre">partial_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.tags"><code class="docutils literal notranslate"><span class="pre">tags</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.validate_template"><code class="docutils literal notranslate"><span class="pre">validate_template</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.abatch"><code class="docutils literal notranslate"><span class="pre">abatch()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.abatch_as_completed"><code class="docutils literal notranslate"><span class="pre">abatch_as_completed()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat"><code class="docutils literal notranslate"><span class="pre">aformat()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat_messages"><code class="docutils literal notranslate"><span class="pre">aformat_messages()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat_prompt"><code class="docutils literal notranslate"><span class="pre">aformat_prompt()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.ainvoke"><code class="docutils literal notranslate"><span class="pre">ainvoke()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.append"><code class="docutils literal notranslate"><span class="pre">append()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.astream"><code class="docutils literal notranslate"><span class="pre">astream()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.astream_events"><code class="docutils literal notranslate"><span class="pre">astream_events()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.batch"><code class="docutils literal notranslate"><span class="pre">batch()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.batch_as_completed"><code class="docutils literal notranslate"><span class="pre">batch_as_completed()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.bind"><code class="docutils literal notranslate"><span class="pre">bind()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.configurable_alternatives"><code class="docutils literal notranslate"><span class="pre">configurable_alternatives()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.configurable_fields"><code class="docutils literal notranslate"><span class="pre">configurable_fields()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.extend"><code class="docutils literal notranslate"><span class="pre">extend()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.format"><code class="docutils literal notranslate"><span class="pre">format()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.format_messages"><code class="docutils literal notranslate"><span class="pre">format_messages()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.format_prompt"><code class="docutils literal notranslate"><span class="pre">format_prompt()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_messages"><code class="docutils literal notranslate"><span class="pre">from_messages()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_role_strings"><code class="docutils literal notranslate"><span class="pre">from_role_strings()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_strings"><code class="docutils literal notranslate"><span class="pre">from_strings()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_template"><code class="docutils literal notranslate"><span class="pre">from_template()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.invoke"><code class="docutils literal notranslate"><span class="pre">invoke()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.partial"><code class="docutils literal notranslate"><span class="pre">partial()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.pretty_print"><code class="docutils literal notranslate"><span class="pre">pretty_print()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.pretty_repr"><code class="docutils literal notranslate"><span class="pre">pretty_repr()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.save"><code class="docutils literal notranslate"><span class="pre">save()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.stream"><code class="docutils literal notranslate"><span class="pre">stream()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_alisteners"><code class="docutils literal notranslate"><span class="pre">with_alisteners()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_config"><code class="docutils literal notranslate"><span class="pre">with_config()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_fallbacks"><code class="docutils literal notranslate"><span class="pre">with_fallbacks()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_listeners"><code class="docutils literal notranslate"><span class="pre">with_listeners()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_retry"><code class="docutils literal notranslate"><span class="pre">with_retry()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.with_types"><code class="docutils literal notranslate"><span class="pre">with_types()</span></code></a></li>
</ul>
</li>
</ul>
</nav></div>
</div></div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2023, LangChain Inc.
      <br/>
</p>
</div>
</div>
</div>
</footer>
</body>
</html>