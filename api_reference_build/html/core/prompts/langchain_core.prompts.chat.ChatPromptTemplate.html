
<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>ChatPromptTemplate &#8212; ü¶úüîó LangChain  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'core/prompts/langchain_core.prompts.chat.ChatPromptTemplate';</script>
    <link rel="icon" href="../../_static/favicon.png"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="HumanMessagePromptTemplate" href="langchain_core.prompts.chat.HumanMessagePromptTemplate.html" />
    <link rel="prev" title="ChatMessagePromptTemplate" href="langchain_core.prompts.chat.ChatMessagePromptTemplate.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Aug 09, 2024"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search"
         aria-label="Search"
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/wordmark-api.svg" class="logo__image only-light" alt="ü¶úüîó LangChain  documentation - Home"/>
    <script>document.write(`<img src="../../_static/wordmark-dark-small.png" class="logo__image only-dark" alt="ü¶úüîó LangChain  documentation - Home"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Core
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../langchain/index.html">
    Langchain
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../text_splitters/index.html">
    Text Splitters
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../ai21/index.html">
    AI21
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../airbyte/index.html">
    Airbyte
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    Integrations
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../anthropic/index.html">
    Anthropic
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../astradb/index.html">
    AstraDB
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../aws/index.html">
    AWS
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../azure_dynamic_sessions/index.html">
    Azure Dynamic Sessions
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../chroma/index.html">
    Chroma
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../cohere/index.html">
    Cohere
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../couchbase/index.html">
    Couchbase
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../elasticsearch/index.html">
    Elasticsearch
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../exa/index.html">
    Exa
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../fireworks/index.html">
    Fireworks
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../google_community/index.html">
    Google Community
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../google_genai/index.html">
    Google GenAI
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../google_vertexai/index.html">
    Google VertexAI
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../groq/index.html">
    Groq
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../huggingface/index.html">
    Huggingface
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../milvus/index.html">
    Milvus
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../mistralai/index.html">
    MistralAI
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../mongodb/index.html">
    MongoDB
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../nomic/index.html">
    Nomic
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../nvidia_ai_endpoints/index.html">
    Nvidia Ai Endpoints
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../ollama/index.html">
    Ollama
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../openai/index.html">
    OpenAI
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../pinecone/index.html">
    Pinecone
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../postgres/index.html">
    Postgres
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../prompty/index.html">
    Prompty
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../qdrant/index.html">
    Qdrant
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../robocorp/index.html">
    Robocorp
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../together/index.html">
    Together
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../unstructured/index.html">
    Unstructured
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../voyageai/index.html">
    VoyageAI
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../weaviate/index.html">
    Weaviate
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search"
         aria-label="Search"
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
        </div>
      
      
        <div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
    <style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a href="https://python.langchain.com/" class='text-link'>Docs</a>
</body></div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/langchain-ai/langchain" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/langchainai" title="X / Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-twitter-square fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X / Twitter</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search"
         aria-label="Search"
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Core
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../langchain/index.html">
    Langchain
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../text_splitters/index.html">
    Text Splitters
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../ai21/index.html">
    AI21
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../airbyte/index.html">
    Airbyte
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../anthropic/index.html">
    Anthropic
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../astradb/index.html">
    AstraDB
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../aws/index.html">
    AWS
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../azure_dynamic_sessions/index.html">
    Azure Dynamic Sessions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../chroma/index.html">
    Chroma
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../cohere/index.html">
    Cohere
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../couchbase/index.html">
    Couchbase
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../elasticsearch/index.html">
    Elasticsearch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../exa/index.html">
    Exa
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../fireworks/index.html">
    Fireworks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../google_community/index.html">
    Google Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../google_genai/index.html">
    Google GenAI
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../google_vertexai/index.html">
    Google VertexAI
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../groq/index.html">
    Groq
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../huggingface/index.html">
    Huggingface
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../milvus/index.html">
    Milvus
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../mistralai/index.html">
    MistralAI
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../mongodb/index.html">
    MongoDB
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../nomic/index.html">
    Nomic
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../nvidia_ai_endpoints/index.html">
    Nvidia Ai Endpoints
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../ollama/index.html">
    Ollama
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../openai/index.html">
    OpenAI
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../pinecone/index.html">
    Pinecone
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../postgres/index.html">
    Postgres
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../prompty/index.html">
    Prompty
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../qdrant/index.html">
    Qdrant
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../robocorp/index.html">
    Robocorp
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../together/index.html">
    Together
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../unstructured/index.html">
    Unstructured
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../voyageai/index.html">
    VoyageAI
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../weaviate/index.html">
    Weaviate
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
    <style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a href="https://python.langchain.com/" class='text-link'>Docs</a>
</body></div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/langchain-ai/langchain" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/langchainai" title="X / Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-twitter-square fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X / Twitter</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../agents.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">agents</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../beta.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">beta</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../caches.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">caches</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../callbacks.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">callbacks</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../chat_history.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_history</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../chat_loaders.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_loaders</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../chat_sessions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_sessions</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../document_loaders.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">document_loaders</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../documents.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">documents</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../embeddings.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">embeddings</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../example_selectors.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">example_selectors</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../exceptions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">exceptions</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../globals.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">globals</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../graph_vectorstores.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">graph_vectorstores</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../indexing.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">indexing</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../language_models.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">language_models</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../load.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">load</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">memory</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../messages.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">messages</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../output_parsers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">output_parsers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../outputs.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">outputs</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../prompt_values.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">prompt_values</span></code></a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../prompts.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">prompts</span></code></a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.base.BasePromptTemplate.html">BasePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.chat.AIMessagePromptTemplate.html">AIMessagePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html">BaseChatPromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html">BaseMessagePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.chat.BaseStringMessagePromptTemplate.html">BaseStringMessagePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.chat.ChatMessagePromptTemplate.html">ChatMessagePromptTemplate</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">ChatPromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.chat.HumanMessagePromptTemplate.html">HumanMessagePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.chat.MessagesPlaceholder.html">MessagesPlaceholder</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.chat.SystemMessagePromptTemplate.html">SystemMessagePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html">FewShotChatMessagePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.few_shot.FewShotPromptTemplate.html">FewShotPromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.few_shot_with_templates.FewShotPromptWithTemplates.html">FewShotPromptWithTemplates</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.image.ImagePromptTemplate.html">ImagePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.pipeline.PipelinePromptTemplate.html">PipelinePromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.prompt.PromptTemplate.html">PromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.string.StringPromptTemplate.html">StringPromptTemplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.structured.StructuredPrompt.html">StructuredPrompt</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.base.aformat_document.html">aformat_document</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.base.format_document.html">format_document</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.loading.load_prompt.html">load_prompt</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.loading.load_prompt_from_config.html">load_prompt_from_config</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.string.check_valid_template.html">check_valid_template</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.string.get_template_variables.html">get_template_variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.string.jinja2_formatter.html">jinja2_formatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.string.mustache_formatter.html">mustache_formatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.string.mustache_schema.html">mustache_schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.string.mustache_template_vars.html">mustache_template_vars</a></li>
<li class="toctree-l2"><a class="reference internal" href="langchain_core.prompts.string.validate_jinja2.html">validate_jinja2</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../rate_limiters.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">rate_limiters</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../retrievers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">retrievers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../runnables.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">runnables</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../stores.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">stores</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../structured_query.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">structured_query</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../sys_info.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sys_info</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tools</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../tracers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">tracers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../vectorstores.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">vectorstores</span></code></a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">langchain_core 0.2.29</a></li>
    
    
    <li class="breadcrumb-item"><a href="../prompts.html" class="nav-link"><code class="xref py py-mod docutils literal notranslate"><span class="pre">prompts</span></code></a></li>
    
    <li class="breadcrumb-item active" aria-current="page">ChatPromptTemplate</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="chatprompttemplate">
<h1>ChatPromptTemplate<a class="headerlink" href="#chatprompttemplate" title="Permalink to this heading">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ChatPromptTemplate implements the standard <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Runnable</span> <span class="pre">Interface</span></code></a>. üèÉ</p>
<p>The <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Runnable</span> <span class="pre">Interface</span></code></a> has additional methods that are available on runnables, such as <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_types" title="langchain_core.runnables.base.Runnable.with_types"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_types</span></code></a>, <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_retry" title="langchain_core.runnables.base.Runnable.with_retry"><code class="xref py py-meth docutils literal notranslate"><span class="pre">with_retry</span></code></a>, <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.assign" title="langchain_core.runnables.base.Runnable.assign"><code class="xref py py-meth docutils literal notranslate"><span class="pre">assign</span></code></a>, <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.bind" title="langchain_core.runnables.base.Runnable.bind"><code class="xref py py-meth docutils literal notranslate"><span class="pre">bind</span></code></a>, <a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.get_graph" title="langchain_core.runnables.base.Runnable.get_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_graph</span></code></a>, and more.</p>
</div>
<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain_core.prompts.chat.</span></span><span class="sig-name descname"><span class="pre">ChatPromptTemplate</span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseChatPromptTemplate</span></code></a></p>
<p>Prompt template for chat models.</p>
<p>Use to create flexible templated prompts for chat models.</p>
<p class="rubric">Examples</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.2.24: </span>You can pass any Message-like formats supported by
<code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.from_messages()</span></code> directly to <code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate()</span></code>
init.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are a helpful AI bot. Your name is </span><span class="si">{name}</span><span class="s2">.&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Hello, how are you doing?&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;ai&quot;</span><span class="p">,</span> <span class="s2">&quot;I&#39;m doing well, thanks!&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{user_input}</span><span class="s2">&quot;</span><span class="p">),</span>
<span class="p">])</span>

<span class="n">prompt_value</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Bob&quot;</span><span class="p">,</span>
        <span class="s2">&quot;user_input&quot;</span><span class="p">:</span> <span class="s2">&quot;What is your name?&quot;</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="c1"># Output:</span>
<span class="c1"># ChatPromptValue(</span>
<span class="c1">#    messages=[</span>
<span class="c1">#        SystemMessage(content=&#39;You are a helpful AI bot. Your name is Bob.&#39;),</span>
<span class="c1">#        HumanMessage(content=&#39;Hello, how are you doing?&#39;),</span>
<span class="c1">#        AIMessage(content=&quot;I&#39;m doing well, thanks!&quot;),</span>
<span class="c1">#        HumanMessage(content=&#39;What is your name?&#39;)</span>
<span class="c1">#    ]</span>
<span class="c1">#)</span>
</pre></div>
</div>
<p>Messages Placeholder:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># In addition to Human/AI/Tool/Function messages,</span>
<span class="c1"># you can initialize the template with a MessagesPlaceholder</span>
<span class="c1"># either using the class directly or with the shorthand tuple syntax:</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are a helpful AI bot.&quot;</span><span class="p">),</span>
    <span class="c1"># Means the template will receive an optional list of messages under</span>
    <span class="c1"># the &quot;conversation&quot; key</span>
    <span class="p">(</span><span class="s2">&quot;placeholder&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{conversation}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Equivalently:</span>
    <span class="c1"># MessagesPlaceholder(variable_name=&quot;conversation&quot;, optional=True)</span>
<span class="p">])</span>

<span class="n">prompt_value</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;conversation&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Hi!&quot;</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;ai&quot;</span><span class="p">,</span> <span class="s2">&quot;How can I assist you today?&quot;</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Can you make me an ice cream sundae?&quot;</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;ai&quot;</span><span class="p">,</span> <span class="s2">&quot;No.&quot;</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Output:</span>
<span class="c1"># ChatPromptValue(</span>
<span class="c1">#    messages=[</span>
<span class="c1">#        SystemMessage(content=&#39;You are a helpful AI bot.&#39;),</span>
<span class="c1">#        HumanMessage(content=&#39;Hi!&#39;),</span>
<span class="c1">#        AIMessage(content=&#39;How can I assist you today?&#39;),</span>
<span class="c1">#        HumanMessage(content=&#39;Can you make me an ice cream sundae?&#39;),</span>
<span class="c1">#        AIMessage(content=&#39;No.&#39;),</span>
<span class="c1">#    ]</span>
<span class="c1">#)</span>
</pre></div>
</div>
</div></blockquote>
<p>Single-variable template:</p>
<blockquote>
<div><p>If your prompt has only a single input variable (i.e., 1 instance of ‚Äú{variable_nams}‚Äù),
and you invoke the template with a non-dict object, the prompt template will
inject the provided argument into that variable location.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are a helpful AI bot. Your name is Carl.&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{user_input}</span><span class="s2">&quot;</span><span class="p">),</span>
<span class="p">])</span>

<span class="n">prompt_value</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Hello, there!&quot;</span><span class="p">)</span>
<span class="c1"># Equivalent to</span>
<span class="c1"># prompt_value = template.invoke({&quot;user_input&quot;: &quot;Hello, there!&quot;})</span>

<span class="c1"># Output:</span>
<span class="c1">#  ChatPromptValue(</span>
<span class="c1">#     messages=[</span>
<span class="c1">#         SystemMessage(content=&#39;You are a helpful AI bot. Your name is Carl.&#39;),</span>
<span class="c1">#         HumanMessage(content=&#39;Hello, there!&#39;),</span>
<span class="c1">#     ]</span>
<span class="c1"># )</span>
</pre></div>
</div>
</div></blockquote>
<p>Create a chat prompt template from a variety of message formats.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> ‚Äì sequence of message representations.
A message can be represented using the following formats:
(1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of
(message type, template); e.g., (‚Äúhuman‚Äù, ‚Äú{user_input}‚Äù),
(4) 2-tuple of (message class, template), (5) a string which is
shorthand for (‚Äúhuman‚Äù, template); e.g., ‚Äú{user_input}‚Äù.</p></li>
<li><p><strong>template_format</strong> ‚Äì format of the template. Defaults to ‚Äúf-string‚Äù.</p></li>
<li><p><strong>input_variables</strong> ‚Äì A list of the names of the variables whose values are
required as inputs to the prompt.</p></li>
<li><p><strong>optional_variables</strong> ‚Äì A list of the names of the variables for placeholder</p></li>
<li><p><strong>inferred</strong> (<em>or MessagePlaceholder that are optional. These variables are auto</em>) ‚Äì </p></li>
<li><p><strong>them.</strong> (<em>from the prompt and user need not provide</em>) ‚Äì </p></li>
<li><p><strong>partial_variables</strong> ‚Äì A dictionary of the partial variables the prompt
template carries. Partial variables populate the template so that you
don‚Äôt need to pass them in every time you call the prompt.</p></li>
<li><p><strong>validate_template</strong> ‚Äì Whether to validate the template.</p></li>
<li><p><strong>input_types</strong> ‚Äì A dictionary of the types of the variables the prompt template
expects. If not provided, all variables are assumed to be strings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A chat prompt template.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Instantiation from a list of message templates:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Hello, how are you?&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;ai&quot;</span><span class="p">,</span> <span class="s2">&quot;I&#39;m doing well, thanks!&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;That&#39;s good to hear.&quot;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
<p>Instantiation from mixed message formats:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="p">([</span>
    <span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;hello&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Hello, how are you?&quot;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.input_types">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_types</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.input_types" title="Permalink to this definition">#</a></dt>
<dd><p>A dictionary of the types of the variables the prompt template expects.
If not provided, all variables are assumed to be strings.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.input_variables">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_variables</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.input_variables" title="Permalink to this definition">#</a></dt>
<dd><p>A list of the names of the variables whose values are required as inputs to the
prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.messages">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">messages</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">MessageLike</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.messages" title="Permalink to this definition">#</a></dt>
<dd><p>List of messages consisting of either message prompt templates or messages.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.metadata">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metadata</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.metadata" title="Permalink to this definition">#</a></dt>
<dd><p>Metadata to be used for tracing.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.optional_variables">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">optional_variables</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.optional_variables" title="Permalink to this definition">#</a></dt>
<dd><p>optional_variables: A list of the names of the variables for placeholder
or MessagePlaceholder that are optional. These variables are auto inferred
from the prompt and user need not provide them.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.output_parser">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_parser</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../output_parsers/langchain_core.output_parsers.base.BaseOutputParser.html#langchain_core.output_parsers.base.BaseOutputParser" title="langchain_core.output_parsers.base.BaseOutputParser"><span class="pre">BaseOutputParser</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.output_parser" title="Permalink to this definition">#</a></dt>
<dd><p>How to parse the output of calling an LLM on this formatted prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.partial_variables">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">partial_variables</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.partial_variables" title="Permalink to this definition">#</a></dt>
<dd><p>A dictionary of the partial variables the prompt template carries.</p>
<p>Partial variables populate the template so that you don‚Äôt need to
pass them in every time you call the prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.tags">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tags</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.tags" title="Permalink to this definition">#</a></dt>
<dd><p>Tags to be used for tracing.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.validate_template">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.validate_template" title="Permalink to this definition">#</a></dt>
<dd><p>Whether or not to try validating the template.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.abatch">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">abatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.abatch" title="Permalink to this definition">#</a></dt>
<dd><p>Default implementation runs ainvoke in parallel using asyncio.gather.</p>
<p>The default implementation of batch works well for IO bound runnables.</p>
<p>Subclasses should override this method if they can batch more efficiently;
e.g., if the underlying Runnable uses an API which supports a batch mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>List</em><em>[</em><em>Input</em><em>]</em>) ‚Äì A list of inputs to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>List</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>] </em><em>| </em><em>None</em>) ‚Äì A config to use when invoking the Runnable.
The config supports standard keys like ‚Äòtags‚Äô, ‚Äòmetadata‚Äô for tracing
purposes, ‚Äòmax_concurrency‚Äô for controlling how much work to do
in parallel, and other keys. Please refer to the RunnableConfig
for more details. Defaults to None.</p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) ‚Äì Whether to return exceptions instead of raising them.
Defaults to False.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) ‚Äì Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of outputs from the Runnable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.abatch_as_completed">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">abatch_as_completed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Exception</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.abatch_as_completed" title="Permalink to this definition">#</a></dt>
<dd><p>Run ainvoke in parallel on a list of inputs,
yielding results as they complete.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Sequence</em><em>[</em><em>Input</em><em>]</em>) ‚Äì A list of inputs to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>Sequence</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>] </em><em>| </em><em>None</em>) ‚Äì A config to use when invoking the Runnable.
The config supports standard keys like ‚Äòtags‚Äô, ‚Äòmetadata‚Äô for tracing
purposes, ‚Äòmax_concurrency‚Äô for controlling how much work to do
in parallel, and other keys. Please refer to the RunnableConfig
for more details. Defaults to None. Defaults to None.</p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) ‚Äì Whether to return exceptions instead of raising them.
Defaults to False.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) ‚Äì Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple of the index of the input and the output from the Runnable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>AsyncIterator</em>[<em>Tuple</em>[int, <em>Output</em> | Exception]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.aformat">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aformat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat" title="Permalink to this definition">#</a></dt>
<dd><p>Async format the chat template into a string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì keyword arguments to use for filling in template variables
in all the template messages in this chat template.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>formatted string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.aformat_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aformat_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.aformat_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat_messages" title="Permalink to this definition">#</a></dt>
<dd><p>Async format the chat template into a list of finalized messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì keyword arguments to use for filling in template variables
in all the template messages in this chat template.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of formatted messages.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> ‚Äì If unexpected input.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.aformat_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aformat_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat_prompt" title="Permalink to this definition">#</a></dt>
<dd><p>Async format prompt. Should return a PromptValue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì Keyword arguments to use for formatting.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>PromptValue.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.ainvoke">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ainvoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.ainvoke" title="Permalink to this definition">#</a></dt>
<dd><p>Async invoke the prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Dict</em>) ‚Äì Dict, input to the prompt.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) ‚Äì RunnableConfig, configuration for the prompt.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the prompt.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue">PromptValue</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.append">
<span class="sig-name descname"><span class="pre">append</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><span class="pre">BaseMessagePromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><span class="pre">BaseChatPromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.append"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.append" title="Permalink to this definition">#</a></dt>
<dd><p>Append a message to the end of the chat template.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>message</strong> (<a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><em>BaseMessagePromptTemplate</em></a><em> | </em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em> | </em><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><em>BaseChatPromptTemplate</em></a><em> | </em><em>Tuple</em><em>[</em><em>str</em><em> | </em><em>Type</em><em>, </em><em>str</em><em> | </em><em>List</em><em>[</em><em>dict</em><em>] </em><em>| </em><em>List</em><em>[</em><em>object</em><em>]</em><em>] </em><em>| </em><em>str</em>) ‚Äì representation of a message to append.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.as_tool">
<span class="sig-name descname"><span class="pre">as_tool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args_schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../tools/langchain_core.tools.base.BaseTool.html#langchain_core.tools.base.BaseTool" title="langchain_core.tools.base.BaseTool"><span class="pre">BaseTool</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.as_tool" title="Permalink to this definition">#</a></dt>
<dd><div class="admonition-beta admonition">
<p class="admonition-title">Beta</p>
<p>This API is in beta and may change in the future.</p>
</div>
<p>Create a BaseTool from a Runnable.</p>
<p><code class="docutils literal notranslate"><span class="pre">as_tool</span></code> will instantiate a BaseTool with a name, description, and
<code class="docutils literal notranslate"><span class="pre">args_schema</span></code> from a Runnable. Where possible, schemas are inferred
from <code class="docutils literal notranslate"><span class="pre">runnable.get_input_schema</span></code>. Alternatively (e.g., if the
Runnable takes a dict as input and the specific dict keys are not typed),
the schema can be specified directly with <code class="docutils literal notranslate"><span class="pre">args_schema</span></code>. You can also
pass <code class="docutils literal notranslate"><span class="pre">arg_types</span></code> to just specify the required arguments and their types.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args_schema</strong> (<em>Optional</em><em>[</em><em>Type</em><em>[</em><em>BaseModel</em><em>]</em><em>]</em>) ‚Äì The schema for the tool. Defaults to None.</p></li>
<li><p><strong>name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) ‚Äì The name of the tool. Defaults to None.</p></li>
<li><p><strong>description</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) ‚Äì The description of the tool. Defaults to None.</p></li>
<li><p><strong>arg_types</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Type</em><em>]</em><em>]</em>) ‚Äì A dictionary of argument names to types. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A BaseTool instance.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../tools/langchain_core.tools.base.BaseTool.html#langchain_core.tools.base.BaseTool" title="langchain_core.tools.base.BaseTool">BaseTool</a></p>
</dd>
</dl>
<p>Typed dict input:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">typing_extensions</span> <span class="kn">import</span> <span class="n">TypedDict</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">class</span> <span class="nc">Args</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
    <span class="n">a</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]))</span>

<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">as_tool</span> <span class="o">=</span> <span class="n">runnable</span><span class="o">.</span><span class="n">as_tool</span><span class="p">()</span>
<span class="n">as_tool</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]})</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">dict</span></code> input, specifying schema via <code class="docutils literal notranslate"><span class="pre">args_schema</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]))</span>

<span class="k">class</span> <span class="nc">FSchema</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply a function to an integer and list of integers.&quot;&quot;&quot;</span>

    <span class="n">a</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Integer&quot;</span><span class="p">)</span>
    <span class="n">b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;List of ints&quot;</span><span class="p">)</span>

<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">as_tool</span> <span class="o">=</span> <span class="n">runnable</span><span class="o">.</span><span class="n">as_tool</span><span class="p">(</span><span class="n">FSchema</span><span class="p">)</span>
<span class="n">as_tool</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]})</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">dict</span></code> input, specifying schema via <code class="docutils literal notranslate"><span class="pre">arg_types</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]))</span>

<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">as_tool</span> <span class="o">=</span> <span class="n">runnable</span><span class="o">.</span><span class="n">as_tool</span><span class="p">(</span><span class="n">arg_types</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]})</span>
<span class="n">as_tool</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]})</span>
</pre></div>
</div>
<p>String input:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="s2">&quot;a&quot;</span>

<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="s2">&quot;z&quot;</span>

<span class="n">runnable</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="o">|</span> <span class="n">g</span>
<span class="n">as_tool</span> <span class="o">=</span> <span class="n">runnable</span><span class="o">.</span><span class="n">as_tool</span><span class="p">()</span>
<span class="n">as_tool</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.2.14.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.astream">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">astream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.astream" title="Permalink to this definition">#</a></dt>
<dd><p>Default implementation of astream, which calls ainvoke.
Subclasses should override this method if they support streaming output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Input</em>) ‚Äì The input to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) ‚Äì The config to use for the Runnable. Defaults to None.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) ‚Äì Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the Runnable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>AsyncIterator</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.astream_events">
<span class="sig-name descname"><span class="pre">astream_events</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'v1'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'v2'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_types</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.schema.StandardStreamEvent.html#langchain_core.runnables.schema.StandardStreamEvent" title="langchain_core.runnables.schema.StandardStreamEvent"><span class="pre">StandardStreamEvent</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.schema.CustomStreamEvent.html#langchain_core.runnables.schema.CustomStreamEvent" title="langchain_core.runnables.schema.CustomStreamEvent"><span class="pre">CustomStreamEvent</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.astream_events" title="Permalink to this definition">#</a></dt>
<dd><div class="admonition-beta admonition">
<p class="admonition-title">Beta</p>
<p>This API is in beta and may change in the future.</p>
</div>
<p>Generate a stream of events.</p>
<p>Use to create an iterator over StreamEvents that provide real-time information
about the progress of the Runnable, including StreamEvents from intermediate
results.</p>
<p>A StreamEvent is a dictionary with the following schema:</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">event</span></code>: <strong>str</strong> - Event names are of the</dt><dd><p>format: on_[runnable_type]_(start|stream|end).</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: <strong>str</strong> - The name of the Runnable that generated the event.</p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">run_id</span></code>: <strong>str</strong> - randomly generated ID associated with the given execution of</dt><dd><p>the Runnable that emitted the event.
A child Runnable that gets invoked as part of the execution of a
parent Runnable is assigned its own unique ID.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">parent_ids</span></code>: <strong>List[str]</strong> - The IDs of the parent runnables that</dt><dd><p>generated the event. The root Runnable will have an empty list.
The order of the parent IDs is from the root to the immediate parent.
Only available for v2 version of the API. The v1 version of the API
will return an empty list.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">tags</span></code>: <strong>Optional[List[str]]</strong> - The tags of the Runnable that generated</dt><dd><p>the event.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">metadata</span></code>: <strong>Optional[Dict[str, Any]]</strong> - The metadata of the Runnable</dt><dd><p>that generated the event.</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: <strong>Dict[str, Any]</strong></p></li>
</ul>
<p>Below is a table that illustrates some evens that might be emitted by various
chains. Metadata fields have been omitted from the table for brevity.
Chain definitions have been included after the table.</p>
<p><strong>ATTENTION</strong> This reference table is for the V2 version of the schema.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>event</p></th>
<th class="head"><p>name</p></th>
<th class="head"><p>chunk</p></th>
<th class="head"><p>input</p></th>
<th class="head"><p>output</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>on_chat_model_start</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{‚Äúmessages‚Äù: [[SystemMessage, HumanMessage]]}</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_chat_model_stream</p></td>
<td><p>[model name]</p></td>
<td><p>AIMessageChunk(content=‚Äùhello‚Äù)</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chat_model_end</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{‚Äúmessages‚Äù: [[SystemMessage, HumanMessage]]}</p></td>
<td><p>AIMessageChunk(content=‚Äùhello world‚Äù)</p></td>
</tr>
<tr class="row-odd"><td><p>on_llm_start</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>{‚Äòinput‚Äô: ‚Äòhello‚Äô}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_llm_stream</p></td>
<td><p>[model name]</p></td>
<td><p>‚ÄòHello‚Äô</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_llm_end</p></td>
<td><p>[model name]</p></td>
<td></td>
<td><p>‚ÄòHello human!‚Äô</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chain_start</p></td>
<td><p>format_docs</p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>on_chain_stream</p></td>
<td><p>format_docs</p></td>
<td><p>‚Äúhello world!, goodbye world!‚Äù</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_chain_end</p></td>
<td><p>format_docs</p></td>
<td></td>
<td><p>[Document(‚Ä¶)]</p></td>
<td><p>‚Äúhello world!, goodbye world!‚Äù</p></td>
</tr>
<tr class="row-odd"><td><p>on_tool_start</p></td>
<td><p>some_tool</p></td>
<td></td>
<td><p>{‚Äúx‚Äù: 1, ‚Äúy‚Äù: ‚Äú2‚Äù}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_tool_end</p></td>
<td><p>some_tool</p></td>
<td></td>
<td></td>
<td><p>{‚Äúx‚Äù: 1, ‚Äúy‚Äù: ‚Äú2‚Äù}</p></td>
</tr>
<tr class="row-odd"><td><p>on_retriever_start</p></td>
<td><p>[retriever name]</p></td>
<td></td>
<td><p>{‚Äúquery‚Äù: ‚Äúhello‚Äù}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_retriever_end</p></td>
<td><p>[retriever name]</p></td>
<td></td>
<td><p>{‚Äúquery‚Äù: ‚Äúhello‚Äù}</p></td>
<td><p>[Document(‚Ä¶), ..]</p></td>
</tr>
<tr class="row-odd"><td><p>on_prompt_start</p></td>
<td><p>[template_name]</p></td>
<td></td>
<td><p>{‚Äúquestion‚Äù: ‚Äúhello‚Äù}</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>on_prompt_end</p></td>
<td><p>[template_name]</p></td>
<td></td>
<td><p>{‚Äúquestion‚Äù: ‚Äúhello‚Äù}</p></td>
<td><p>ChatPromptValue(messages: [SystemMessage, ‚Ä¶])</p></td>
</tr>
</tbody>
</table>
</div>
<p>In addition to the standard events, users can also dispatch custom events (see example below).</p>
<p>Custom events will be only be surfaced with in the <cite>v2</cite> version of the API!</p>
<p>A custom event has following format:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>name</p></td>
<td><p>str</p></td>
<td><p>A user defined name for the event.</p></td>
</tr>
<tr class="row-odd"><td><p>data</p></td>
<td><p>Any</p></td>
<td><p>The data associated with the event. This can be anything, though we suggest making it JSON serializable.</p></td>
</tr>
</tbody>
</table>
</div>
<p>Here are declarations associated with the standard events shown above:</p>
<p><cite>format_docs</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">format_docs</span><span class="p">(</span><span class="n">docs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Format the docs.&#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">])</span>

<span class="n">format_docs</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">format_docs</span><span class="p">)</span>
</pre></div>
</div>
<p><cite>some_tool</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@tool</span>
<span class="k">def</span> <span class="nf">some_tool</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Some_tool.&#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">}</span>
</pre></div>
</div>
<p><cite>prompt</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are Cat Agent 007&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{question}</span><span class="s2">&quot;</span><span class="p">)]</span>
<span class="p">)</span><span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;run_name&quot;</span><span class="p">:</span> <span class="s2">&quot;my_template&quot;</span><span class="p">,</span> <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;my_template&quot;</span><span class="p">]})</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">reverse</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">s</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">reverse</span><span class="p">)</span>

<span class="n">events</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">event</span> <span class="k">async</span> <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">chain</span><span class="o">.</span><span class="n">astream_events</span><span class="p">(</span><span class="s2">&quot;hello&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="s2">&quot;v2&quot;</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># will produce the following events (run_id, and parent_ids</span>
<span class="c1"># has been omitted for brevity):</span>
<span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;hello&quot;</span><span class="p">},</span>
        <span class="s2">&quot;event&quot;</span><span class="p">:</span> <span class="s2">&quot;on_chain_start&quot;</span><span class="p">,</span>
        <span class="s2">&quot;metadata&quot;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;chunk&quot;</span><span class="p">:</span> <span class="s2">&quot;olleh&quot;</span><span class="p">},</span>
        <span class="s2">&quot;event&quot;</span><span class="p">:</span> <span class="s2">&quot;on_chain_stream&quot;</span><span class="p">,</span>
        <span class="s2">&quot;metadata&quot;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;olleh&quot;</span><span class="p">},</span>
        <span class="s2">&quot;event&quot;</span><span class="p">:</span> <span class="s2">&quot;on_chain_end&quot;</span><span class="p">,</span>
        <span class="s2">&quot;metadata&quot;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tags&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">},</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Example: Dispatch Custom Event</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.callbacks.manager</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">adispatch_custom_event</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span><span class="p">,</span> <span class="n">RunnableConfig</span>
<span class="kn">import</span> <span class="nn">asyncio</span>


<span class="k">async</span> <span class="k">def</span> <span class="nf">slow_thing</span><span class="p">(</span><span class="n">some_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">RunnableConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Do something that takes a long time.&quot;&quot;&quot;</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Placeholder for some slow operation</span>
    <span class="k">await</span> <span class="n">adispatch_custom_event</span><span class="p">(</span>
        <span class="s2">&quot;progress_event&quot;</span><span class="p">,</span>
        <span class="p">{</span><span class="s2">&quot;message&quot;</span><span class="p">:</span> <span class="s2">&quot;Finished step 1 of 3&quot;</span><span class="p">},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span> <span class="c1"># Must be included for python &lt; 3.10</span>
    <span class="p">)</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Placeholder for some slow operation</span>
    <span class="k">await</span> <span class="n">adispatch_custom_event</span><span class="p">(</span>
        <span class="s2">&quot;progress_event&quot;</span><span class="p">,</span>
        <span class="p">{</span><span class="s2">&quot;message&quot;</span><span class="p">:</span> <span class="s2">&quot;Finished step 2 of 3&quot;</span><span class="p">},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span> <span class="c1"># Must be included for python &lt; 3.10</span>
    <span class="p">)</span>
    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Placeholder for some slow operation</span>
    <span class="k">return</span> <span class="s2">&quot;Done&quot;</span>

<span class="n">slow_thing</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">slow_thing</span><span class="p">)</span>

<span class="k">async</span> <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="n">slow_thing</span><span class="o">.</span><span class="n">astream_events</span><span class="p">(</span><span class="s2">&quot;some_input&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="s2">&quot;v2&quot;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Any</em>) ‚Äì The input to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) ‚Äì The config to use for the Runnable.</p></li>
<li><p><strong>version</strong> (<em>Literal</em><em>[</em><em>'v1'</em><em>, </em><em>'v2'</em><em>]</em>) ‚Äì The version of the schema to use either <cite>v2</cite> or <cite>v1</cite>.
Users should use <cite>v2</cite>.
<cite>v1</cite> is for backwards compatibility and will be deprecated
in 0.4.0.
No default will be assigned until the API is stabilized.
custom events will only be surfaced in <cite>v2</cite>.</p></li>
<li><p><strong>include_names</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) ‚Äì Only include events from runnables with matching names.</p></li>
<li><p><strong>include_types</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) ‚Äì Only include events from runnables with matching types.</p></li>
<li><p><strong>include_tags</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) ‚Äì Only include events from runnables with matching tags.</p></li>
<li><p><strong>exclude_names</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) ‚Äì Exclude events from runnables with matching names.</p></li>
<li><p><strong>exclude_types</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) ‚Äì Exclude events from runnables with matching types.</p></li>
<li><p><strong>exclude_tags</strong> (<em>Sequence</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) ‚Äì Exclude events from runnables with matching tags.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì Additional keyword arguments to pass to the Runnable.
These will be passed to astream_log as this implementation
of astream_events is built on top of astream_log.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p>An async stream of StreamEvents.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>NotImplementedError</strong> ‚Äì If the version is not <cite>v1</cite> or <cite>v2</cite>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>AsyncIterator</em>[<a class="reference internal" href="../runnables/langchain_core.runnables.schema.StandardStreamEvent.html#langchain_core.runnables.schema.StandardStreamEvent" title="langchain_core.runnables.schema.StandardStreamEvent"><em>StandardStreamEvent</em></a> | <a class="reference internal" href="../runnables/langchain_core.runnables.schema.CustomStreamEvent.html#langchain_core.runnables.schema.CustomStreamEvent" title="langchain_core.runnables.schema.CustomStreamEvent"><em>CustomStreamEvent</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.batch">
<span class="sig-name descname"><span class="pre">batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.batch" title="Permalink to this definition">#</a></dt>
<dd><p>Default implementation runs invoke in parallel using a thread pool executor.</p>
<p>The default implementation of batch works well for IO bound runnables.</p>
<p>Subclasses should override this method if they can batch more efficiently;
e.g., if the underlying Runnable uses an API which supports a batch mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>List</em><em>[</em><em>Input</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>List</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>] </em><em>| </em><em>None</em>) ‚Äì </p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.batch_as_completed">
<span class="sig-name descname"><span class="pre">batch_as_completed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_exceptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Exception</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.batch_as_completed" title="Permalink to this definition">#</a></dt>
<dd><p>Run invoke in parallel on a list of inputs,
yielding results as they complete.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Sequence</em><em>[</em><em>Input</em><em>]</em>) ‚Äì </p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>Sequence</em><em>[</em><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em>] </em><em>| </em><em>None</em>) ‚Äì </p></li>
<li><p><strong>return_exceptions</strong> (<em>bool</em>) ‚Äì </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) ‚Äì </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Iterator</em>[<em>Tuple</em>[int, <em>Output</em> | Exception]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.configurable_alternatives">
<span class="sig-name descname"><span class="pre">configurable_alternatives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">which</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><span class="pre">ConfigurableField</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.configurable_alternatives" title="Permalink to this definition">#</a></dt>
<dd><p>Configure alternatives for Runnables that can be set at runtime.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>which</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><em>ConfigurableField</em></a>) ‚Äì The ConfigurableField instance that will be used to select the
alternative.</p></li>
<li><p><strong>default_key</strong> (<em>str</em>) ‚Äì The default key to use if no alternative is selected.
Defaults to ‚Äúdefault‚Äù.</p></li>
<li><p><strong>prefix_keys</strong> (<em>bool</em>) ‚Äì Whether to prefix the keys with the ConfigurableField id.
Defaults to False.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>] </em><em>| </em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a><em>[</em><em>Input</em><em>, </em><em>Output</em><em>]</em><em>]</em>) ‚Äì A dictionary of keys to Runnable instances or callables that
return Runnable instances.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the alternatives configured.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_anthropic</span> <span class="kn">import</span> <span class="n">ChatAnthropic</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables.utils</span> <span class="kn">import</span> <span class="n">ConfigurableField</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatAnthropic</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;claude-3-sonnet-20240229&quot;</span>
<span class="p">)</span><span class="o">.</span><span class="n">configurable_alternatives</span><span class="p">(</span>
    <span class="n">ConfigurableField</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;llm&quot;</span><span class="p">),</span>
    <span class="n">default_key</span><span class="o">=</span><span class="s2">&quot;anthropic&quot;</span><span class="p">,</span>
    <span class="n">openai</span><span class="o">=</span><span class="n">ChatOpenAI</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># uses the default model ChatAnthropic</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;which organization created you?&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="c1"># uses ChatOpenAI</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
        <span class="n">configurable</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;llm&quot;</span><span class="p">:</span> <span class="s2">&quot;openai&quot;</span><span class="p">}</span>
    <span class="p">)</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;which organization created you?&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.configurable_fields">
<span class="sig-name descname"><span class="pre">configurable_fields</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><span class="pre">ConfigurableField</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldSingleOption.html#langchain_core.runnables.utils.ConfigurableFieldSingleOption" title="langchain_core.runnables.utils.ConfigurableFieldSingleOption"><span class="pre">ConfigurableFieldSingleOption</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldMultiOption.html#langchain_core.runnables.utils.ConfigurableFieldMultiOption" title="langchain_core.runnables.utils.ConfigurableFieldMultiOption"><span class="pre">ConfigurableFieldMultiOption</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><span class="pre">RunnableSerializable</span></a><span class="p"><span class="pre">[</span></span><span class="pre">Input</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.configurable_fields" title="Permalink to this definition">#</a></dt>
<dd><p>Configure particular Runnable fields at runtime.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField" title="langchain_core.runnables.utils.ConfigurableField"><em>ConfigurableField</em></a><em> | </em><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldSingleOption.html#langchain_core.runnables.utils.ConfigurableFieldSingleOption" title="langchain_core.runnables.utils.ConfigurableFieldSingleOption"><em>ConfigurableFieldSingleOption</em></a><em> | </em><a class="reference internal" href="../runnables/langchain_core.runnables.utils.ConfigurableFieldMultiOption.html#langchain_core.runnables.utils.ConfigurableFieldMultiOption" title="langchain_core.runnables.utils.ConfigurableFieldMultiOption"><em>ConfigurableFieldMultiOption</em></a>) ‚Äì A dictionary of ConfigurableField instances to configure.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new Runnable with the fields configured.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable" title="langchain_core.runnables.base.RunnableSerializable"><em>RunnableSerializable</em></a>[<em>Input</em>, <em>Output</em>]</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">ConfigurableField</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">configurable_fields</span><span class="p">(</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="n">ConfigurableField</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;output_token_number&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Max tokens in the output&quot;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The maximum number of tokens in the output&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># max_tokens = 20</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;max_tokens_20: &quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;tell me something about chess&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>

<span class="c1"># max_tokens = 200</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;max_tokens_200: &quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">with_config</span><span class="p">(</span>
    <span class="n">configurable</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;output_token_number&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}</span>
    <span class="p">)</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;tell me something about chess&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">content</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.extend">
<span class="sig-name descname"><span class="pre">extend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><span class="pre">BaseMessagePromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><span class="pre">BaseChatPromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.extend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.extend" title="Permalink to this definition">#</a></dt>
<dd><p>Extend the chat template with a sequence of messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><em>BaseMessagePromptTemplate</em></a><em> | </em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em> | </em><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><em>BaseChatPromptTemplate</em></a><em> | </em><em>Tuple</em><em>[</em><em>str</em><em> | </em><em>Type</em><em>, </em><em>str</em><em> | </em><em>List</em><em>[</em><em>dict</em><em>] </em><em>| </em><em>List</em><em>[</em><em>object</em><em>]</em><em>] </em><em>| </em><em>str</em><em>]</em>) ‚Äì sequence of message representations to append.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.format">
<span class="sig-name descname"><span class="pre">format</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.format" title="Permalink to this definition">#</a></dt>
<dd><p>Format the chat template into a string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì keyword arguments to use for filling in template variables
in all the template messages in this chat template.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>formatted string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.format_messages">
<span class="sig-name descname"><span class="pre">format_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.format_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.format_messages" title="Permalink to this definition">#</a></dt>
<dd><p>Format the chat template into a list of finalized messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì keyword arguments to use for filling in template variables
in all the template messages in this chat template.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of formatted messages.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.format_prompt">
<span class="sig-name descname"><span class="pre">format_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.format_prompt" title="Permalink to this definition">#</a></dt>
<dd><p>Format prompt. Should return a PromptValue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì Keyword arguments to use for formatting.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>PromptValue.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><em>PromptValue</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.from_messages">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><span class="pre">BaseMessagePromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><span class="pre">BaseMessage</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><span class="pre">BaseChatPromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">object</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">template_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'f-string'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'mustache'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'jinja2'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'f-string'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.from_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_messages" title="Permalink to this definition">#</a></dt>
<dd><p>Create a chat prompt template from a variety of message formats.</p>
<p class="rubric">Examples</p>
<p>Instantiation from a list of message templates:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Hello, how are you?&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;ai&quot;</span><span class="p">,</span> <span class="s2">&quot;I&#39;m doing well, thanks!&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;That&#39;s good to hear.&quot;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
<p>Instantiation from mixed message formats:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span>
    <span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;hello&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Hello, how are you?&quot;</span><span class="p">),</span>
<span class="p">])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><em>BaseMessagePromptTemplate</em></a><em> | </em><a class="reference internal" href="../messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage" title="langchain_core.messages.base.BaseMessage"><em>BaseMessage</em></a><em> | </em><a class="reference internal" href="langchain_core.prompts.chat.BaseChatPromptTemplate.html#langchain_core.prompts.chat.BaseChatPromptTemplate" title="langchain_core.prompts.chat.BaseChatPromptTemplate"><em>BaseChatPromptTemplate</em></a><em> | </em><em>Tuple</em><em>[</em><em>str</em><em> | </em><em>Type</em><em>, </em><em>str</em><em> | </em><em>List</em><em>[</em><em>dict</em><em>] </em><em>| </em><em>List</em><em>[</em><em>object</em><em>]</em><em>] </em><em>| </em><em>str</em><em>]</em>) ‚Äì sequence of message representations.
A message can be represented using the following formats:
(1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of
(message type, template); e.g., (‚Äúhuman‚Äù, ‚Äú{user_input}‚Äù),
(4) 2-tuple of (message class, template), (4) a string which is
shorthand for (‚Äúhuman‚Äù, template); e.g., ‚Äú{user_input}‚Äù.</p></li>
<li><p><strong>template_format</strong> (<em>Literal</em><em>[</em><em>'f-string'</em><em>, </em><em>'mustache'</em><em>, </em><em>'jinja2'</em><em>]</em>) ‚Äì format of the template. Defaults to ‚Äúf-string‚Äù.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a chat prompt template.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.from_role_strings">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_role_strings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">string_messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.from_role_strings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_role_strings" title="Permalink to this definition">#</a></dt>
<dd><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.0.1: </span>Use <code class="docutils literal notranslate"><span class="pre">from_messages</span> <span class="pre">classmethod</span></code> instead.</p>
</div>
<p>Create a chat prompt template from a list of (role, template) tuples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>string_messages</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) ‚Äì list of (role, template) tuples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a chat prompt template.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.from_strings">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_strings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">string_messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><span class="pre">BaseMessagePromptTemplate</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.from_strings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_strings" title="Permalink to this definition">#</a></dt>
<dd><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version langchain-core==0.0.1: </span>Use <code class="docutils literal notranslate"><span class="pre">from_messages</span> <span class="pre">classmethod</span></code> instead.</p>
</div>
<p>Create a chat prompt template from a list of (role class, template) tuples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>string_messages</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Type</em><em>[</em><a class="reference internal" href="langchain_core.prompts.chat.BaseMessagePromptTemplate.html#langchain_core.prompts.chat.BaseMessagePromptTemplate" title="langchain_core.prompts.chat.BaseMessagePromptTemplate"><em>BaseMessagePromptTemplate</em></a><em>]</em><em>, </em><em>str</em><em>]</em><em>]</em>) ‚Äì list of (role class, template) tuples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a chat prompt template.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.from_template">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_template</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">template</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.from_template"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_template" title="Permalink to this definition">#</a></dt>
<dd><p>Create a chat prompt template from a template string.</p>
<p>Creates a chat template consisting of a single message assumed to be from
the human.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>template</strong> (<em>str</em>) ‚Äì template string</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì keyword arguments to pass to the constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new instance of this class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.invoke">
<span class="sig-name descname"><span class="pre">invoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue"><span class="pre">PromptValue</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.invoke" title="Permalink to this definition">#</a></dt>
<dd><p>Invoke the prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Dict</em>) ‚Äì Dict, input to the prompt.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) ‚Äì RunnableConfig, configuration for the prompt.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the prompt.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../prompt_values/langchain_core.prompt_values.PromptValue.html#langchain_core.prompt_values.PromptValue" title="langchain_core.prompt_values.PromptValue">PromptValue</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.partial">
<span class="sig-name descname"><span class="pre">partial</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><span class="pre">ChatPromptTemplate</span></a></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.partial"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.partial" title="Permalink to this definition">#</a></dt>
<dd><p>Get a new ChatPromptTemplate with some input variables already filled in.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>Any</em>) ‚Äì keyword arguments to use for filling in template variables. Ought
to be a subset of the input variables.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new ChatPromptTemplate.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#langchain_core.prompts.chat.ChatPromptTemplate" title="langchain_core.prompts.chat.ChatPromptTemplate"><em>ChatPromptTemplate</em></a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are an AI assistant named </span><span class="si">{name}</span><span class="s2">.&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;Hi I&#39;m </span><span class="si">{user}</span><span class="s2">&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;ai&quot;</span><span class="p">,</span> <span class="s2">&quot;Hi there, </span><span class="si">{user}</span><span class="s2">, I&#39;m </span><span class="si">{name}</span><span class="s2">.&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">template2</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">user</span><span class="o">=</span><span class="s2">&quot;Lucy&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;R2D2&quot;</span><span class="p">)</span>

<span class="n">template2</span><span class="o">.</span><span class="n">format_messages</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;hello&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.pretty_print">
<span class="sig-name descname"><span class="pre">pretty_print</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.pretty_print" title="Permalink to this definition">#</a></dt>
<dd><p>Print a human-readable representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.pretty_repr">
<span class="sig-name descname"><span class="pre">pretty_repr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">html</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.pretty_repr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.pretty_repr" title="Permalink to this definition">#</a></dt>
<dd><p>Human-readable representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>html</strong> (<em>bool</em>) ‚Äì Whether to format as HTML. Defaults to False.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Human-readable representation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Path</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../../_modules/langchain_core/prompts/chat.html#ChatPromptTemplate.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.save" title="Permalink to this definition">#</a></dt>
<dd><p>Save prompt to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Path</em><em> | </em><em>str</em>) ‚Äì path to file.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Output</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.stream" title="Permalink to this definition">#</a></dt>
<dd><p>Default implementation of stream, which calls invoke.
Subclasses should override this method if they support streaming output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Input</em>) ‚Äì The input to the Runnable.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig" title="langchain_core.runnables.config.RunnableConfig"><em>RunnableConfig</em></a><em> | </em><em>None</em>) ‚Äì The config to use for the Runnable. Defaults to None.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em><em> | </em><em>None</em>) ‚Äì Additional keyword arguments to pass to the Runnable.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p>The output of the Runnable.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Iterator</em>[<em>Output</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain_core.prompts.chat.ChatPromptTemplate.to_json">
<span class="sig-name descname"><span class="pre">to_json</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../load/langchain_core.load.serializable.SerializedConstructor.html#langchain_core.load.serializable.SerializedConstructor" title="langchain_core.load.serializable.SerializedConstructor"><span class="pre">SerializedConstructor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../load/langchain_core.load.serializable.SerializedNotImplemented.html#langchain_core.load.serializable.SerializedNotImplemented" title="langchain_core.load.serializable.SerializedNotImplemented"><span class="pre">SerializedNotImplemented</span></a></span></span><a class="headerlink" href="#langchain_core.prompts.chat.ChatPromptTemplate.to_json" title="Permalink to this definition">#</a></dt>
<dd><p>Serialize the Runnable to JSON.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A JSON-serializable representation of the Runnable.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="../load/langchain_core.load.serializable.SerializedConstructor.html#langchain_core.load.serializable.SerializedConstructor" title="langchain_core.load.serializable.SerializedConstructor"><em>SerializedConstructor</em></a> | <a class="reference internal" href="../load/langchain_core.load.serializable.SerializedNotImplemented.html#langchain_core.load.serializable.SerializedNotImplemented" title="langchain_core.load.serializable.SerializedNotImplemented"><em>SerializedNotImplemented</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<h1>Examples using ChatPromptTemplate<a class="headerlink" href="#chatprompttemplate" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/aws_dynamodb/">AWS DynamoDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/activeloop/">Activeloop Deep Memory</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/cassandra/">Apache Cassandra</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/asknews/">AskNews</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/astradb/">Astra DB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/chatbot/">Build a Chatbot</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/query_analysis/">Build a Query Analysis System</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/rag/">Build a Retrieval Augmented Generation (RAG) App</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/llm_chain/">Build a Simple LLM Application</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/extraction/">Build an Extraction Chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/ai21/">ChatAI21</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/anthropic/">ChatAnthropic</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/ollama/">ChatOllama</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/openai/">ChatOpenAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/">ChatPerplexity</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/upstage/">ChatUpstage</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/google_vertex_ai_palm/">ChatVertexAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/classification/">Classify Text into Labels</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/providers/cohere/">Cohere</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/concepts/">Conceptual guide</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/callbacks/context/">Context</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/">Conversational RAG</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/edenai/">Eden AI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat_loaders/facebook/">Facebook Messenger</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/callbacks/fiddler/">Fiddler</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/document_loaders/figma/">Figma</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/fleet_context/">Fleet AI Context</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/google_alloydb/">Google AlloyDB for PostgreSQL</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/google_el_carro/">Google El Carro Oracle</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/google_sql_mysql/">Google SQL for MySQL</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/google_sql_pg/">Google SQL for PostgreSQL</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/google_sql_mssql/">Google SQL for SQL Server</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/groq/">Groq</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/query_high_cardinality/">How deal with high cardinality categoricals when doing query analysis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/graph_semantic/">How to add a semantic layer over graph database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/tools_prompting/">How to add ad-hoc tool calling capability to LLMs and Chat Models</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/qa_chat_history_how_to/">How to add chat history</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/binding/">How to add default invocation args to a Runnable</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/query_few_shot/">How to add examples to the prompt for query analysis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/fallbacks/">How to add fallbacks to a runnable</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/chatbots_memory/">How to add memory to chatbots</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/message_history/">How to add message history</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/chatbots_retrieval/">How to add retrieval to chatbots</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/chatbots_tools/">How to add tools to chatbots</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/assign/">How to add values to a chain‚Äôs state</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/callbacks_attach/">How to attach callbacks to a runnable</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/sequence/">How to chain runnables</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/custom_llm/">How to create a custom LLM class</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/dynamic_chain/">How to create a dynamic (self-constructing) chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/custom_callbacks/">How to create custom callback handlers</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/sql_large_db/">How to deal with large databases when doing SQL question-answering</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/debugging/">How to debug your LLM apps</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/qa_per_user/">How to do per-user retrieval</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/sql_query_checking/">How to do query validation as part of SQL question-answering</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/sql_csv/">How to do question answering over CSVs</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/function_calling/">How to do tool/function calling</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/qa_citations/">How to get a RAG application to add citations</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/qa_sources/">How to get your RAG application to return sources</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/query_no_queries/">How to handle cases where no queries are generated</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/extraction_long_text/">How to handle long text when doing extraction</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/query_multiple_queries/">How to handle multiple queries when doing query analysis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/query_multiple_retrievers/">How to handle multiple retrievers when doing query analysis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/tools_error/">How to handle tool errors</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/inspect/">How to inspect runnables</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/parallel/">How to invoke runnables in parallel</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/graph_mapping/">How to map values to a graph database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/migrate_agent/">How to migrate from legacy LangChain agents to LangGraph</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/callbacks_runtime/">How to pass callbacks in at runtime</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/passthrough/">How to pass through arguments from one step to the next</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/callbacks_constructor/">How to propagate callbacks  constructor</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/multi_vector/">How to retrieve using multiple vectors per document</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/structured_output/">How to return structured data from a model</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/functions/">How to run custom functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/qa_streaming/">How to stream results from your RAG application</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/streaming/">How to stream runnables</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/chat_token_usage_tracking/">How to track token usage in ChatModels</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/tool_calling">How to use a model to call tools</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/few_shot_examples_chat/">How to use few shot examples in chat models</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/multimodal_prompts/">How to use multimodal prompts</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/extraction_parse/">How to use prompting alone (no tool calling) to do extraction</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/extraction_examples/">How to use reference examples when doing extraction</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/hybrid/">Hybrid Search</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/jaguar/">Jaguar Vector Database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/jinachat/">JinaChat</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/kinetica/">Kinetica SqlAssist LLM Demo</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/lcel_cheatsheet/">LangChain Expression Language Cheatsheet</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat_loaders/langsmith_llm_runs/">LangSmith LLM Runs</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/llama2_chat/">Llama2Chat</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/maritalk/">Maritalk</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/mistralai/">MistralAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/mongodb_chat_message_history/">MongoDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/">NVIDIA NIMs</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/text_embedding/nvidia_ai_endpoints/">NVIDIA NIMs </a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/document_transformers/openai_metadata_tagger/">OpenAI metadata tagger</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/ragatouille/">RAGatouille</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/redis_chat_message_history/">Redis</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/sql_chat_message_history/">SQL (SQLAlchemy)</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/toolkits/sql_database/">SQL Database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/sqlite/">SQLite</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/streamlit_chat_message_history/">Streamlit</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/tavily/">Tavily Search API</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/tidb_chat_message_history/">TiDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/callbacks/uptrain/">UpTrain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/providers/vectara/vectara_summary/">Vectara</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/retrievers/">Vector stores and retrievers</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/weaviate/">Weaviate</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/yellowbrick/">Yellowbrick</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/you-retriever/">You.com</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/yuan2/">Yuan2.0</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/memory/zep_cloud_chat_message_history/">ZepCloudChatMessageHistory</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat_loaders/imessage/">iMessage</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/chat/vllm/">vLLM Chat</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/v0.2/docs/langserve/">ü¶úÔ∏èüèì LangServe</a></p></li>
</ul>
</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate</span></code></a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.input_types"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.input_types</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.input_variables"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.input_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.messages"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.messages</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.metadata"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.metadata</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.optional_variables"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.optional_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.output_parser"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.output_parser</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.partial_variables"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.partial_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.tags"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.tags</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.validate_template"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.validate_template</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.abatch"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.abatch()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.abatch_as_completed"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.abatch_as_completed()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.aformat()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat_messages"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.aformat_messages()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.aformat_prompt"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.aformat_prompt()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.ainvoke"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.ainvoke()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.append"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.append()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.as_tool"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.as_tool()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.astream"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.astream()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.astream_events"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.astream_events()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.batch"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.batch()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.batch_as_completed"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.batch_as_completed()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.configurable_alternatives"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.configurable_alternatives()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.configurable_fields"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.configurable_fields()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.extend"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.extend()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.format"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.format()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.format_messages"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.format_messages()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.format_prompt"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.format_prompt()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_messages"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.from_messages()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_role_strings"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.from_role_strings()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_strings"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.from_strings()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.from_template"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.from_template()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.invoke"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.invoke()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.partial"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.partial()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.pretty_print"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.pretty_print()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.pretty_repr"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.pretty_repr()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.save"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.save()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.stream"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.stream()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain_core.prompts.chat.ChatPromptTemplate.to_json"><code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate.to_json()</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2023, LangChain Inc.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>