
<!DOCTYPE html>

<html data-content_root="" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.19: https://docutils.sourceforge.io/" name="generator"/>
<title>create_structured_output_runnable ‚Äî ü¶úüîó LangChain  documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/autodoc_pydantic.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
<script src="../../_static/doctools.js"></script>
<script src="../../_static/sphinx_highlight.js"></script>
<script src="../../_static/clipboard.min.js"></script>
<script src="../../_static/copybutton.js"></script>
<script src="../../_static/design-tabs.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'langchain/chains/langchain.chains.structured_output.base.create_structured_output_runnable';</script>
<link href="../../_static/favicon.png" rel="icon"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="../chat_models.html" rel="next" title="chat_models"/>
<link href="langchain.chains.structured_output.base.create_openai_fn_runnable.html" rel="prev" title="create_openai_fn_runnable"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Sep 11, 2024" name="docbuild:last-update"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../index.html">
<img alt="ü¶úüîó LangChain  documentation - Home" class="logo__image only-light" src="../../_static/wordmark-api.svg"/>
<script>document.write(`<img src="../../_static/wordmark-api-dark.svg" class="logo__image only-dark" alt="ü¶úüîó LangChain  documentation - Home"/>`);</script>
</a></div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../reference.html">
    Reference
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://api.python.langchain.com/">
    Legacy reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../reference.html">
    Reference
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://api.python.langchain.com/">
    Legacy reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Base packages</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../core/index.html">Core</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Langchain</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../agents.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">agents</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../callbacks.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">callbacks</span></code></a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../chains.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chains</span></code></a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.base.Chain.html">Chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.base.BaseCombineDocumentsChain.html">BaseCombineDocumentsChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain.html">MapReduceDocumentsChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.map_rerank.MapRerankDocumentsChain.html">MapRerankDocumentsChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.reduce.AsyncCombineDocsProtocol.html">AsyncCombineDocsProtocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.reduce.CombineDocsProtocol.html">CombineDocsProtocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.reduce.ReduceDocumentsChain.html">ReduceDocumentsChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.refine.RefineDocumentsChain.html">RefineDocumentsChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.constitutional_ai.models.ConstitutionalPrinciple.html">ConstitutionalPrinciple</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.conversational_retrieval.base.BaseConversationalRetrievalChain.html">BaseConversationalRetrievalChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.conversational_retrieval.base.ChatVectorDBChain.html">ChatVectorDBChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.conversational_retrieval.base.InputType.html">InputType</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.elasticsearch_database.base.ElasticsearchDatabaseChain.html">ElasticsearchDatabaseChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.flare.base.FlareChain.html">FlareChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.flare.base.QuestionGeneratorChain.html">QuestionGeneratorChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.flare.prompts.FinishedOutputParser.html">FinishedOutputParser</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html">HypotheticalDocumentEmbedder</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.moderation.OpenAIModerationChain.html">OpenAIModerationChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.natbot.crawler.Crawler.html">Crawler</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.natbot.crawler.ElementInViewPort.html">ElementInViewPort</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.citation_fuzzy_match.FactWithEvidence.html">FactWithEvidence</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.citation_fuzzy_match.QuestionAnswer.html">QuestionAnswer</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.openapi.SimpleRequestChain.html">SimpleRequestChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.qa_with_structure.AnswerWithSources.html">AnswerWithSources</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.prompt_selector.BasePromptSelector.html">BasePromptSelector</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.prompt_selector.ConditionalPromptSelector.html">ConditionalPromptSelector</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.qa_with_sources.loading.LoadingCallable.html">LoadingCallable</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html">RetrievalQAWithSourcesChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.qa_with_sources.vector_db.VectorDBQAWithSourcesChain.html">VectorDBQAWithSourcesChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.base.StructuredQueryOutputParser.html">StructuredQueryOutputParser</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.parser.ISO8601Date.html">ISO8601Date</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.parser.ISO8601DateTime.html">ISO8601DateTime</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.schema.AttributeInfo.html">AttributeInfo</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.question_answering.chain.LoadingCallable.html">LoadingCallable</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.router.base.MultiRouteChain.html">MultiRouteChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.router.base.Route.html">Route</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.router.base.RouterChain.html">RouterChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.router.embedding_router.EmbeddingRouterChain.html">EmbeddingRouterChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.router.llm_router.RouterOutputParser.html">RouterOutputParser</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.router.multi_retrieval_qa.MultiRetrievalQAChain.html">MultiRetrievalQAChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.sequential.SequentialChain.html">SequentialChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.sequential.SimpleSequentialChain.html">SimpleSequentialChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.sql_database.query.SQLInput.html">SQLInput</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.sql_database.query.SQLInputWithTables.html">SQLInputWithTables</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.summarize.chain.LoadingCallable.html">LoadingCallable</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.transform.TransformChain.html">TransformChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.reduce.acollapse_docs.html">acollapse_docs</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.reduce.collapse_docs.html">collapse_docs</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.reduce.split_list_of_docs.html">split_list_of_docs</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html">create_stuff_documents_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.example_generator.generate_example.html">generate_example</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.history_aware_retriever.create_history_aware_retriever.html">create_history_aware_retriever</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.citation_fuzzy_match.create_citation_fuzzy_match_runnable.html">create_citation_fuzzy_match_runnable</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.openapi.openapi_spec_to_openai_fn.html">openapi_spec_to_openai_fn</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.utils.get_llm_kwargs.html">get_llm_kwargs</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.prompt_selector.is_chat_model.html">is_chat_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.prompt_selector.is_llm.html">is_llm</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.base.construct_examples.html">construct_examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.base.fix_filter_directive.html">fix_filter_directive</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.base.get_query_constructor_prompt.html">get_query_constructor_prompt</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.base.load_query_constructor_runnable.html">load_query_constructor_runnable</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.parser.get_parser.html">get_parser</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.parser.v_args.html">v_args</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.retrieval.create_retrieval_chain.html">create_retrieval_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.sql_database.query.create_sql_query_chain.html">create_sql_query_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.structured_output.base.get_openai_output_parser.html">get_openai_output_parser</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.summarize.chain.load_summarize_chain.html">load_summarize_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.api.base.APIChain.html">APIChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.base.AnalyzeDocumentChain.html">AnalyzeDocumentChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.combine_documents.stuff.StuffDocumentsChain.html">StuffDocumentsChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.constitutional_ai.base.ConstitutionalChain.html">ConstitutionalChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.conversation.base.ConversationChain.html">ConversationChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain.html">ConversationalRetrievalChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.llm.LLMChain.html">LLMChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.llm_checker.base.LLMCheckerChain.html">LLMCheckerChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.llm_math.base.LLMMathChain.html">LLMMathChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.llm_summarization_checker.base.LLMSummarizationCheckerChain.html">LLMSummarizationCheckerChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.mapreduce.MapReduceChain.html">MapReduceChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.natbot.base.NatBotChain.html">NatBotChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.qa_generation.base.QAGenerationChain.html">QAGenerationChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain.html">BaseQAWithSourcesChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.qa_with_sources.base.QAWithSourcesChain.html">QAWithSourcesChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.retrieval_qa.base.BaseRetrievalQA.html">BaseRetrievalQA</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.retrieval_qa.base.RetrievalQA.html">RetrievalQA</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.retrieval_qa.base.VectorDBQA.html">VectorDBQA</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.router.llm_router.LLMRouterChain.html">LLMRouterChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.router.multi_prompt.MultiPromptChain.html">MultiPromptChain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.loading.load_chain.html">load_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.loading.load_chain_from_config.html">load_chain_from_config</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.base.create_openai_fn_chain.html">create_openai_fn_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.base.create_structured_output_chain.html">create_structured_output_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.citation_fuzzy_match.create_citation_fuzzy_match_chain.html">create_citation_fuzzy_match_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.extraction.create_extraction_chain.html">create_extraction_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.extraction.create_extraction_chain_pydantic.html">create_extraction_chain_pydantic</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.openapi.get_openapi_chain.html">get_openapi_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.qa_with_structure.create_qa_with_sources_chain.html">create_qa_with_sources_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.qa_with_structure.create_qa_with_structure_chain.html">create_qa_with_structure_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.tagging.create_tagging_chain.html">create_tagging_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_functions.tagging.create_tagging_chain_pydantic.html">create_tagging_chain_pydantic</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.openai_tools.extraction.create_extraction_chain_pydantic.html">create_extraction_chain_pydantic</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.qa_with_sources.loading.load_qa_with_sources_chain.html">load_qa_with_sources_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.query_constructor.base.load_query_constructor_chain.html">load_query_constructor_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.question_answering.chain.load_qa_chain.html">load_qa_chain</a></li>
<li class="toctree-l3"><a class="reference internal" href="langchain.chains.structured_output.base.create_openai_fn_runnable.html">create_openai_fn_runnable</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">create_structured_output_runnable</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../chat_models.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chat_models</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../embeddings.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../evaluation.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">evaluation</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../globals.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">globals</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../hub.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">hub</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../indexes.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">indexes</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../memory.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">memory</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_laboratory.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">model_laboratory</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../output_parsers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">output_parsers</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../retrievers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">retrievers</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../runnables.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">runnables</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../smith.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">smith</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../storage.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">storage</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../text_splitters/index.html">Text Splitters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/index.html">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../experimental/index.html">Experimental</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Integrations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ai21/index.html">AI21</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../airbyte/index.html">Airbyte</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../anthropic/index.html">Anthropic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../astradb/index.html">AstraDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../aws/index.html">AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../azure_dynamic_sessions/index.html">Azure Dynamic Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../box/index.html">Box</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chroma/index.html">Chroma</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cohere/index.html">Cohere</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../couchbase/index.html">Couchbase</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../elasticsearch/index.html">Elasticsearch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../exa/index.html">Exa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fireworks/index.html">Fireworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_community/index.html">Google Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_genai/index.html">Google GenAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../google_vertexai/index.html">Google VertexAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../groq/index.html">Groq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../huggingface/index.html">Huggingface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../milvus/index.html">Milvus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mistralai/index.html">MistralAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mongodb/index.html">MongoDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nomic/index.html">Nomic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nvidia_ai_endpoints/index.html">Nvidia Ai Endpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ollama/index.html">Ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../openai/index.html">OpenAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pinecone/index.html">Pinecone</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../postgres/index.html">Postgres</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../prompty/index.html">Prompty</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../qdrant/index.html">Qdrant</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../robocorp/index.html">Robocorp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../together/index.html">Together</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unstructured/index.html">Unstructured</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../voyageai/index.html">VoyageAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../weaviate/index.html">Weaviate</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../../reference.html">LangChain Python API Reference</a></li>
<li class="breadcrumb-item"><i class="fa-solid fa-ellipsis"></i></li>
<li class="breadcrumb-item"><a class="nav-link" href="../chains.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">chains</span></code></a></li>
<li aria-current="page" class="breadcrumb-item active">create_struc...</li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<section id="create-structured-output-runnable">
<h1>create_structured_output_runnable<a class="headerlink" href="#create-structured-output-runnable" title="Permalink to this heading">#</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="langchain.chains.structured_output.base.create_structured_output_runnable">
<span class="sig-prename descclassname"><span class="pre">langchain.chains.structured_output.base.</span></span><span class="sig-name descname"><span class="pre">create_structured_output_runnable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">llm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../core/prompts/langchain_core.prompts.base.BasePromptTemplate.html#langchain_core.prompts.base.BasePromptTemplate" title="langchain_core.prompts.base.BasePromptTemplate"><span class="pre">BasePromptTemplate</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_parser</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../core/output_parsers/langchain_core.output_parsers.base.BaseOutputParser.html#langchain_core.output_parsers.base.BaseOutputParser" title="langchain_core.output_parsers.base.BaseOutputParser"><span class="pre">BaseOutputParser</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../../core/output_parsers/langchain_core.output_parsers.base.BaseGenerationOutputParser.html#langchain_core.output_parsers.base.BaseGenerationOutputParser" title="langchain_core.output_parsers.base.BaseGenerationOutputParser"><span class="pre">BaseGenerationOutputParser</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enforce_function_usage</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_single</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'openai-functions'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'openai-tools'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'openai-json'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'openai-functions'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">‚Üí</span> <span class="sig-return-typehint"><a class="reference internal" href="../../core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a></span></span><a class="reference internal" href="../../_modules/langchain/chains/structured_output/base.html#create_structured_output_runnable"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chains.structured_output.base.create_structured_output_runnable" title="Permalink to this definition">#</a></dt>
<dd><div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 0.1.17: </span>LangChain has introduced a method called <cite>with_structured_output</cite> that is available on ChatModels capable of tool calling. You can read more about the method here: &lt;<a class="reference external" href="https://python.langchain.com/docs/modules/model_io/chat/structured_output/">https://python.langchain.com/docs/modules/model_io/chat/structured_output/</a>&gt;.Please follow our extraction use case documentation for more guidelines on how to do information extraction with LLMs. &lt;<a class="reference external" href="https://python.langchain.com/docs/use_cases/extraction/">https://python.langchain.com/docs/use_cases/extraction/</a>&gt;. If you notice other issues, please provide feedback here: &lt;<a class="github reference external" href="https://github.com/langchain-ai/langchain/discussions/18154">langchain-ai/langchain#18154</a>&gt; Use ``
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_anthropic import ChatAnthropic</p>
<dl class="simple">
<dt>class Joke(BaseModel):</dt><dd><p>setup: str = Field(description=‚ÄùThe setup of the joke‚Äù)
punchline: str = Field(description=‚ÄùThe punchline to the joke‚Äù)</p>
</dd>
</dl>
<p># Or any other chat model that supports tools.
# Please reference to to the documentation of structured_output
# to see an up to date list of which models support
# with_structured_output.
model = ChatAnthropic(model=‚Äùclaude-3-opus-20240229‚Äù, temperature=0)
structured_llm = model.with_structured_output(Joke)
structured_llm.invoke(‚ÄúTell me a joke about cats.</p>
<blockquote>
<div><p>Make sure to call the Joke function.‚Äù)</p>
</div></blockquote>
<p>`` instead.</p>
</div>
<p>Create a runnable for extracting structured outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_schema</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>Type</em><em>[</em><em>BaseModel</em><em>]</em>) ‚Äì Either a dictionary or pydantic.BaseModel class. If a dictionary
is passed in, it‚Äôs assumed to already be a valid JsonSchema.
For best results, pydantic.BaseModels should have docstrings describing what
the schema represents and descriptions for the parameters.</p></li>
<li><p><strong>llm</strong> (<a class="reference internal" href="../../core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>) ‚Äì Language model to use. Assumed to support the OpenAI function-calling API
if mode is ‚Äòopenai-function‚Äô. Assumed to support OpenAI response_format
parameter if mode is ‚Äòopenai-json‚Äô.</p></li>
<li><p><strong>prompt</strong> (<a class="reference internal" href="../../core/prompts/langchain_core.prompts.base.BasePromptTemplate.html#langchain_core.prompts.base.BasePromptTemplate" title="langchain_core.prompts.base.BasePromptTemplate"><em>BasePromptTemplate</em></a><em> | </em><em>None</em>) ‚Äì BasePromptTemplate to pass to the model. If mode is ‚Äòopenai-json‚Äô and
prompt has input variable ‚Äòoutput_schema‚Äô then the given output_schema
will be converted to a JsonSchema and inserted in the prompt.</p></li>
<li><p><strong>output_parser</strong> (<a class="reference internal" href="../../core/output_parsers/langchain_core.output_parsers.base.BaseOutputParser.html#langchain_core.output_parsers.base.BaseOutputParser" title="langchain_core.output_parsers.base.BaseOutputParser"><em>BaseOutputParser</em></a><em> | </em><a class="reference internal" href="../../core/output_parsers/langchain_core.output_parsers.base.BaseGenerationOutputParser.html#langchain_core.output_parsers.base.BaseGenerationOutputParser" title="langchain_core.output_parsers.base.BaseGenerationOutputParser"><em>BaseGenerationOutputParser</em></a><em> | </em><em>None</em>) ‚Äì Output parser to use for parsing model outputs. By default
will be inferred from the function types. If pydantic.BaseModel is passed
in, then the OutputParser will try to parse outputs using the pydantic
class. Otherwise model outputs will be parsed as JSON.</p></li>
<li><p><strong>mode</strong> (<em>Literal</em><em>[</em><em>'openai-functions'</em><em>, </em><em>'openai-tools'</em><em>, </em><em>'openai-json'</em><em>]</em>) ‚Äì How structured outputs are extracted from the model. If ‚Äòopenai-functions‚Äô
then OpenAI function calling is used with the deprecated ‚Äòfunctions‚Äô,
‚Äòfunction_call‚Äô schema. If ‚Äòopenai-tools‚Äô then OpenAI function
calling with the latest ‚Äòtools‚Äô, ‚Äòtool_choice‚Äô schema is used. This is
recommended over ‚Äòopenai-functions‚Äô. If ‚Äòopenai-json‚Äô then OpenAI model
with response_format set to JSON is used.</p></li>
<li><p><strong>enforce_function_usage</strong> (<em>bool</em>) ‚Äì Only applies when mode is ‚Äòopenai-tools‚Äô or
‚Äòopenai-functions‚Äô. If True, then the model will be forced to use the given
output schema. If False, then the model can elect whether to use the output
schema.</p></li>
<li><p><strong>return_single</strong> (<em>bool</em>) ‚Äì Only applies when mode is ‚Äòopenai-tools‚Äô. Whether to a list of
structured outputs or a single one. If True and model does not return any
structured outputs then chain output is None. If False and model does not
return any structured outputs then chain output is an empty list.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) ‚Äì Additional named arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A runnable sequence that will return a structured output(s) matching the given</dt><dd><p>output_schema.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../../core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a></p>
</dd>
</dl>
<dl>
<dt>OpenAI tools example with Pydantic schema (mode=‚Äôopenai-tools‚Äô):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>


<span class="k">class</span> <span class="nc">RecordDog</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''Record some identifying information about a dog.'''</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's name"</span><span class="p">)</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's color"</span><span class="p">)</span>
    <span class="n">fav_food</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's favorite food"</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-3.5-turbo-0125"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="s2">"system"</span><span class="p">,</span> <span class="s2">"You are an extraction algorithm. Please extract every possible instance"</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">'human'</span><span class="p">,</span> <span class="s1">'</span><span class="si">{input}</span><span class="s1">'</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span>
    <span class="n">RecordDog</span><span class="p">,</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">"openai-tools"</span><span class="p">,</span>
    <span class="n">enforce_function_usage</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_single</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">"input"</span><span class="p">:</span> <span class="s2">"Harry was a chubby brown beagle who loved chicken"</span><span class="p">})</span>
<span class="c1"># -&gt; RecordDog(name="Harry", color="brown", fav_food="chicken")</span>
</pre></div>
</div>
</dd>
<dt>OpenAI tools example with dict schema (mode=‚Äùopenai-tools‚Äù):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>


<span class="n">dog_schema</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"function"</span><span class="p">,</span>
    <span class="s2">"function"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"record_dog"</span><span class="p">,</span>
        <span class="s2">"description"</span><span class="p">:</span> <span class="s2">"Record some identifying information about a dog."</span><span class="p">,</span>
        <span class="s2">"parameters"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"object"</span><span class="p">,</span>
            <span class="s2">"properties"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">"name"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">"description"</span><span class="p">:</span> <span class="s2">"The dog's name"</span><span class="p">,</span>
                    <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"string"</span>
                <span class="p">},</span>
                <span class="s2">"color"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">"description"</span><span class="p">:</span> <span class="s2">"The dog's color"</span><span class="p">,</span>
                    <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"string"</span>
                <span class="p">},</span>
                <span class="s2">"fav_food"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">"description"</span><span class="p">:</span> <span class="s2">"The dog's favorite food"</span><span class="p">,</span>
                    <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"string"</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">"required"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"name"</span><span class="p">,</span> <span class="s2">"color"</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>


<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-3.5-turbo-0125"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span>
    <span class="n">dog_schema</span><span class="p">,</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">"openai-tools"</span><span class="p">,</span>
    <span class="n">enforce_function_usage</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_single</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"Harry was a chubby brown beagle who loved chicken"</span><span class="p">)</span>
<span class="c1"># -&gt; {'name': 'Harry', 'color': 'brown', 'fav_food': 'chicken'}</span>
</pre></div>
</div>
</dd>
<dt>OpenAI functions example (mode=‚Äùopenai-functions‚Äù):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''Identifying information about a dog.'''</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's name"</span><span class="p">)</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's color"</span><span class="p">)</span>
    <span class="n">fav_food</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's favorite food"</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-3.5-turbo-0125"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span><span class="n">Dog</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"openai-functions"</span><span class="p">)</span>
<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"Harry was a chubby brown beagle who loved chicken"</span><span class="p">)</span>
<span class="c1"># -&gt; Dog(name="Harry", color="brown", fav_food="chicken")</span>
</pre></div>
</div>
</dd>
<dt>OpenAI functions with prompt example:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''Identifying information about a dog.'''</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's name"</span><span class="p">)</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's color"</span><span class="p">)</span>
    <span class="n">fav_food</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's favorite food"</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-3.5-turbo-0125"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span><span class="n">Dog</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"openai-functions"</span><span class="p">)</span>
<span class="n">system</span> <span class="o">=</span> <span class="s1">'''Extract information about any dogs mentioned in the user input.'''</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[(</span><span class="s2">"system"</span><span class="p">,</span> <span class="n">system</span><span class="p">),</span> <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{input}</span><span class="s2">"</span><span class="p">),]</span>
<span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">structured_llm</span>
<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">"input"</span><span class="p">:</span> <span class="s2">"Harry was a chubby brown beagle who loved chicken"</span><span class="p">})</span>
<span class="c1"># -&gt; Dog(name="Harry", color="brown", fav_food="chicken")</span>
</pre></div>
</div>
</dd>
<dt>OpenAI json response format example (mode=‚Äùopenai-json‚Äù):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">'''Identifying information about a dog.'''</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's name"</span><span class="p">)</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's color"</span><span class="p">)</span>
    <span class="n">fav_food</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"The dog's favorite food"</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-3.5-turbo-0125"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span><span class="n">Dog</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"openai-json"</span><span class="p">)</span>
<span class="n">system</span> <span class="o">=</span> <span class="s1">'''You are a world class assistant for extracting information in structured JSON formats.</span>
<span class="s1">Extract a valid JSON blob from the user input that matches the following JSON Schema:</span>

<span class="si">{output_schema}</span><span class="s1">'''</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[(</span><span class="s2">"system"</span><span class="p">,</span> <span class="n">system</span><span class="p">),</span> <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{input}</span><span class="s2">"</span><span class="p">),]</span>
<span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">structured_llm</span>
<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">"input"</span><span class="p">:</span> <span class="s2">"Harry was a chubby brown beagle who loved chicken"</span><span class="p">})</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>
<ul class="simple">
</ul>
</section>
</article>
</div>
<div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain.chains.structured_output.base.create_structured_output_runnable"><code class="docutils literal notranslate"><span class="pre">create_structured_output_runnable()</span></code></a></li>
</ul>
</nav></div>
</div></div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      ¬© Copyright 2023, LangChain Inc.
      <br/>
</p>
</div>
</div>
</div>
</footer>
</body>
</html>