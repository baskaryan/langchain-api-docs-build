
<!DOCTYPE html>

<html data-content_root="" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>langchain_community.vectorstores.deeplake â€” ðŸ¦œðŸ”— LangChain  documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/autodoc_pydantic.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/css/custom.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/sphinx_highlight.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/design-tabs.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = '_modules/langchain_community/vectorstores/deeplake';</script>
<link href="../../../_static/favicon.png" rel="icon"/>
<link href="../../../search.html" rel="search" title="Search"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Aug 19, 2024" name="docbuild:last-update"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../../index.html">
<img alt="ðŸ¦œðŸ”— LangChain  documentation - Home" class="logo__image only-light" src="../../../_static/wordmark-api.svg"/>
<script>document.write(`<img src="../../../_static/wordmark-api-dark.svg" class="logo__image only-dark" alt="ðŸ¦œðŸ”— LangChain  documentation - Home"/>`);</script>
</a></div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../reference.html">
    Reference
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://api.python.langchain.com/">
    Legacy reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar hide-on-wide">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../reference.html">
    Reference
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://api.python.langchain.com/">
    Legacy reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../../index.html">Module code</a></li>
<li aria-current="page" class="breadcrumb-item active">langchain_co...</li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<h1>Source code for langchain_community.vectorstores.deeplake</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">deeplake</span>
    <span class="kn">from</span> <span class="nn">deeplake</span> <span class="kn">import</span> <span class="n">VectorStore</span> <span class="k">as</span> <span class="n">DeepLakeVectorStore</span>
    <span class="kn">from</span> <span class="nn">deeplake.core.fast_forwarding</span> <span class="kn">import</span> <span class="n">version_compare</span>
    <span class="kn">from</span> <span class="nn">deeplake.util.exceptions</span> <span class="kn">import</span> <span class="n">SampleExtendError</span>

    <span class="n">_DEEPLAKE_INSTALLED</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">_DEEPLAKE_INSTALLED</span> <span class="o">=</span> <span class="kc">False</span>

<span class="kn">from</span> <span class="nn">langchain_core.documents</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">langchain_core.embeddings</span> <span class="kn">import</span> <span class="n">Embeddings</span>
<span class="kn">from</span> <span class="nn">langchain_core.vectorstores</span> <span class="kn">import</span> <span class="n">VectorStore</span>

<span class="kn">from</span> <span class="nn">langchain_community.vectorstores.utils</span> <span class="kn">import</span> <span class="n">maximal_marginal_relevance</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="DeepLake"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake">[docs]</a><span class="k">class</span> <span class="nc">DeepLake</span><span class="p">(</span><span class="n">VectorStore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""`Activeloop Deep Lake` vector store.</span>

<span class="sd">    We integrated deeplake's similarity search and filtering for fast prototyping.</span>
<span class="sd">    Now, it supports Tensor Query Language (TQL) for production use cases</span>
<span class="sd">    over billion rows.</span>

<span class="sd">    Why Deep Lake?</span>

<span class="sd">    - Not only stores embeddings, but also the original data with version control.</span>
<span class="sd">    - Serverless, doesn't require another service and can be used with major</span>
<span class="sd">        cloud providers (S3, GCS, etc.)</span>
<span class="sd">    - More than just a multi-modal vector store. You can use the dataset</span>
<span class="sd">        to fine-tune your own LLM models.</span>

<span class="sd">    To use, you should have the ``deeplake`` python package installed.</span>

<span class="sd">    Example:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">                from langchain_community.vectorstores import DeepLake</span>
<span class="sd">                from langchain_community.embeddings.openai import OpenAIEmbeddings</span>

<span class="sd">                embeddings = OpenAIEmbeddings()</span>
<span class="sd">                vectorstore = DeepLake("langchain_store", embeddings.embed_query)</span>
<span class="sd">    """</span>

    <span class="n">_LANGCHAIN_DEFAULT_DEEPLAKE_PATH</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"./deeplake/"</span>
    <span class="n">_valid_search_kwargs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"lambda_mult"</span><span class="p">]</span>

<div class="viewcode-block" id="DeepLake.__init__"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_LANGCHAIN_DEFAULT_DEEPLAKE_PATH</span><span class="p">,</span>
        <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Embeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding_function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Embeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">read_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">ingestion_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">runtime</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">index_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Creates an empty DeepLakeVectorStore or loads an existing one.</span>

<span class="sd">        The DeepLakeVectorStore is located at the specified ``path``.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Create a vector store with default tensors</span>
<span class="sd">            &gt;&gt;&gt; deeplake_vectorstore = DeepLake(</span>
<span class="sd">            ...        path = &lt;path_for_storing_Data&gt;,</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create a vector store in the Deep Lake Managed Tensor Database</span>
<span class="sd">            &gt;&gt;&gt; data = DeepLake(</span>
<span class="sd">            ...        path = "hub://org_id/dataset_name",</span>
<span class="sd">            ...        runtime = {"tensor_db": True},</span>
<span class="sd">            ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset_path (str): The full path for storing to the Deep Lake</span>
<span class="sd">                Vector Store. It can be:</span>
<span class="sd">                - a Deep Lake cloud path of the form ``hub://org_id/dataset_name``.</span>
<span class="sd">                    Requires registration with Deep Lake.</span>
<span class="sd">                - an s3 path of the form ``s3://bucketname/path/to/dataset``.</span>
<span class="sd">                    Credentials are required in either the environment or passed to</span>
<span class="sd">                    the creds argument.</span>
<span class="sd">                - a local file system path of the form ``./path/to/dataset``</span>
<span class="sd">                    or ``~/path/to/dataset`` or ``path/to/dataset``.</span>
<span class="sd">                - a memory path of the form ``mem://path/to/dataset`` which doesn't</span>
<span class="sd">                    save the dataset but keeps it in memory instead.</span>
<span class="sd">                    Should be used only for testing as it does not persist.</span>
<span class="sd">                    Defaults to _LANGCHAIN_DEFAULT_DEEPLAKE_PATH.</span>
<span class="sd">            token (str, optional):  Activeloop token, for fetching credentials</span>
<span class="sd">                to the dataset at path if it is a Deep Lake dataset.</span>
<span class="sd">                Tokens are normally autogenerated. Optional.</span>
<span class="sd">            embedding (Embeddings, optional): Function to convert</span>
<span class="sd">                either documents or query. Optional.</span>
<span class="sd">            embedding_function (Embeddings, optional): Function to convert</span>
<span class="sd">                either documents or query. Optional. Deprecated: keeping this</span>
<span class="sd">                parameter for backwards compatibility.</span>
<span class="sd">            read_only (bool): Open dataset in read-only mode. Default is False.</span>
<span class="sd">            ingestion_batch_size (int): During data ingestion, data is divided</span>
<span class="sd">                into batches. Batch size is the size of each batch.</span>
<span class="sd">                Default is 1024.</span>
<span class="sd">            num_workers (int): Number of workers to use during data ingestion.</span>
<span class="sd">                Default is 0.</span>
<span class="sd">            verbose (bool): Print dataset summary after each operation.</span>
<span class="sd">                Default is True.</span>
<span class="sd">            exec_option (str, optional): Default method for search execution.</span>
<span class="sd">                It could be either ``"auto"``, ``"python"``, ``"compute_engine"``</span>
<span class="sd">                or ``"tensor_db"``. Defaults to ``"auto"``.</span>
<span class="sd">                If None, it's set to "auto".</span>
<span class="sd">                - ``auto``- Selects the best execution method based on the storage</span>
<span class="sd">                    location of the Vector Store. It is the default option.</span>
<span class="sd">                - ``python`` - Pure-python implementation that runs on the client and</span>
<span class="sd">                    can be used for data stored anywhere. WARNING: using this option</span>
<span class="sd">                    with big datasets is discouraged because it can lead to</span>
<span class="sd">                    memory issues.</span>
<span class="sd">                - ``compute_engine`` - Performant C++ implementation of the Deep Lake</span>
<span class="sd">                    Compute Engine that runs on the client and can be used for any data</span>
<span class="sd">                    stored in or connected to Deep Lake. It cannot be used with</span>
<span class="sd">                    in-memory or local datasets.</span>
<span class="sd">                - ``tensor_db`` - Performant and fully-hosted Managed Tensor Database</span>
<span class="sd">                    that is responsible for storage and query execution. Only available</span>
<span class="sd">                    for data stored in the Deep Lake Managed Database. Store datasets</span>
<span class="sd">                    in this database by specifying runtime = {"tensor_db": True}</span>
<span class="sd">                    during dataset creation.</span>
<span class="sd">            runtime (Dict, optional): Parameters for creating the Vector Store in</span>
<span class="sd">                Deep Lake's Managed Tensor Database. Not applicable when loading an</span>
<span class="sd">                existing Vector Store. To create a Vector Store in the Managed Tensor</span>
<span class="sd">                Database, set `runtime = {"tensor_db": True}`.</span>
<span class="sd">            index_params (Optional[Dict[str, Union[int, str]]], optional): Dictionary</span>
<span class="sd">                containing information about vector index that will be created. Defaults</span>
<span class="sd">                to None, which will utilize ``DEFAULT_VECTORSTORE_INDEX_PARAMS`` from</span>
<span class="sd">                ``deeplake.constants``. The specified key-values override the default</span>
<span class="sd">                ones.</span>
<span class="sd">                - threshold: The threshold for the dataset size above which an index</span>
<span class="sd">                    will be created for the embedding tensor. When the threshold value</span>
<span class="sd">                    is set to -1, index creation is turned off. Defaults to -1, which</span>
<span class="sd">                    turns off the index.</span>
<span class="sd">                - distance_metric: This key specifies the method of calculating the</span>
<span class="sd">                    distance between vectors when creating the vector database (VDB)</span>
<span class="sd">                    index. It can either be a string that corresponds to a member of</span>
<span class="sd">                    the DistanceType enumeration, or the string value itself.</span>
<span class="sd">                    - If no value is provided, it defaults to "L2".</span>
<span class="sd">                    - "L2" corresponds to DistanceType.L2_NORM.</span>
<span class="sd">                    - "COS" corresponds to DistanceType.COSINE_SIMILARITY.</span>
<span class="sd">                - additional_params: Additional parameters for fine-tuning the index.</span>
<span class="sd">            **kwargs: Other optional keyword arguments.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If some condition is not met.</span>
<span class="sd">        """</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ingestion_batch_size</span> <span class="o">=</span> <span class="n">ingestion_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="k">if</span> <span class="n">_DEEPLAKE_INSTALLED</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">"Could not import deeplake python package. "</span>
                <span class="s2">"Please install it with `pip install deeplake[enterprise]`."</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">runtime</span> <span class="o">==</span> <span class="p">{</span><span class="s2">"tensor_db"</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
            <span class="ow">and</span> <span class="n">version_compare</span><span class="p">(</span><span class="n">deeplake</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="s2">"3.6.7"</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">"To use tensor_db option you need to update deeplake to `3.6.7` or "</span>
                <span class="s2">"higher. "</span>
                <span class="sa">f</span><span class="s2">"Currently installed deeplake version is </span><span class="si">{</span><span class="n">deeplake</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">. "</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_path</span> <span class="o">=</span> <span class="n">dataset_path</span>

        <span class="k">if</span> <span class="n">embedding_function</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">"Using embedding function is deprecated and will be removed "</span>
                <span class="s2">"in the future. Please use embedding instead."</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span> <span class="o">=</span> <span class="n">DeepLakeVectorStore</span><span class="p">(</span>
            <span class="n">path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">,</span>
            <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding_function</span> <span class="ow">or</span> <span class="n">embedding</span><span class="p">,</span>
            <span class="n">read_only</span><span class="o">=</span><span class="n">read_only</span><span class="p">,</span>
            <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">runtime</span><span class="o">=</span><span class="n">runtime</span><span class="p">,</span>
            <span class="n">index_params</span><span class="o">=</span><span class="n">index_params</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span> <span class="o">=</span> <span class="n">embedding_function</span> <span class="ow">or</span> <span class="n">embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_id_tensor_name</span> <span class="o">=</span> <span class="s2">"ids"</span> <span class="k">if</span> <span class="s2">"ids"</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">tensors</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"id"</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Embeddings</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span>

<div class="viewcode-block" id="DeepLake.add_texts"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.add_texts">[docs]</a>    <span class="k">def</span> <span class="nf">add_texts</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">texts</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">metadatas</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Run more texts through the embeddings and add to the vectorstore.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; ids = deeplake_vectorstore.add_texts(</span>
<span class="sd">            ...     texts = &lt;list_of_texts&gt;,</span>
<span class="sd">            ...     metadatas = &lt;list_of_metadata_jsons&gt;,</span>
<span class="sd">            ...     ids = &lt;list_of_ids&gt;,</span>
<span class="sd">            ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            texts (Iterable[str]): Texts to add to the vectorstore.</span>
<span class="sd">            metadatas (Optional[List[dict]], optional): Optional list of metadatas.</span>
<span class="sd">            ids (Optional[List[str]], optional): Optional list of IDs.</span>
<span class="sd">            embedding_function (Optional[Embeddings], optional): Embedding function</span>
<span class="sd">                to use to convert the text into embeddings.</span>
<span class="sd">            **kwargs (Any): Any additional keyword arguments passed is not supported</span>
<span class="sd">                by this method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[str]: List of IDs of the added texts.</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_kwargs</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="s2">"add_texts"</span><span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">ids</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_id_tensor_name</span> <span class="o">==</span> <span class="s2">"ids"</span><span class="p">:</span>  <span class="c1"># for backwards compatibility</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">"ids"</span><span class="p">]</span> <span class="o">=</span> <span class="n">ids</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">"id"</span><span class="p">]</span> <span class="o">=</span> <span class="n">ids</span>

        <span class="k">if</span> <span class="n">metadatas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">metadatas</span> <span class="o">=</span> <span class="p">[{}]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">texts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">texts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"`texts` parameter shouldn't be None."</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"`texts` parameter shouldn't be empty."</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">text</span><span class="o">=</span><span class="n">texts</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="n">metadatas</span><span class="p">,</span>
                <span class="n">embedding_data</span><span class="o">=</span><span class="n">texts</span><span class="p">,</span>
                <span class="n">embedding_tensor</span><span class="o">=</span><span class="s2">"embedding"</span><span class="p">,</span>
                <span class="n">embedding_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                <span class="n">return_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="n">SampleExtendError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">"Failed to append a sample to the tensor 'metadata'"</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">"**Hint: You might be using invalid type of argument in "</span>
                    <span class="s2">"document loader (e.g. 'pathlib.PosixPath' instead of 'str')"</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span> <span class="o">+</span> <span class="n">msg</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span></div>

    <span class="k">def</span> <span class="nf">_search_tql</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tql</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Function for performing tql_search.</span>

<span class="sd">        Args:</span>
<span class="sd">            tql (str): TQL Query string for direct evaluation.</span>
<span class="sd">                Available only for `compute_engine` and `tensor_db`.</span>
<span class="sd">            exec_option (str, optional): Supports 3 ways to search.</span>
<span class="sd">                Could be "python", "compute_engine" or "tensor_db". Default is "python".</span>
<span class="sd">                - ``python`` - Pure-python implementation for the client.</span>
<span class="sd">                    WARNING: not recommended for big datasets due to potential memory</span>
<span class="sd">                    issues.</span>
<span class="sd">                - ``compute_engine`` - C++ implementation of Deep Lake Compute</span>
<span class="sd">                    Engine for the client. Not for in-memory or local datasets.</span>
<span class="sd">                - ``tensor_db`` - Hosted Managed Tensor Database for storage</span>
<span class="sd">                    and query execution. Only for data in Deep Lake Managed Database.</span>
<span class="sd">                        Use runtime = {"db_engine": True} during dataset creation.</span>
<span class="sd">            return_score (bool): Return score with document. Default is False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[List[Document], List[Tuple[Document, float]]] - A tuple of two lists.</span>
<span class="sd">                The first list contains Documents, and the second list contains</span>
<span class="sd">                tuples of Document and float score.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If return_score is True but some condition is not met.</span>
<span class="sd">        """</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">tql</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">metadatas</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">"metadata"</span><span class="p">]</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span>

        <span class="n">docs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Document</span><span class="p">(</span>
                <span class="n">page_content</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">metadatas</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">unsupported_argument</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">kwargs</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">unsupported_argument</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"specifying </span><span class="si">{</span><span class="n">unsupported_argument</span><span class="si">}</span><span class="s2"> is "</span>
                    <span class="s2">"not supported with tql search."</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">docs</span>

    <span class="k">def</span> <span class="nf">_search</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding_function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">distance_metric</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_maximal_marginal_relevance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fetch_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="nb">filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_score</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">deep_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Document</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Return docs similar to query.</span>

<span class="sd">        Args:</span>
<span class="sd">            query (str, optional): Text to look up similar docs.</span>
<span class="sd">            embedding (Union[List[float], np.ndarray], optional): Query's embedding.</span>
<span class="sd">            embedding_function (Callable, optional): Function to convert `query`</span>
<span class="sd">                into embedding.</span>
<span class="sd">            k (int): Number of Documents to return.</span>
<span class="sd">            distance_metric (Optional[str], optional): `L2` for Euclidean, `L1` for</span>
<span class="sd">                Nuclear, `max` for L-infinity distance, `cos` for cosine similarity,</span>
<span class="sd">                'dot' for dot product.</span>
<span class="sd">            filter (Union[Dict, Callable], optional): Additional filter prior</span>
<span class="sd">                to the embedding search.</span>
<span class="sd">                - ``Dict`` - Key-value search on tensors of htype json, on an</span>
<span class="sd">                    AND basis (a sample must satisfy all key-value filters to be True)</span>
<span class="sd">                    Dict = {"tensor_name_1": {"key": value},</span>
<span class="sd">                            "tensor_name_2": {"key": value}}</span>
<span class="sd">                - ``Function`` - Any function compatible with `deeplake.filter`.</span>
<span class="sd">            use_maximal_marginal_relevance (bool): Use maximal marginal relevance.</span>
<span class="sd">            fetch_k (int): Number of Documents for MMR algorithm.</span>
<span class="sd">            return_score (bool): Return the score.</span>
<span class="sd">            exec_option (str, optional): Supports 3 ways to perform searching.</span>
<span class="sd">                Could be "python", "compute_engine" or "tensor_db".</span>
<span class="sd">                - ``python`` - Pure-python implementation for the client.</span>
<span class="sd">                    WARNING: not recommended for big datasets.</span>
<span class="sd">                - ``compute_engine`` - C++ implementation of Deep Lake Compute</span>
<span class="sd">                    Engine for the client. Not for in-memory or local datasets.</span>
<span class="sd">                - ``tensor_db`` - Hosted Managed Tensor Database for storage</span>
<span class="sd">                    and query execution. Only for data in Deep Lake Managed Database.</span>
<span class="sd">                    Use runtime = {"db_engine": True} during dataset creation.</span>
<span class="sd">            deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                search results. Defaults to False if deep_memory is not specified in</span>
<span class="sd">                the Vector Store initialization. If True, the distance metric is set</span>
<span class="sd">                to "deepmemory_distance", which represents the metric with which the</span>
<span class="sd">                model was trained. The search is performed using the Deep Memory model.</span>
<span class="sd">                If False, the distance metric is set to "COS" or whatever distance</span>
<span class="sd">                metric user specifies.</span>
<span class="sd">            kwargs: Additional keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of Documents by the specified distance metric,</span>
<span class="sd">            if return_score True, return a tuple of (Document, score)</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if both `embedding` and `embedding_function` are not specified.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"tql_query"</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"`tql_query` is deprecated. Please use `tql` instead."</span><span class="p">)</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">"tql"</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"tql_query"</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"tql"</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search_tql</span><span class="p">(</span>
                <span class="n">tql</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">"tql"</span><span class="p">],</span>
                <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
                <span class="n">return_score</span><span class="o">=</span><span class="n">return_score</span><span class="p">,</span>
                <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span>
                <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding_function</span><span class="p">,</span>
                <span class="n">distance_metric</span><span class="o">=</span><span class="n">distance_metric</span><span class="p">,</span>
                <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="n">use_maximal_marginal_relevance</span><span class="p">,</span>
                <span class="nb">filter</span><span class="o">=</span><span class="nb">filter</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_kwargs</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="s2">"search"</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">embedding_function</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">embedding_function</span><span class="p">,</span> <span class="n">Embeddings</span><span class="p">):</span>
                <span class="n">_embedding_function</span> <span class="o">=</span> <span class="n">embedding_function</span><span class="o">.</span><span class="n">embed_query</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_embedding_function</span> <span class="o">=</span> <span class="n">embedding_function</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span><span class="p">:</span>
            <span class="n">_embedding_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span><span class="o">.</span><span class="n">embed_query</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_embedding_function</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">embedding</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_embedding_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">"Either `embedding` or `embedding_function` needs to be"</span>
                    <span class="s2">" specified."</span>
                <span class="p">)</span>

            <span class="n">embedding</span> <span class="o">=</span> <span class="n">_embedding_function</span><span class="p">(</span><span class="n">query</span><span class="p">)</span> <span class="k">if</span> <span class="n">query</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
            <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">fetch_k</span> <span class="k">if</span> <span class="n">use_maximal_marginal_relevance</span> <span class="k">else</span> <span class="n">k</span><span class="p">,</span>
            <span class="n">distance_metric</span><span class="o">=</span><span class="n">distance_metric</span><span class="p">,</span>
            <span class="nb">filter</span><span class="o">=</span><span class="nb">filter</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="p">[</span><span class="s2">"embedding"</span><span class="p">,</span> <span class="s2">"metadata"</span><span class="p">,</span> <span class="s2">"text"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_id_tensor_name</span><span class="p">],</span>
            <span class="n">deep_memory</span><span class="o">=</span><span class="n">deep_memory</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">"score"</span><span class="p">]</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">"embedding"</span><span class="p">]</span>
        <span class="n">metadatas</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">"metadata"</span><span class="p">]</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">"text"</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">use_maximal_marginal_relevance</span><span class="p">:</span>
            <span class="n">lambda_mult</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lambda_mult"</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">maximal_marginal_relevance</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
                <span class="n">embedding</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                <span class="n">embeddings</span><span class="p">,</span>
                <span class="n">k</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)),</span>
                <span class="n">lambda_mult</span><span class="o">=</span><span class="n">lambda_mult</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
            <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">texts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
            <span class="n">metadatas</span> <span class="o">=</span> <span class="p">[</span><span class="n">metadatas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>

        <span class="n">docs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Document</span><span class="p">(</span>
                <span class="n">page_content</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">metadatas</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">return_score</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">scores</span><span class="p">]</span>

            <span class="k">return</span> <span class="p">[(</span><span class="n">doc</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">scores</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">docs</span>

<div class="viewcode-block" id="DeepLake.similarity_search"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.similarity_search">[docs]</a>    <span class="k">def</span> <span class="nf">similarity_search</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Return docs most similar to query.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Search using an embedding</span>
<span class="sd">            &gt;&gt;&gt; data = vector_store.similarity_search(</span>
<span class="sd">            ...     query=&lt;your_query&gt;,</span>
<span class="sd">            ...     k=&lt;num_items&gt;,</span>
<span class="sd">            ...     exec_option=&lt;preferred_exec_option&gt;,</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Run tql search:</span>
<span class="sd">            &gt;&gt;&gt; data = vector_store.similarity_search(</span>
<span class="sd">            ...     query=None,</span>
<span class="sd">            ...     tql="SELECT * WHERE id == &lt;id&gt;",</span>
<span class="sd">            ...     exec_option="compute_engine",</span>
<span class="sd">            ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            k (int): Number of Documents to return. Defaults to 4.</span>
<span class="sd">            query (str): Text to look up similar documents.</span>
<span class="sd">            kwargs: Additional keyword arguments include:</span>
<span class="sd">                embedding (Callable): Embedding function to use. Defaults to None.</span>
<span class="sd">                distance_metric (str): 'L2' for Euclidean, 'L1' for Nuclear, 'max'</span>
<span class="sd">                    for L-infinity, 'cos' for cosine, 'dot' for dot product.</span>
<span class="sd">                    Defaults to 'L2'.</span>
<span class="sd">                filter (Union[Dict, Callable], optional): Additional filter</span>
<span class="sd">                    before embedding search.</span>
<span class="sd">                    - Dict: Key-value search on tensors of htype json,</span>
<span class="sd">                        (sample must satisfy all key-value filters)</span>
<span class="sd">                        Dict = {"tensor_1": {"key": value}, "tensor_2": {"key": value}}</span>
<span class="sd">                    - Function: Compatible with `deeplake.filter`.</span>
<span class="sd">                    Defaults to None.</span>
<span class="sd">                exec_option (str): Supports 3 ways to perform searching.</span>
<span class="sd">                    'python', 'compute_engine', or 'tensor_db'. Defaults to 'python'.</span>
<span class="sd">                    - 'python': Pure-python implementation for the client.</span>
<span class="sd">                        WARNING: not recommended for big datasets.</span>
<span class="sd">                    - 'compute_engine': C++ implementation of the Compute Engine for</span>
<span class="sd">                        the client. Not for in-memory or local datasets.</span>
<span class="sd">                    - 'tensor_db': Managed Tensor Database for storage and query.</span>
<span class="sd">                        Only for data in Deep Lake Managed Database.</span>
<span class="sd">                        Use `runtime = {"db_engine": True}` during dataset creation.</span>
<span class="sd">                deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                    search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                    in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                    is set to "deepmemory_distance", which represents the metric with</span>
<span class="sd">                    which the model was trained. The search is performed using the Deep</span>
<span class="sd">                    Memory model. If False, the distance metric is set to "COS" or</span>
<span class="sd">                    whatever distance metric user specifies.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Document]: List of Documents most similar to the query vector.</span>
<span class="sd">        """</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">return_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.similarity_search_by_vector"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.similarity_search_by_vector">[docs]</a>    <span class="k">def</span> <span class="nf">similarity_search_by_vector</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Return docs most similar to embedding vector.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Search using an embedding</span>
<span class="sd">            &gt;&gt;&gt; data = vector_store.similarity_search_by_vector(</span>
<span class="sd">            ...    embedding=&lt;your_embedding&gt;,</span>
<span class="sd">            ...    k=&lt;num_items_to_return&gt;,</span>
<span class="sd">            ...    exec_option=&lt;preferred_exec_option&gt;,</span>
<span class="sd">            ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            embedding (Union[List[float], np.ndarray]):</span>
<span class="sd">                Embedding to find similar docs.</span>
<span class="sd">            k (int): Number of Documents to return. Defaults to 4.</span>
<span class="sd">            kwargs: Additional keyword arguments including:</span>
<span class="sd">                filter (Union[Dict, Callable], optional):</span>
<span class="sd">                    Additional filter before embedding search.</span>
<span class="sd">                    - ``Dict`` - Key-value search on tensors of htype json. True</span>
<span class="sd">                        if all key-value filters are satisfied.</span>
<span class="sd">                        Dict = {"tensor_name_1": {"key": value},</span>
<span class="sd">                                "tensor_name_2": {"key": value}}</span>
<span class="sd">                    - ``Function`` - Any function compatible with</span>
<span class="sd">                        `deeplake.filter`.</span>
<span class="sd">                    Defaults to None.</span>
<span class="sd">                exec_option (str): Options for search execution include</span>
<span class="sd">                    "python", "compute_engine", or "tensor_db". Defaults to</span>
<span class="sd">                    "python".</span>
<span class="sd">                    - "python" - Pure-python implementation running on the client.</span>
<span class="sd">                        Can be used for data stored anywhere. WARNING: using this</span>
<span class="sd">                        option with big datasets is discouraged due to potential</span>
<span class="sd">                        memory issues.</span>
<span class="sd">                    - "compute_engine" - Performant C++ implementation of the Deep</span>
<span class="sd">                        Lake Compute Engine. Runs on the client and can be used for</span>
<span class="sd">                        any data stored in or connected to Deep Lake. It cannot be</span>
<span class="sd">                        used with in-memory or local datasets.</span>
<span class="sd">                    - "tensor_db" - Performant, fully-hosted Managed Tensor Database.</span>
<span class="sd">                        Responsible for storage and query execution. Only available</span>
<span class="sd">                        for data stored in the Deep Lake Managed Database.</span>
<span class="sd">                        To store datasets in this database, specify</span>
<span class="sd">                        `runtime = {"db_engine": True}` during dataset creation.</span>
<span class="sd">                distance_metric (str): `L2` for Euclidean, `L1` for Nuclear,</span>
<span class="sd">                    `max` for L-infinity distance, `cos` for cosine similarity,</span>
<span class="sd">                    'dot' for dot product. Defaults to `L2`.</span>
<span class="sd">                deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                    search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                    in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                    is set to "deepmemory_distance", which represents the metric with</span>
<span class="sd">                    which the model was trained. The search is performed using the Deep</span>
<span class="sd">                    Memory model. If False, the distance metric is set to "COS" or</span>
<span class="sd">                    whatever distance metric user specifies.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Document]: List of Documents most similar to the query vector.</span>
<span class="sd">        """</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">return_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.similarity_search_with_score"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.similarity_search_with_score">[docs]</a>    <span class="k">def</span> <span class="nf">similarity_search_with_score</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Document</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Run similarity search with Deep Lake with distance returned.</span>

<span class="sd">        Examples:</span>
<span class="sd">        &gt;&gt;&gt; data = vector_store.similarity_search_with_score(</span>
<span class="sd">        ...     query=&lt;your_query&gt;,</span>
<span class="sd">        ...     embedding=&lt;your_embedding_function&gt;</span>
<span class="sd">        ...     k=&lt;number_of_items_to_return&gt;,</span>
<span class="sd">        ...     exec_option=&lt;preferred_exec_option&gt;,</span>
<span class="sd">        ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            query (str): Query text to search for.</span>
<span class="sd">            k (int): Number of results to return. Defaults to 4.</span>
<span class="sd">            kwargs: Additional keyword arguments. Some of these arguments are:</span>
<span class="sd">                distance_metric: `L2` for Euclidean, `L1` for Nuclear, `max` L-infinity</span>
<span class="sd">                    distance, `cos` for cosine similarity, 'dot' for dot product.</span>
<span class="sd">                    Defaults to `L2`.</span>
<span class="sd">                filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.</span>
<span class="sd">                    embedding_function (Callable): Embedding function to use. Defaults</span>
<span class="sd">                    to None.</span>
<span class="sd">                exec_option (str): DeepLakeVectorStore supports 3 ways to perform</span>
<span class="sd">                    searching. It could be either "python", "compute_engine" or</span>
<span class="sd">                    "tensor_db". Defaults to "python".</span>
<span class="sd">                    - "python" - Pure-python implementation running on the client.</span>
<span class="sd">                        Can be used for data stored anywhere. WARNING: using this</span>
<span class="sd">                        option with big datasets is discouraged due to potential</span>
<span class="sd">                        memory issues.</span>
<span class="sd">                    - "compute_engine" - Performant C++ implementation of the Deep</span>
<span class="sd">                        Lake Compute Engine. Runs on the client and can be used for</span>
<span class="sd">                        any data stored in or connected to Deep Lake. It cannot be used</span>
<span class="sd">                        with in-memory or local datasets.</span>
<span class="sd">                    - "tensor_db" - Performant, fully-hosted Managed Tensor Database.</span>
<span class="sd">                        Responsible for storage and query execution. Only available for</span>
<span class="sd">                        data stored in the Deep Lake Managed Database. To store datasets</span>
<span class="sd">                        in this database, specify `runtime = {"db_engine": True}`</span>
<span class="sd">                        during dataset creation.</span>
<span class="sd">                deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                    search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                    in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                    is set to "deepmemory_distance", which represents the metric with</span>
<span class="sd">                    which the model was trained. The search is performed using the Deep</span>
<span class="sd">                    Memory model. If False, the distance metric is set to "COS" or</span>
<span class="sd">                    whatever distance metric user specifies.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Tuple[Document, float]]: List of documents most similar to the query</span>
<span class="sd">                text with distance in float."""</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">return_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.max_marginal_relevance_search_by_vector"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.max_marginal_relevance_search_by_vector">[docs]</a>    <span class="k">def</span> <span class="nf">max_marginal_relevance_search_by_vector</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">fetch_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">lambda_mult</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Return docs selected using the maximal marginal relevance. Maximal marginal</span>
<span class="sd">        relevance optimizes for similarity to query AND diversity among selected docs.</span>

<span class="sd">        Examples:</span>
<span class="sd">        &gt;&gt;&gt; data = vector_store.max_marginal_relevance_search_by_vector(</span>
<span class="sd">        ...        embedding=&lt;your_embedding&gt;,</span>
<span class="sd">        ...        fetch_k=&lt;elements_to_fetch_before_mmr_search&gt;,</span>
<span class="sd">        ...        k=&lt;number_of_items_to_return&gt;,</span>
<span class="sd">        ...        exec_option=&lt;preferred_exec_option&gt;,</span>
<span class="sd">        ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            embedding: Embedding to look up documents similar to.</span>
<span class="sd">            k: Number of Documents to return. Defaults to 4.</span>
<span class="sd">            fetch_k: Number of Documents to fetch for MMR algorithm.</span>
<span class="sd">            lambda_mult: Number between 0 and 1 determining the degree of diversity.</span>
<span class="sd">                0 corresponds to max diversity and 1 to min diversity. Defaults to 0.5.</span>
<span class="sd">            exec_option (str): DeepLakeVectorStore supports 3 ways for searching.</span>
<span class="sd">                Could be "python", "compute_engine" or "tensor_db". Defaults to</span>
<span class="sd">                "python".</span>
<span class="sd">                - "python" - Pure-python implementation running on the client.</span>
<span class="sd">                    Can be used for data stored anywhere. WARNING: using this</span>
<span class="sd">                    option with big datasets is discouraged due to potential</span>
<span class="sd">                    memory issues.</span>
<span class="sd">                - "compute_engine" - Performant C++ implementation of the Deep</span>
<span class="sd">                    Lake Compute Engine. Runs on the client and can be used for</span>
<span class="sd">                    any data stored in or connected to Deep Lake. It cannot be used</span>
<span class="sd">                    with in-memory or local datasets.</span>
<span class="sd">                - "tensor_db" - Performant, fully-hosted Managed Tensor Database.</span>
<span class="sd">                    Responsible for storage and query execution. Only available for</span>
<span class="sd">                    data stored in the Deep Lake Managed Database. To store datasets</span>
<span class="sd">                    in this database, specify `runtime = {"db_engine": True}`</span>
<span class="sd">                    during dataset creation.</span>
<span class="sd">            deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                is set to "deepmemory_distance", which represents the metric with</span>
<span class="sd">                which the model was trained. The search is performed using the Deep</span>
<span class="sd">                Memory model. If False, the distance metric is set to "COS" or</span>
<span class="sd">                whatever distance metric user specifies.</span>
<span class="sd">            kwargs: Additional keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Documents] - A list of documents.</span>
<span class="sd">        """</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">fetch_k</span><span class="o">=</span><span class="n">fetch_k</span><span class="p">,</span>
            <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">lambda_mult</span><span class="o">=</span><span class="n">lambda_mult</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.max_marginal_relevance_search"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.max_marginal_relevance_search">[docs]</a>    <span class="k">def</span> <span class="nf">max_marginal_relevance_search</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">fetch_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">lambda_mult</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Return docs selected using maximal marginal relevance.</span>

<span class="sd">        Maximal marginal relevance optimizes for similarity to query AND diversity</span>
<span class="sd">        among selected documents.</span>

<span class="sd">        Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Search using an embedding</span>
<span class="sd">        &gt;&gt;&gt; data = vector_store.max_marginal_relevance_search(</span>
<span class="sd">        ...        query = &lt;query_to_search&gt;,</span>
<span class="sd">        ...        embedding_function = &lt;embedding_function_for_query&gt;,</span>
<span class="sd">        ...        k = &lt;number_of_items_to_return&gt;,</span>
<span class="sd">        ...        exec_option = &lt;preferred_exec_option&gt;,</span>
<span class="sd">        ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            query: Text to look up documents similar to.</span>
<span class="sd">            k: Number of Documents to return. Defaults to 4.</span>
<span class="sd">            fetch_k: Number of Documents for MMR algorithm.</span>
<span class="sd">            lambda_mult: Value between 0 and 1. 0 corresponds</span>
<span class="sd">                        to maximum diversity and 1 to minimum.</span>
<span class="sd">                        Defaults to 0.5.</span>
<span class="sd">            exec_option (str): Supports 3 ways to perform searching.</span>
<span class="sd">                - "python" - Pure-python implementation running on the client.</span>
<span class="sd">                        Can be used for data stored anywhere. WARNING: using this</span>
<span class="sd">                        option with big datasets is discouraged due to potential</span>
<span class="sd">                        memory issues.</span>
<span class="sd">                    - "compute_engine" - Performant C++ implementation of the Deep</span>
<span class="sd">                        Lake Compute Engine. Runs on the client and can be used for</span>
<span class="sd">                        any data stored in or connected to Deep Lake. It cannot be</span>
<span class="sd">                        used with in-memory or local datasets.</span>
<span class="sd">                    - "tensor_db" - Performant, fully-hosted Managed Tensor Database.</span>
<span class="sd">                        Responsible for storage and query execution. Only available</span>
<span class="sd">                        for data stored in the Deep Lake Managed Database. To store</span>
<span class="sd">                        datasets in this database, specify</span>
<span class="sd">                        `runtime = {"db_engine": True}` during dataset creation.</span>
<span class="sd">            deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                is set to "deepmemory_distance", which represents the metric with</span>
<span class="sd">                which the model was trained. The search is performed using the Deep</span>
<span class="sd">                Memory model. If False, the distance metric is set to "COS" or</span>
<span class="sd">                whatever distance metric user specifies.</span>
<span class="sd">            kwargs: Additional keyword arguments</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of Documents selected by maximal marginal relevance.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: when MRR search is on but embedding function is</span>
<span class="sd">                not specified.</span>
<span class="sd">        """</span>
        <span class="n">embedding_function</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"embedding"</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span>
        <span class="k">if</span> <span class="n">embedding_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"For MMR search, you must specify an embedding function on"</span>
                <span class="s2">" `creation` or during add call."</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">fetch_k</span><span class="o">=</span><span class="n">fetch_k</span><span class="p">,</span>
            <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">lambda_mult</span><span class="o">=</span><span class="n">lambda_mult</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
            <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding_function</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.from_texts"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.from_texts">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_texts</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Embeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadatas</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_LANGCHAIN_DEFAULT_DEEPLAKE_PATH</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DeepLake</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Create a Deep Lake dataset from a raw documents.</span>

<span class="sd">        If a dataset_path is specified, the dataset will be persisted in that location,</span>
<span class="sd">        otherwise by default at `./deeplake`</span>

<span class="sd">        Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Search using an embedding</span>
<span class="sd">        &gt;&gt;&gt; vector_store = DeepLake.from_texts(</span>
<span class="sd">        ...        texts = &lt;the_texts_that_you_want_to_embed&gt;,</span>
<span class="sd">        ...        embedding_function = &lt;embedding_function_for_query&gt;,</span>
<span class="sd">        ...        k = &lt;number_of_items_to_return&gt;,</span>
<span class="sd">        ...        exec_option = &lt;preferred_exec_option&gt;,</span>
<span class="sd">        ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset_path (str): - The full path to the dataset. Can be:</span>
<span class="sd">                - Deep Lake cloud path of the form ``hub://username/dataset_name``.</span>
<span class="sd">                    To write to Deep Lake cloud datasets,</span>
<span class="sd">                    ensure that you are logged in to Deep Lake</span>
<span class="sd">                    (use 'activeloop login' from command line)</span>
<span class="sd">                - AWS S3 path of the form ``s3://bucketname/path/to/dataset``.</span>
<span class="sd">                    Credentials are required in either the environment</span>
<span class="sd">                - Google Cloud Storage path of the form</span>
<span class="sd">                    ``gcs://bucketname/path/to/dataset`` Credentials are required</span>
<span class="sd">                    in either the environment</span>
<span class="sd">                - Local file system path of the form ``./path/to/dataset`` or</span>
<span class="sd">                    ``~/path/to/dataset`` or ``path/to/dataset``.</span>
<span class="sd">                - In-memory path of the form ``mem://path/to/dataset`` which doesn't</span>
<span class="sd">                    save the dataset, but keeps it in memory instead.</span>
<span class="sd">                    Should be used only for testing as it does not persist.</span>
<span class="sd">            texts (List[Document]): List of documents to add.</span>
<span class="sd">            embedding (Optional[Embeddings]): Embedding function. Defaults to None.</span>
<span class="sd">                Note, in other places, it is called embedding_function.</span>
<span class="sd">            metadatas (Optional[List[dict]]): List of metadatas. Defaults to None.</span>
<span class="sd">            ids (Optional[List[str]]): List of document IDs. Defaults to None.</span>
<span class="sd">            kwargs: Additional keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            DeepLake: Deep Lake dataset.</span>
<span class="sd">        """</span>
        <span class="n">deeplake_dataset</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">dataset_path</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">deeplake_dataset</span><span class="o">.</span><span class="n">add_texts</span><span class="p">(</span>
            <span class="n">texts</span><span class="o">=</span><span class="n">texts</span><span class="p">,</span>
            <span class="n">metadatas</span><span class="o">=</span><span class="n">metadatas</span><span class="p">,</span>
            <span class="n">ids</span><span class="o">=</span><span class="n">ids</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">deeplake_dataset</span></div>

<div class="viewcode-block" id="DeepLake.delete"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.delete">[docs]</a>    <span class="k">def</span> <span class="nf">delete</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Delete the entities in the dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            ids (Optional[List[str]], optional): The document_ids to delete.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            **kwargs: Other keyword arguments that subclasses might use.</span>
<span class="sd">                - filter (Optional[Dict[str, str]], optional): The filter to delete by.</span>
<span class="sd">                - delete_all (Optional[bool], optional): Whether to drop the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: Whether the delete operation was successful.</span>
<span class="sd">        """</span>
        <span class="nb">filter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"filter"</span><span class="p">)</span>
        <span class="n">delete_all</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"delete_all"</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">ids</span><span class="o">=</span><span class="n">ids</span><span class="p">,</span> <span class="nb">filter</span><span class="o">=</span><span class="nb">filter</span><span class="p">,</span> <span class="n">delete_all</span><span class="o">=</span><span class="n">delete_all</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="DeepLake.force_delete_by_path"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.force_delete_by_path">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">force_delete_by_path</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Force delete dataset by path.</span>

<span class="sd">        Args:</span>
<span class="sd">            path (str): path of the dataset to delete.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if deeplake is not installed.</span>
<span class="sd">        """</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">deeplake</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">"Could not import deeplake python package. "</span>
                <span class="s2">"Please install it with `pip install deeplake`."</span>
            <span class="p">)</span>
        <span class="n">deeplake</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">large_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.delete_dataset"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.delete_dataset">[docs]</a>    <span class="k">def</span> <span class="nf">delete_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Delete the collection."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">delete_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.ds"><a class="viewcode-back" href="../../../community/vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.ds">[docs]</a>    <span class="k">def</span> <span class="nf">ds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">"this method is deprecated and will be removed, "</span>
            <span class="s2">"better to use `db.vectorstore.dataset` instead."</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">dataset</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_validate_kwargs</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">method_name</span><span class="p">):</span>  <span class="c1"># type: ignore[no-untyped-def]</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">valid_items</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_get_valid_args</span><span class="p">(</span><span class="n">method_name</span><span class="p">)</span>
            <span class="n">unsupported_items</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_get_unsupported_items</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">valid_items</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">unsupported_items</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"`</span><span class="si">{</span><span class="n">unsupported_items</span><span class="si">}</span><span class="s2">` are not a valid "</span>
                    <span class="sa">f</span><span class="s2">"argument to </span><span class="si">{</span><span class="n">method_name</span><span class="si">}</span><span class="s2"> method"</span>
                <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_get_valid_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">method_name</span><span class="p">):</span>  <span class="c1"># type: ignore[no-untyped-def]</span>
        <span class="k">if</span> <span class="n">method_name</span> <span class="o">==</span> <span class="s2">"search"</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_valid_search_kwargs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_get_unsupported_items</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">valid_items</span><span class="p">):</span>  <span class="c1"># type: ignore[no-untyped-def]</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_items</span><span class="p">}</span>
        <span class="n">unsupported_items</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">unsupported_items</span> <span class="o">=</span> <span class="s2">"`, `"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        <span class="k">return</span> <span class="n">unsupported_items</span></div>
</pre></div>
</article>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      Â© Copyright 2023, LangChain Inc.
      <br/>
</p>
</div>
</div>
</div>
</footer>
</body>
</html>