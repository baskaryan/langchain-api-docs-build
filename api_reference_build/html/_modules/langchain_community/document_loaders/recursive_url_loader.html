
<!DOCTYPE html>

<html data-content_root="" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>langchain_community.document_loaders.recursive_url_loader â€” ðŸ¦œðŸ”— LangChain  documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/autodoc_pydantic.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/css/custom.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/sphinx_highlight.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/design-tabs.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = '_modules/langchain_community/document_loaders/recursive_url_loader';</script>
<link href="../../../_static/favicon.png" rel="icon"/>
<link href="../../../search.html" rel="search" title="Search"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Sep 02, 2024" name="docbuild:last-update"/>
</head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../../index.html">
<img alt="ðŸ¦œðŸ”— LangChain  documentation - Home" class="logo__image only-light" src="../../../_static/wordmark-api.svg"/>
<script>document.write(`<img src="../../../_static/wordmark-api-dark.svg" class="logo__image only-dark" alt="ðŸ¦œðŸ”— LangChain  documentation - Home"/>`);</script>
</a></div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../reference.html">
    Reference
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://api.python.langchain.com/">
    Legacy reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search" spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar hide-on-wide">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../reference.html">
    Reference
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-external" href="https://api.python.langchain.com/">
    Legacy reference
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- This will display a link to LangChain docs -->
<head>
<style>
        .text-link {
            text-decoration: none; /* Remove underline */
            color: inherit;        /* Inherit color from parent element */
        }
    </style>
</head>
<body>
<a class="text-link" href="https://python.langchain.com/">Docs</a>
</body></div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Quick Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/langchain-ai/langchain" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-square-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://twitter.com/langchainai" rel="noopener" target="_blank" title="X / Twitter"><i aria-hidden="true" class="fab fa-twitter-square fa-lg"></i>
<span class="sr-only">X / Twitter</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../../index.html">Module code</a></li>
<li aria-current="page" class="breadcrumb-item active">langchain_co...</li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<h1>Source code for langchain_community.document_loaders.recursive_url_loader</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Iterator</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Sequence</span><span class="p">,</span>
    <span class="n">Set</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="n">cast</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">aiohttp</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">langchain_core.documents</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">langchain_core.utils.html</span> <span class="kn">import</span> <span class="n">extract_sub_links</span>

<span class="kn">from</span> <span class="nn">langchain_community.document_loaders.base</span> <span class="kn">import</span> <span class="n">BaseLoader</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_metadata_extractor</span><span class="p">(</span>
    <span class="n">raw_html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">response</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">requests</span><span class="o">.</span><span class="n">Response</span><span class="p">,</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientResponse</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Extract metadata from raw html using BeautifulSoup."""</span>
    <span class="n">content_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="s2">"headers"</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"Content-Type"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"source"</span><span class="p">:</span> <span class="n">url</span><span class="p">,</span> <span class="s2">"content_type"</span><span class="p">:</span> <span class="n">content_type</span><span class="p">}</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">"The bs4 package is required for default metadata extraction. "</span>
            <span class="s2">"Please install it with `pip install -U beautifulsoup4`."</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">metadata</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">raw_html</span><span class="p">,</span> <span class="s2">"html.parser"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span> <span class="o">:=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">"title"</span><span class="p">):</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s2">"title"</span><span class="p">]</span> <span class="o">=</span> <span class="n">title</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">description</span> <span class="o">:=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">"meta"</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"description"</span><span class="p">}):</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s2">"description"</span><span class="p">]</span> <span class="o">=</span> <span class="n">description</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"content"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">html</span> <span class="o">:=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">"html"</span><span class="p">):</span>
        <span class="n">metadata</span><span class="p">[</span><span class="s2">"language"</span><span class="p">]</span> <span class="o">=</span> <span class="n">html</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lang"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metadata</span>


<div class="viewcode-block" id="RecursiveUrlLoader"><a class="viewcode-back" href="../../../community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html#langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader">[docs]</a><span class="k">class</span> <span class="nc">RecursiveUrlLoader</span><span class="p">(</span><span class="n">BaseLoader</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Recursively load all child links from a root URL.</span>

<span class="sd">    **Security Note**: This loader is a crawler that will start crawling</span>
<span class="sd">        at a given URL and then expand to crawl child links recursively.</span>

<span class="sd">        Web crawlers should generally NOT be deployed with network access</span>
<span class="sd">        to any internal servers.</span>

<span class="sd">        Control access to who can submit crawling requests and what network access</span>
<span class="sd">        the crawler has.</span>

<span class="sd">        While crawling, the crawler may encounter malicious URLs that would lead to a</span>
<span class="sd">        server-side request forgery (SSRF) attack.</span>

<span class="sd">        To mitigate risks, the crawler by default will only load URLs from the same</span>
<span class="sd">        domain as the start URL (controlled via prevent_outside named argument).</span>

<span class="sd">        This will mitigate the risk of SSRF attacks, but will not eliminate it.</span>

<span class="sd">        For example, if crawling a host which hosts several sites:</span>

<span class="sd">        https://some_host/alice_site/</span>
<span class="sd">        https://some_host/bob_site/</span>

<span class="sd">        A malicious URL on Alice's site could cause the crawler to make a malicious</span>
<span class="sd">        GET request to an endpoint on Bob's site. Both sites are hosted on the</span>
<span class="sd">        same host, so such a request would not be prevented by default.</span>

<span class="sd">        See https://python.langchain.com/v0.2/docs/security/</span>

<span class="sd">    Setup:</span>

<span class="sd">        This class has no required additional dependencies. You can optionally install</span>
<span class="sd">        ``beautifulsoup4`` for richer default metadata extraction:</span>

<span class="sd">        .. code-block:: bash</span>

<span class="sd">            pip install -U beautifulsoup4</span>

<span class="sd">    Instantiate:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            from langchain_community.document_loaders import RecursiveUrlLoader</span>

<span class="sd">            loader = RecursiveUrlLoader(</span>
<span class="sd">                "https://docs.python.org/3.9/",</span>
<span class="sd">                # max_depth=2,</span>
<span class="sd">                # use_async=False,</span>
<span class="sd">                # extractor=None,</span>
<span class="sd">                # metadata_extractor=None,</span>
<span class="sd">                # exclude_dirs=(),</span>
<span class="sd">                # timeout=10,</span>
<span class="sd">                # check_response_status=True,</span>
<span class="sd">                # continue_on_failure=True,</span>
<span class="sd">                # prevent_outside=True,</span>
<span class="sd">                # base_url=None,</span>
<span class="sd">                # ...</span>
<span class="sd">            )</span>

<span class="sd">    Lazy load:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            docs = []</span>
<span class="sd">            docs_lazy = loader.lazy_load()</span>

<span class="sd">            # async variant:</span>
<span class="sd">            # docs_lazy = await loader.alazy_load()</span>

<span class="sd">            for doc in docs_lazy:</span>
<span class="sd">                docs.append(doc)</span>
<span class="sd">            print(docs[0].page_content[:100])</span>
<span class="sd">            print(docs[0].metadata)</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            &lt;!DOCTYPE html&gt;</span>

<span class="sd">            &lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;</span>
<span class="sd">            &lt;head&gt;</span>
<span class="sd">                &lt;meta charset="utf-8" /&gt;&lt;</span>
<span class="sd">            {'source': 'https://docs.python.org/3.9/', 'content_type': 'text/html', 'title': '3.9.19 Documentation', 'language': None}</span>

<span class="sd">    Async load:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            docs = await loader.aload()</span>
<span class="sd">            print(docs[0].page_content[:100])</span>
<span class="sd">            print(docs[0].metadata)</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            &lt;!DOCTYPE html&gt;</span>

<span class="sd">            &lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;</span>
<span class="sd">            &lt;head&gt;</span>
<span class="sd">                &lt;meta charset="utf-8" /&gt;&lt;</span>
<span class="sd">            {'source': 'https://docs.python.org/3.9/', 'content_type': 'text/html', 'title': '3.9.19 Documentation', 'language': None}</span>

<span class="sd">    Content parsing / extraction:</span>
<span class="sd">        By default the loader sets the raw HTML from each link as the Document page</span>
<span class="sd">        content. To parse this HTML into a more human/LLM-friendly format you can pass</span>
<span class="sd">        in a custom ``extractor`` method:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                # This example uses `beautifulsoup4` and `lxml`</span>
<span class="sd">                import re</span>
<span class="sd">                from bs4 import BeautifulSoup</span>

<span class="sd">                def bs4_extractor(html: str) -&gt; str:</span>
<span class="sd">                    soup = BeautifulSoup(html, "lxml")</span>
<span class="sd">                    return re.sub(r"\n\n+", "\n\n", soup.text).strip()</span>

<span class="sd">                loader = RecursiveUrlLoader(</span>
<span class="sd">                    "https://docs.python.org/3.9/",</span>
<span class="sd">                    extractor=bs4_extractor,</span>
<span class="sd">                )</span>
<span class="sd">                print(loader.load()[0].page_content[:200])</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                3.9.19 Documentation</span>

<span class="sd">                Download</span>
<span class="sd">                Download these documents</span>
<span class="sd">                Docs by version</span>

<span class="sd">                Python 3.13 (in development)</span>
<span class="sd">                Python 3.12 (stable)</span>
<span class="sd">                Python 3.11 (security-fixes)</span>
<span class="sd">                Python 3.10 (security-fixes)</span>
<span class="sd">                Python 3.9 (securit</span>

<span class="sd">    Metadata extraction:</span>
<span class="sd">        Similarly to content extraction, you can specify a metadata extraction function</span>
<span class="sd">        to customize how Document metadata is extracted from the HTTP response.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            import aiohttp</span>
<span class="sd">            import requests</span>
<span class="sd">            from typing import Union</span>

<span class="sd">            def simple_metadata_extractor(</span>
<span class="sd">                raw_html: str, url: str, response: Union[requests.Response, aiohttp.ClientResponse]</span>
<span class="sd">            ) -&gt; dict:</span>
<span class="sd">                content_type = getattr(response, "headers").get("Content-Type", "")</span>
<span class="sd">                return {"source": url, "content_type": content_type}</span>

<span class="sd">            loader = RecursiveUrlLoader(</span>
<span class="sd">                "https://docs.python.org/3.9/",</span>
<span class="sd">                metadata_extractor=simple_metadata_extractor,</span>
<span class="sd">            )</span>
<span class="sd">            loader.load()[0].metadata</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            {'source': 'https://docs.python.org/3.9/', 'content_type': 'text/html'}</span>

<span class="sd">    Filtering URLs:</span>
<span class="sd">        You may not always want to pull every URL from a website. There are four parameters</span>
<span class="sd">        that allow us to control what URLs we pull recursively. First, we can set the</span>
<span class="sd">        ``prevent_outside`` parameter to prevent URLs outside of the ``base_url`` from</span>
<span class="sd">        being pulled. Note that the ``base_url`` does not need to be the same as the URL we</span>
<span class="sd">        pass in, as shown below. We can also use ``link_regex`` and ``exclude_dirs`` to be</span>
<span class="sd">        more specific with the URLs that we select. In this example, we only pull websites</span>
<span class="sd">        from the python docs, which contain the string "index" somewhere and are not</span>
<span class="sd">        located in the FAQ section of the website.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            loader = RecursiveUrlLoader(</span>
<span class="sd">                "https://docs.python.org/3.9/",</span>
<span class="sd">                prevent_outside=True,</span>
<span class="sd">                base_url="https://docs.python.org",</span>
<span class="sd">                link_regex=r'&lt;a\s+(?:[^&gt;]*?\s+)?href="([^"]*(?=index)[^"]*)"',</span>
<span class="sd">                exclude_dirs=['https://docs.python.org/3.9/faq']</span>
<span class="sd">            )</span>
<span class="sd">            docs = loader.load()</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            ['https://docs.python.org/3.9/',</span>
<span class="sd">            'https://docs.python.org/3.9/py-modindex.html',</span>
<span class="sd">            'https://docs.python.org/3.9/genindex.html',</span>
<span class="sd">            'https://docs.python.org/3.9/tutorial/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/using/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/extending/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/installing/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/library/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/c-api/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/howto/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/distributing/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/reference/index.html',</span>
<span class="sd">            'https://docs.python.org/3.9/whatsnew/index.html']</span>

<span class="sd">    """</span>  <span class="c1"># noqa: E501</span>

<div class="viewcode-block" id="RecursiveUrlLoader.__init__"><a class="viewcode-back" href="../../../community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html#langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">max_depth</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">use_async</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extractor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata_extractor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_MetadataExtractorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exclude_dirs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">prevent_outside</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">link_regex</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">Pattern</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">headers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">check_response_status</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">continue_on_failure</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">base_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">autoset_encoding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">encoding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Initialize with URL to crawl and any subdirectories to exclude.</span>

<span class="sd">        Args:</span>
<span class="sd">            url: The URL to crawl.</span>
<span class="sd">            max_depth: The max depth of the recursive loading.</span>
<span class="sd">            use_async: Whether to use asynchronous loading.</span>
<span class="sd">                If True, lazy_load function will not be lazy, but it will still work in the</span>
<span class="sd">                expected way, just not lazy.</span>
<span class="sd">            extractor: A function to extract document contents from raw HTML.</span>
<span class="sd">                When extract function returns an empty string, the document is</span>
<span class="sd">                ignored. Default returns the raw HTML.</span>
<span class="sd">            metadata_extractor: A function to extract metadata from args: raw HTML, the</span>
<span class="sd">                source url, and the requests.Response/aiohttp.ClientResponse object</span>
<span class="sd">                (args in that order).</span>
<span class="sd">                Default extractor will attempt to use BeautifulSoup4 to extract the</span>
<span class="sd">                title, description and language of the page.</span>
<span class="sd">                ..code-block:: python</span>

<span class="sd">                    import requests</span>
<span class="sd">                    import aiohttp</span>

<span class="sd">                    def simple_metadata_extractor(</span>
<span class="sd">                        raw_html: str, url: str, response: Union[requests.Response, aiohttp.ClientResponse]</span>
<span class="sd">                    ) -&gt; dict:</span>
<span class="sd">                        content_type = getattr(response, "headers").get("Content-Type", "")</span>
<span class="sd">                        return {"source": url, "content_type": content_type}</span>

<span class="sd">            exclude_dirs: A list of subdirectories to exclude.</span>
<span class="sd">            timeout: The timeout for the requests, in the unit of seconds. If None then</span>
<span class="sd">                connection will not timeout.</span>
<span class="sd">            prevent_outside: If True, prevent loading from urls which are not children</span>
<span class="sd">                of the root url.</span>
<span class="sd">            link_regex: Regex for extracting sub-links from the raw html of a web page.</span>
<span class="sd">            headers: Default request headers to use for all requests.</span>
<span class="sd">            check_response_status: If True, check HTTP response status and skip</span>
<span class="sd">                URLs with error responses (400-599).</span>
<span class="sd">            continue_on_failure: If True, continue if getting or parsing a link raises</span>
<span class="sd">                an exception. Otherwise, raise the exception.</span>
<span class="sd">            base_url: The base url to check for outside links against.</span>
<span class="sd">            autoset_encoding: Whether to automatically set the encoding of the response.</span>
<span class="sd">                If True, the encoding of the response will be set to the apparent</span>
<span class="sd">                encoding, unless the `encoding` argument has already been explicitly set.</span>
<span class="sd">            encoding: The encoding of the response. If manually set, the encoding will be</span>
<span class="sd">                set to given value, regardless of the `autoset_encoding` argument.</span>
<span class="sd">        """</span>  <span class="c1"># noqa: E501</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">url</span> <span class="o">=</span> <span class="n">url</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span> <span class="k">if</span> <span class="n">max_depth</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_async</span> <span class="o">=</span> <span class="n">use_async</span> <span class="k">if</span> <span class="n">use_async</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span> <span class="o">=</span> <span class="n">extractor</span> <span class="k">if</span> <span class="n">extractor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>
        <span class="n">metadata_extractor</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">metadata_extractor</span>
            <span class="k">if</span> <span class="n">metadata_extractor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">_metadata_extractor</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">autoset_encoding</span> <span class="o">=</span> <span class="n">autoset_encoding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="n">encoding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metadata_extractor</span> <span class="o">=</span> <span class="n">_wrap_metadata_extractor</span><span class="p">(</span><span class="n">metadata_extractor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exclude_dirs</span> <span class="o">=</span> <span class="n">exclude_dirs</span> <span class="k">if</span> <span class="n">exclude_dirs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">()</span>

        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">exclude_dir</span><span class="p">)</span> <span class="k">for</span> <span class="n">exclude_dir</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">exclude_dirs</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Base url is included in exclude_dirs. Received base_url: </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2"> and "</span>
                <span class="sa">f</span><span class="s2">"exclude_dirs: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">exclude_dirs</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">timeout</span> <span class="o">=</span> <span class="n">timeout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prevent_outside</span> <span class="o">=</span> <span class="n">prevent_outside</span> <span class="k">if</span> <span class="n">prevent_outside</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">link_regex</span> <span class="o">=</span> <span class="n">link_regex</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_response_status</span> <span class="o">=</span> <span class="n">check_response_status</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">continue_on_failure</span> <span class="o">=</span> <span class="n">continue_on_failure</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_url</span> <span class="o">=</span> <span class="n">base_url</span> <span class="k">if</span> <span class="n">base_url</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">url</span></div>

    <span class="k">def</span> <span class="nf">_get_child_links_recursive</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">visited</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Recursively get all child links starting with the path of the input URL.</span>

<span class="sd">        Args:</span>
<span class="sd">            url: The URL to crawl.</span>
<span class="sd">            visited: A set of visited URLs.</span>
<span class="sd">            depth: Current depth of recursion. Stop when depth &gt;= max_depth.</span>
<span class="sd">        """</span>

        <span class="k">if</span> <span class="n">depth</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Get all links that can be accessed from the current URL</span>
        <span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">timeout</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoding</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">response</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoding</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoset_encoding</span><span class="p">:</span>
                <span class="n">response</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">apparent_encoding</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_response_status</span> <span class="ow">and</span> <span class="mi">400</span> <span class="o">&lt;=</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">&lt;=</span> <span class="mi">599</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Received HTTP status </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">continue_on_failure</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Unable to load from </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">. Received error </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2"> of type "</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">e</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span>
                <span class="p">)</span>
                <span class="k">return</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
        <span class="n">content</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">content</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">Document</span><span class="p">(</span>
                <span class="n">page_content</span><span class="o">=</span><span class="n">content</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metadata_extractor</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">response</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="c1"># Store the visited links and recursively visit the children</span>
        <span class="n">sub_links</span> <span class="o">=</span> <span class="n">extract_sub_links</span><span class="p">(</span>
            <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
            <span class="n">url</span><span class="p">,</span>
            <span class="n">base_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="p">,</span>
            <span class="n">pattern</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">link_regex</span><span class="p">,</span>
            <span class="n">prevent_outside</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prevent_outside</span><span class="p">,</span>
            <span class="n">exclude_prefixes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exclude_dirs</span><span class="p">,</span>
            <span class="n">continue_on_failure</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">continue_on_failure</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">sub_links</span><span class="p">:</span>
            <span class="c1"># Check all unvisited links</span>
            <span class="k">if</span> <span class="n">link</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_child_links_recursive</span><span class="p">(</span>
                    <span class="n">link</span><span class="p">,</span> <span class="n">visited</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">_async_get_child_links_recursive</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">visited</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Recursively get all child links starting with the path of the input URL.</span>

<span class="sd">        Args:</span>
<span class="sd">            url: The URL to crawl.</span>
<span class="sd">            visited: A set of visited URLs.</span>
<span class="sd">            depth: To reach the current url, how many pages have been visited.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_async</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"Async functions forbidden when not initialized with `use_async`"</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">depth</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Disable SSL verification because websites may have invalid SSL certificates,</span>
        <span class="c1"># but won't cause any security issues for us.</span>
        <span class="n">close_session</span> <span class="o">=</span> <span class="n">session</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="n">session</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">session</span>
            <span class="k">if</span> <span class="n">session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">(</span>
                <span class="n">connector</span><span class="o">=</span><span class="n">aiohttp</span><span class="o">.</span><span class="n">TCPConnector</span><span class="p">(</span><span class="n">ssl</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="n">timeout</span><span class="o">=</span><span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientTimeout</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">timeout</span><span class="p">),</span>
                <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
                <span class="n">text</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_response_status</span> <span class="ow">and</span> <span class="mi">400</span> <span class="o">&lt;=</span> <span class="n">response</span><span class="o">.</span><span class="n">status</span> <span class="o">&lt;=</span> <span class="mi">599</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Received HTTP status </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">status</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="n">aiohttp</span><span class="o">.</span><span class="n">client_exceptions</span><span class="o">.</span><span class="n">InvalidURL</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">close_session</span><span class="p">:</span>
                <span class="k">await</span> <span class="n">session</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">continue_on_failure</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Unable to load </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">. Received error </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2"> of type "</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">e</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="p">[]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">content</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">content</span><span class="p">:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">Document</span><span class="p">(</span>
                    <span class="n">page_content</span><span class="o">=</span><span class="n">content</span><span class="p">,</span>
                    <span class="n">metadata</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metadata_extractor</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">response</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">depth</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">sub_links</span> <span class="o">=</span> <span class="n">extract_sub_links</span><span class="p">(</span>
                <span class="n">text</span><span class="p">,</span>
                <span class="n">url</span><span class="p">,</span>
                <span class="n">base_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="p">,</span>
                <span class="n">pattern</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">link_regex</span><span class="p">,</span>
                <span class="n">prevent_outside</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prevent_outside</span><span class="p">,</span>
                <span class="n">exclude_prefixes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exclude_dirs</span><span class="p">,</span>
                <span class="n">continue_on_failure</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">continue_on_failure</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Recursively call the function to get the children of the children</span>
            <span class="n">sub_tasks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">to_visit</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">sub_links</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">visited</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">to_visit</span><span class="p">:</span>
                <span class="n">sub_tasks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_async_get_child_links_recursive</span><span class="p">(</span>
                        <span class="n">link</span><span class="p">,</span> <span class="n">visited</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="n">next_results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">*</span><span class="n">sub_tasks</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">sub_result</span> <span class="ow">in</span> <span class="n">next_results</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sub_result</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">)</span> <span class="ow">or</span> <span class="n">sub_result</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># We don't want to stop the whole process, so just ignore it</span>
                    <span class="c1"># Not standard html format or invalid url or 404 may cause this.</span>
                    <span class="k">continue</span>
                <span class="c1"># locking not fully working, temporary hack to ensure deduplication</span>
                <span class="n">results</span> <span class="o">+=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">sub_result</span> <span class="k">if</span> <span class="n">r</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">close_session</span><span class="p">:</span>
            <span class="k">await</span> <span class="n">session</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">results</span>

<div class="viewcode-block" id="RecursiveUrlLoader.lazy_load"><a class="viewcode-back" href="../../../community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html#langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.lazy_load">[docs]</a>    <span class="k">def</span> <span class="nf">lazy_load</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Lazy load web pages.</span>
<span class="sd">        When use_async is True, this function will not be lazy,</span>
<span class="sd">        but it will still work in the expected way, just not lazy."""</span>
        <span class="n">visited</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_async</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_async_get_child_links_recursive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">url</span><span class="p">,</span> <span class="n">visited</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">results</span> <span class="ow">or</span> <span class="p">[])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_child_links_recursive</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">url</span><span class="p">,</span> <span class="n">visited</span><span class="p">)</span></div></div>


<span class="n">_MetadataExtractorType1</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="nb">dict</span><span class="p">]</span>
<span class="n">_MetadataExtractorType2</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[</span>
    <span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">requests</span><span class="o">.</span><span class="n">Response</span><span class="p">,</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientResponse</span><span class="p">]],</span> <span class="nb">dict</span>
<span class="p">]</span>
<span class="n">_MetadataExtractorType</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">_MetadataExtractorType1</span><span class="p">,</span> <span class="n">_MetadataExtractorType2</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_wrap_metadata_extractor</span><span class="p">(</span>
    <span class="n">metadata_extractor</span><span class="p">:</span> <span class="n">_MetadataExtractorType</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_MetadataExtractorType2</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">metadata_extractor</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">_MetadataExtractorType2</span><span class="p">,</span> <span class="n">metadata_extractor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">_metadata_extractor_wrapper</span><span class="p">(</span>
            <span class="n">raw_html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">response</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">requests</span><span class="o">.</span><span class="n">Response</span><span class="p">,</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientResponse</span><span class="p">],</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">_MetadataExtractorType1</span><span class="p">,</span> <span class="n">metadata_extractor</span><span class="p">)(</span><span class="n">raw_html</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">_metadata_extractor_wrapper</span>
</pre></div>
</article>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      Â© Copyright 2023, LangChain Inc.
      <br/>
</p>
</div>
</div>
</div>
</footer>
</body>
</html>